{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deepdow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddz_Pls5GqDU",
        "outputId": "9ce8860b-ac23-440c-97f1-cc12a5c70847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepdow\n",
            "  Downloading deepdow-0.2.2-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from deepdow) (0.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from deepdow) (1.4.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/dist-packages (from deepdow) (2.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from deepdow) (8.4.0)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.2.2-py3-none-any.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from deepdow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.9/dist-packages (from deepdow) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.5 in /usr/local/lib/python3.9/dist-packages (from deepdow) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from deepdow) (4.65.0)\n",
            "Collecting cvxpylayers\n",
            "  Downloading cvxpylayers-0.1.5.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.5->deepdow) (4.5.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from cvxpylayers->deepdow) (1.10.1)\n",
            "Collecting diffcp>=1.0.13\n",
            "  Downloading diffcp-1.0.22-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cvxpy>=1.1.0a4 in /usr/local/lib/python3.9/dist-packages (from cvxpylayers->deepdow) (1.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (4.39.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepdow) (3.0.9)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (9.0.0)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.6.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (3.1.2)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (0.4)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (2.2.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (3.19.6)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (3.4.3)\n",
            "Collecting shap<1,>=0.40\n",
            "  Downloading shap-0.41.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.4/572.4 KB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (1.4.47)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (6.1.0)\n",
            "Collecting alembic<2\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (2.2.1)\n",
            "Requirement already satisfied: pytz<2023 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (2022.7.1)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (1.2.2)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (0.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (2.27.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (8.1.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.9/dist-packages (from mlflow->deepdow) (6.0)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (67.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (2.16.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (0.40.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (1.51.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (1.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->deepdow) (2.2.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.9/dist-packages (from cvxpy>=1.1.0a4->cvxpylayers->deepdow) (3.2.2)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from cvxpy>=1.1.0a4->cvxpylayers->deepdow) (0.6.2.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.9/dist-packages (from cvxpy>=1.1.0a4->cvxpylayers->deepdow) (2.0.12)\n",
            "Collecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->deepdow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->deepdow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->deepdow) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=1.1 in /usr/local/lib/python3.9/dist-packages (from diffcp>=1.0.13->cvxpylayers->deepdow) (3.1.0)\n",
            "Collecting pybind11>=2.4\n",
            "  Downloading pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.9/dist-packages (from docker<7,>=4.0.0->mlflow->deepdow) (1.26.15)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask<3->mlflow->deepdow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deepdow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deepdow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deepdow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->deepdow) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow->deepdow) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2<4,>=2.11->mlflow->deepdow) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.17.3->mlflow->deepdow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.17.3->mlflow->deepdow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.17.3->mlflow->deepdow) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<2->mlflow->deepdow) (1.1.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from shap<1,>=0.40->mlflow->deepdow) (0.56.4)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->deepdow) (2.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.9/dist-packages (from osqp>=0.4.1->cvxpy>=1.1.0a4->cvxpylayers->deepdow) (0.1.5.post3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->deepdow) (0.4.8)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->shap<1,>=0.40->mlflow->deepdow) (0.39.1)\n",
            "Building wheels for collected packages: cvxpylayers, databricks-cli\n",
            "  Building wheel for cvxpylayers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cvxpylayers: filename=cvxpylayers-0.1.5-py3-none-any.whl size=26080 sha256=001bc3205dce301d8f586e008f0f0cf59a0be75d709382e9c3177aa6fac7363b\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/bb/d3/6295191d6bf8c8f859e2d81523366212dbf74db4829f950b68\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.6-py3-none-any.whl size=143237 sha256=b0d7e3072fb2111c327c3f9dc62bcd8654c352d786a7ffe9d981d3afae2f78cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/d9/cb/1cdc0826334cb600957db0b5a8448db02a8995daeab2556745\n",
            "Successfully built cvxpylayers databricks-cli\n",
            "Installing collected packages: websocket-client, smmap, slicer, querystring-parser, pyjwt, pybind11, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, shap, gitpython, diffcp, mlflow, cvxpylayers, deepdow\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 cvxpylayers-0.1.5 databricks-cli-0.17.6 deepdow-0.2.2 diffcp-1.0.22 docker-6.0.1 gitdb-4.0.10 gitpython-3.1.31 gunicorn-20.1.0 mlflow-2.2.2 pybind11-2.10.4 pyjwt-2.6.0 querystring-parser-1.2.4 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 websocket-client-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_LgeFa7N2g8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import cvxpy as cp\n",
        "import seaborn\n",
        "from deepdow.benchmarks import Benchmark, OneOverN, Random\n",
        "from deepdow.callbacks import EarlyStoppingCallback\n",
        "from deepdow.data import InRAMDataset, RigidDataLoader, prepare_standard_scaler, Scale\n",
        "from deepdow.data.synthetic import sin_single\n",
        "from deepdow.experiments import Run\n",
        "from deepdow.layers import SoftmaxAllocator\n",
        "from deepdow.losses import MeanReturns, SharpeRatio, MaximumDrawdown\n",
        "from deepdow.visualize import generate_metrics_table, generate_weights_table, plot_metrics, plot_weight_heatmap\n",
        "\n",
        "torch.manual_seed(4)\n",
        "np.random.seed(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assets = pd.read_csv('/content/drive/MyDrive/uchicago trading/Training Data_Case 3.csv', index_col=0)\n",
        "assets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vf8rTH7wOFf8",
        "outputId": "4fa2bbd3-a878-422f-e8c1-3048d88b1d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           A        B       C       D      E      F       G       H      I  \\\n",
              "1     119.96   198.25   76.54   32.08  53.20  19.47   40.63   43.47  19.76   \n",
              "2     120.32   201.42   76.73   31.86  53.88  19.23   40.47   45.16  19.88   \n",
              "3     119.60   200.23   77.60   31.56  55.11  18.93   39.84   46.03  20.29   \n",
              "4     121.76   199.61   79.48   31.62  55.80  19.15   40.13   46.89  20.01   \n",
              "5     120.10   199.64   81.49   31.89  55.02  19.16   39.94   47.59  20.12   \n",
              "...      ...      ...     ...     ...    ...    ...     ...     ...    ...   \n",
              "2516  317.31  1385.04  199.14  273.02  52.11  89.45  151.54  390.13  88.25   \n",
              "2517  317.20  1358.01  202.59  277.45  52.73  90.93  152.39  394.03  87.56   \n",
              "2518  312.31  1315.00  198.29  281.23  52.71  92.28  153.92  375.70  89.54   \n",
              "2519  312.45  1319.59  200.78  282.77  52.26  93.49  155.26  368.33  91.36   \n",
              "2520  314.02  1313.26  204.65  288.71  52.97  94.15  156.17  352.78  92.05   \n",
              "\n",
              "           J  \n",
              "1     113.91  \n",
              "2     112.98  \n",
              "3     114.24  \n",
              "4     114.27  \n",
              "5     113.87  \n",
              "...      ...  \n",
              "2516   35.99  \n",
              "2517   35.89  \n",
              "2518   36.13  \n",
              "2519   35.15  \n",
              "2520   34.59  \n",
              "\n",
              "[2520 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce4770ec-49a9-4705-aa38-2c7f4f84caca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>119.96</td>\n",
              "      <td>198.25</td>\n",
              "      <td>76.54</td>\n",
              "      <td>32.08</td>\n",
              "      <td>53.20</td>\n",
              "      <td>19.47</td>\n",
              "      <td>40.63</td>\n",
              "      <td>43.47</td>\n",
              "      <td>19.76</td>\n",
              "      <td>113.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>120.32</td>\n",
              "      <td>201.42</td>\n",
              "      <td>76.73</td>\n",
              "      <td>31.86</td>\n",
              "      <td>53.88</td>\n",
              "      <td>19.23</td>\n",
              "      <td>40.47</td>\n",
              "      <td>45.16</td>\n",
              "      <td>19.88</td>\n",
              "      <td>112.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>119.60</td>\n",
              "      <td>200.23</td>\n",
              "      <td>77.60</td>\n",
              "      <td>31.56</td>\n",
              "      <td>55.11</td>\n",
              "      <td>18.93</td>\n",
              "      <td>39.84</td>\n",
              "      <td>46.03</td>\n",
              "      <td>20.29</td>\n",
              "      <td>114.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121.76</td>\n",
              "      <td>199.61</td>\n",
              "      <td>79.48</td>\n",
              "      <td>31.62</td>\n",
              "      <td>55.80</td>\n",
              "      <td>19.15</td>\n",
              "      <td>40.13</td>\n",
              "      <td>46.89</td>\n",
              "      <td>20.01</td>\n",
              "      <td>114.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>120.10</td>\n",
              "      <td>199.64</td>\n",
              "      <td>81.49</td>\n",
              "      <td>31.89</td>\n",
              "      <td>55.02</td>\n",
              "      <td>19.16</td>\n",
              "      <td>39.94</td>\n",
              "      <td>47.59</td>\n",
              "      <td>20.12</td>\n",
              "      <td>113.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2516</th>\n",
              "      <td>317.31</td>\n",
              "      <td>1385.04</td>\n",
              "      <td>199.14</td>\n",
              "      <td>273.02</td>\n",
              "      <td>52.11</td>\n",
              "      <td>89.45</td>\n",
              "      <td>151.54</td>\n",
              "      <td>390.13</td>\n",
              "      <td>88.25</td>\n",
              "      <td>35.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2517</th>\n",
              "      <td>317.20</td>\n",
              "      <td>1358.01</td>\n",
              "      <td>202.59</td>\n",
              "      <td>277.45</td>\n",
              "      <td>52.73</td>\n",
              "      <td>90.93</td>\n",
              "      <td>152.39</td>\n",
              "      <td>394.03</td>\n",
              "      <td>87.56</td>\n",
              "      <td>35.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2518</th>\n",
              "      <td>312.31</td>\n",
              "      <td>1315.00</td>\n",
              "      <td>198.29</td>\n",
              "      <td>281.23</td>\n",
              "      <td>52.71</td>\n",
              "      <td>92.28</td>\n",
              "      <td>153.92</td>\n",
              "      <td>375.70</td>\n",
              "      <td>89.54</td>\n",
              "      <td>36.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2519</th>\n",
              "      <td>312.45</td>\n",
              "      <td>1319.59</td>\n",
              "      <td>200.78</td>\n",
              "      <td>282.77</td>\n",
              "      <td>52.26</td>\n",
              "      <td>93.49</td>\n",
              "      <td>155.26</td>\n",
              "      <td>368.33</td>\n",
              "      <td>91.36</td>\n",
              "      <td>35.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2520</th>\n",
              "      <td>314.02</td>\n",
              "      <td>1313.26</td>\n",
              "      <td>204.65</td>\n",
              "      <td>288.71</td>\n",
              "      <td>52.97</td>\n",
              "      <td>94.15</td>\n",
              "      <td>156.17</td>\n",
              "      <td>352.78</td>\n",
              "      <td>92.05</td>\n",
              "      <td>34.59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2520 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce4770ec-49a9-4705-aa38-2c7f4f84caca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce4770ec-49a9-4705-aa38-2c7f4f84caca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce4770ec-49a9-4705-aa38-2c7f4f84caca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assets.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "gDg1XGt6OT-m",
        "outputId": "eab2ce56-c7c9-40e0-9ff3-d66c66998d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_df = assets.corr(method='pearson')\n",
        "#reset symbol as index (rather than 0-X)\n",
        "corr_df.head().reset_index()\n",
        "#del corr_df.index.name\n",
        "corr_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "FXpNiz-FPw7G",
        "outputId": "0071ae36-6bdc-4e8c-a2de-04e4ad45aedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          A         B         C         D         E         F         G  \\\n",
              "A  1.000000  0.907763  0.876312  0.977546 -0.585680  0.976689  0.947130   \n",
              "B  0.907763  1.000000  0.952322  0.949021 -0.563379  0.902734  0.934653   \n",
              "C  0.876312  0.952322  1.000000  0.913316 -0.602664  0.896976  0.937151   \n",
              "D  0.977546  0.949021  0.913316  1.000000 -0.606136  0.979219  0.970006   \n",
              "E -0.585680 -0.563379 -0.602664 -0.606136  1.000000 -0.627725 -0.640013   \n",
              "F  0.976689  0.902734  0.896976  0.979219 -0.627725  1.000000  0.966342   \n",
              "G  0.947130  0.934653  0.937151  0.970006 -0.640013  0.966342  1.000000   \n",
              "H  0.588398  0.756198  0.680581  0.656929 -0.043075  0.564128  0.614272   \n",
              "I  0.931284  0.960922  0.907120  0.952789 -0.656586  0.920264  0.924578   \n",
              "J -0.796871 -0.863604 -0.822143 -0.851680  0.772634 -0.810844 -0.839205   \n",
              "\n",
              "          H         I         J  \n",
              "A  0.588398  0.931284 -0.796871  \n",
              "B  0.756198  0.960922 -0.863604  \n",
              "C  0.680581  0.907120 -0.822143  \n",
              "D  0.656929  0.952789 -0.851680  \n",
              "E -0.043075 -0.656586  0.772634  \n",
              "F  0.564128  0.920264 -0.810844  \n",
              "G  0.614272  0.924578 -0.839205  \n",
              "H  1.000000  0.656634 -0.550657  \n",
              "I  0.656634  1.000000 -0.887359  \n",
              "J -0.550657 -0.887359  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-364fd45f-25fd-4ff7-8e95-6197110002e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.907763</td>\n",
              "      <td>0.876312</td>\n",
              "      <td>0.977546</td>\n",
              "      <td>-0.585680</td>\n",
              "      <td>0.976689</td>\n",
              "      <td>0.947130</td>\n",
              "      <td>0.588398</td>\n",
              "      <td>0.931284</td>\n",
              "      <td>-0.796871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>0.907763</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.952322</td>\n",
              "      <td>0.949021</td>\n",
              "      <td>-0.563379</td>\n",
              "      <td>0.902734</td>\n",
              "      <td>0.934653</td>\n",
              "      <td>0.756198</td>\n",
              "      <td>0.960922</td>\n",
              "      <td>-0.863604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <td>0.876312</td>\n",
              "      <td>0.952322</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.913316</td>\n",
              "      <td>-0.602664</td>\n",
              "      <td>0.896976</td>\n",
              "      <td>0.937151</td>\n",
              "      <td>0.680581</td>\n",
              "      <td>0.907120</td>\n",
              "      <td>-0.822143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <td>0.977546</td>\n",
              "      <td>0.949021</td>\n",
              "      <td>0.913316</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.606136</td>\n",
              "      <td>0.979219</td>\n",
              "      <td>0.970006</td>\n",
              "      <td>0.656929</td>\n",
              "      <td>0.952789</td>\n",
              "      <td>-0.851680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E</th>\n",
              "      <td>-0.585680</td>\n",
              "      <td>-0.563379</td>\n",
              "      <td>-0.602664</td>\n",
              "      <td>-0.606136</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.627725</td>\n",
              "      <td>-0.640013</td>\n",
              "      <td>-0.043075</td>\n",
              "      <td>-0.656586</td>\n",
              "      <td>0.772634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F</th>\n",
              "      <td>0.976689</td>\n",
              "      <td>0.902734</td>\n",
              "      <td>0.896976</td>\n",
              "      <td>0.979219</td>\n",
              "      <td>-0.627725</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.966342</td>\n",
              "      <td>0.564128</td>\n",
              "      <td>0.920264</td>\n",
              "      <td>-0.810844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G</th>\n",
              "      <td>0.947130</td>\n",
              "      <td>0.934653</td>\n",
              "      <td>0.937151</td>\n",
              "      <td>0.970006</td>\n",
              "      <td>-0.640013</td>\n",
              "      <td>0.966342</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.614272</td>\n",
              "      <td>0.924578</td>\n",
              "      <td>-0.839205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H</th>\n",
              "      <td>0.588398</td>\n",
              "      <td>0.756198</td>\n",
              "      <td>0.680581</td>\n",
              "      <td>0.656929</td>\n",
              "      <td>-0.043075</td>\n",
              "      <td>0.564128</td>\n",
              "      <td>0.614272</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.656634</td>\n",
              "      <td>-0.550657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I</th>\n",
              "      <td>0.931284</td>\n",
              "      <td>0.960922</td>\n",
              "      <td>0.907120</td>\n",
              "      <td>0.952789</td>\n",
              "      <td>-0.656586</td>\n",
              "      <td>0.920264</td>\n",
              "      <td>0.924578</td>\n",
              "      <td>0.656634</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.887359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>J</th>\n",
              "      <td>-0.796871</td>\n",
              "      <td>-0.863604</td>\n",
              "      <td>-0.822143</td>\n",
              "      <td>-0.851680</td>\n",
              "      <td>0.772634</td>\n",
              "      <td>-0.810844</td>\n",
              "      <td>-0.839205</td>\n",
              "      <td>-0.550657</td>\n",
              "      <td>-0.887359</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-364fd45f-25fd-4ff7-8e95-6197110002e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-364fd45f-25fd-4ff7-8e95-6197110002e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-364fd45f-25fd-4ff7-8e95-6197110002e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 6))\n",
        "seaborn.heatmap(corr_df, annot=True, cmap='RdYlGn')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "5GqFIoOtQG0z",
        "outputId": "4b39d47d-fc3a-4f86-d998-b89c76266c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different Types of Optimizers and Allocating Methods\n",
        "What we want is a high sharpe ratio."
      ],
      "metadata": {
        "id": "DONJr5CnIDJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean-Variance Optimization"
      ],
      "metadata": {
        "id": "CJ9lvnbg3poa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = assets\n",
        "# Calculate expected returns and covariance matrix\n",
        "returns = data.pct_change().mean() * 252\n",
        "cov_matrix = data.pct_change().cov() * 252"
      ],
      "metadata": {
        "id": "wUzoyo-ckFyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_portfolio(returns, cov_matrix):\n",
        "    \"\"\"\n",
        "    Optimize portfolio allocation using mean-variance optimization\n",
        "    \"\"\"\n",
        "    n_assets = len(returns)\n",
        "    args = (returns, cov_matrix)\n",
        "\n",
        "    def portfolio_variance(weights, returns, cov_matrix):\n",
        "        \"\"\"\n",
        "        Calculate portfolio variance given weights\n",
        "        \"\"\"\n",
        "        return np.dot(weights.T, np.dot(cov_matrix, weights))\n",
        "\n",
        "    def portfolio_return(weights, returns, cov_matrix):\n",
        "        \"\"\"\n",
        "        Calculate portfolio return given weights\n",
        "        \"\"\"\n",
        "        return np.dot(weights.T, returns)\n",
        "\n",
        "    # Constraints\n",
        "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
        "\n",
        "    # Bounds\n",
        "    bounds = tuple((0, 1) for _ in range(n_assets))\n",
        "\n",
        "    # Initial guess (equal allocation)\n",
        "    init_guess = np.ones(n_assets) / n_assets\n",
        "\n",
        "    # Optimization\n",
        "    result = minimize(portfolio_variance, init_guess, args=args,\n",
        "                      method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "    if not result.success:\n",
        "        raise ValueError(\"Optimization failed: {}\".format(result.message))\n",
        "\n",
        "    return result.x"
      ],
      "metadata": {
        "id": "sE_PFlg61jvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get optimal portfolio weights\n",
        "weights = optimize_portfolio(returns, cov_matrix)\n",
        "\n",
        "# Print portfolio allocation\n",
        "print(\"Portfolio allocation:\")\n",
        "for i, weight in enumerate(weights):\n",
        "    print(\"Asset {}: {:.2f}%\".format(i+1, weight*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP5Cxdi71la9",
        "outputId": "d1cbd6af-df23-4c73-b388-d6d560046540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portfolio allocation:\n",
            "Asset 1: 3.86%\n",
            "Asset 2: 15.35%\n",
            "Asset 3: 28.52%\n",
            "Asset 4: 8.01%\n",
            "Asset 5: 12.72%\n",
            "Asset 6: 0.00%\n",
            "Asset 7: 0.41%\n",
            "Asset 8: 7.64%\n",
            "Asset 9: 21.21%\n",
            "Asset 10: 2.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimum Variance Optimization\n",
        "This implementation solves the quadratic optimization problem. The objective is to minimize the portfolio risk, subject to the constraint that the weights sum to one and are non-negative.\n",
        "\n",
        "The resulting weights represent the minimum variance portfolio allocation, which should have the lowest possible portfolio volatility or risk, subject to the constraints."
      ],
      "metadata": {
        "id": "s9ZjUhqf3xR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate expected returns and covariance matrix\n",
        "returns = data.pct_change().mean()\n",
        "cov_matrix = data.pct_change().cov()\n",
        "\n",
        "# Define optimization problem\n",
        "n_assets = len(returns)\n",
        "weights = cp.Variable(n_assets)\n",
        "risk = cp.quad_form(weights, cov_matrix)\n",
        "constraints = [cp.sum(weights) == 1, weights >= 0]\n",
        "objective = cp.Minimize(risk)\n",
        "problem = cp.Problem(objective, constraints)\n",
        "\n",
        "# Solve optimization problem\n",
        "problem.solve()\n",
        "\n",
        "# Print results\n",
        "print(\"Minimum variance portfolio allocation:\")\n",
        "for i, weight in enumerate(weights.value):\n",
        "    print(\"Asset {}: {:.2f}%\".format(i+1, weight*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdOXbRYG1nkK",
        "outputId": "cc518734-2233-4e78-cc55-0119c7d1750e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum variance portfolio allocation:\n",
            "Asset 1: 3.49%\n",
            "Asset 2: 15.29%\n",
            "Asset 3: 28.46%\n",
            "Asset 4: 8.68%\n",
            "Asset 5: 12.49%\n",
            "Asset 6: 0.00%\n",
            "Asset 7: 0.04%\n",
            "Asset 8: 7.75%\n",
            "Asset 9: 21.41%\n",
            "Asset 10: 2.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Risk Parity Allocation\n",
        "In this implementation, we calculate the asset weights based on the inverse of the volatility of each asset, rather than their expected returns. The idea is to weight the assets in proportion to their contribution to the overall portfolio risk, rather than their expected returns.\n",
        "\n",
        "We then normalize the weights so that they sum to one, which ensures that the portfolio is fully invested.\n",
        "\n",
        "The resulting weights represent the risk parity portfolio allocation, which should have a more balanced risk profile and be less sensitive to any one asset class or market factor."
      ],
      "metadata": {
        "id": "CHXmLoIz4DsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate asset weights based on inverse volatility\n",
        "weights = 1 / np.sqrt(data.pct_change().var())\n",
        "\n",
        "# Normalize weights to sum to 1\n",
        "weights /= np.sum(weights)\n",
        "\n",
        "# Print results\n",
        "print(\"Risk parity portfolio allocation:\")\n",
        "for i, weight in enumerate(weights):\n",
        "    print(\"Asset {}: {:.2f}%\".format(i+1, weight*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Avejg54GEo",
        "outputId": "7386bc0c-cbbf-4c94-8579-d886ccf1f023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risk parity portfolio allocation:\n",
            "Asset 1: 10.26%\n",
            "Asset 2: 13.03%\n",
            "Asset 3: 14.09%\n",
            "Asset 4: 9.66%\n",
            "Asset 5: 9.92%\n",
            "Asset 6: 6.97%\n",
            "Asset 7: 8.93%\n",
            "Asset 8: 6.24%\n",
            "Asset 9: 12.95%\n",
            "Asset 10: 7.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tactical Asset Allocation\n",
        "We define the long and short moving averages and calculate them using the rolling() method of the DataFrame object.\n",
        "\n",
        "Next, we create signals based on the moving average crossover. We use a DataFrame object called signals to store the signals, where each cell can take one of three values: 1 (long signal), -1 (short signal), or 0 (no signal).\n",
        "\n",
        "We then use the signals to calculate the asset allocation weights. We shift the signals by one day so that we use yesterday's signals to make today's allocation. We start with zero weights on the first day, and normalize the weights so that they sum to 1 for each day.\n",
        "\n",
        "Finally, we calculate the portfolio returns by multiplying the asset returns by the weights and summing across assets. We calculate the cumulative returns by taking the cumulative product of the portfolio returns.\n",
        "\n",
        "This implementation uses Moving Average Crossover as an example strategy."
      ],
      "metadata": {
        "id": "pyjXkFX59LiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the long and short moving averages\n",
        "long_ma = 200\n",
        "short_ma = 50\n",
        "\n",
        "# Calculate the moving averages\n",
        "ma_long = data.rolling(long_ma).mean()\n",
        "ma_short = data.rolling(short_ma).mean()\n",
        "\n",
        "# Create signals based on the moving average crossover\n",
        "signals = pd.DataFrame(0, index=data.index, columns=data.columns)\n",
        "signals[ma_short > ma_long] = 1\n",
        "signals[ma_short <= ma_long] = -1\n",
        "\n",
        "# Calculate the asset allocation weights\n",
        "weights = signals.shift(1)  # Use yesterday's signals to make today's allocation\n",
        "weights.iloc[0, :] = 0  # Start with zero weights\n",
        "weights = weights.div(np.abs(weights).sum(axis=1), axis=0)  # Normalize to sum to 1\n",
        "\n",
        "# Calculate the portfolio returns\n",
        "returns = data.pct_change()\n",
        "portfolio_returns = (weights * returns).sum(axis=1)\n",
        "\n",
        "# Calculate the cumulative returns\n",
        "cumulative_returns = (1 + portfolio_returns).cumprod()\n",
        "\n",
        "# Plot the results\n",
        "cumulative_returns.plot( title='Tactical Asset Allocation')\n",
        "sharpe_ratio = np.sqrt(252) * portfolio_returns.mean() / portfolio_returns.std()\n",
        "print(sharpe_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "TnSLzuZE45jO",
        "outputId": "1f515463-1149-4b19-9fd7-565d1963542d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.41024372664996867\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TAA using relative strength"
      ],
      "metadata": {
        "id": "HFtNMcFhDbDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define lookback periods\n",
        "lookback_short = 20\n",
        "lookback_long = 50\n",
        "\n",
        "# Initialize portfolio weights\n",
        "weights = pd.DataFrame(columns=assets.columns, index=assets.index)\n",
        "\n",
        "# Iterate over each day\n",
        "for i in range(lookback_long, len(assets)):\n",
        "\n",
        "    # Calculate returns over lookback periods\n",
        "    returns_short = assets.iloc[i-lookback_short:i].pct_change().dropna()\n",
        "    returns_long = assets.iloc[i-lookback_long:i].pct_change().dropna()\n",
        "\n",
        "    # Calculate relative strength\n",
        "    relative_strength = returns_short.mean() / returns_long.mean()\n",
        "\n",
        "    # Calculate weights based on relative strength\n",
        "    weights.iloc[i] = relative_strength / relative_strength.sum()\n",
        "\n",
        "# Add a small constant to avoid division by zero\n",
        "weights_sum = weights.sum(axis=1) + 1e-6\n",
        "\n",
        "# Normalize weights\n",
        "weights = weights.div(weights_sum, axis=0)\n",
        "\n",
        "# Calculate daily portfolio returns\n",
        "portfolio_returns = (weights.shift(1) * assets.pct_change()).sum(axis=1)\n",
        "plt.plot(portfolio_returns)\n",
        "\n",
        "# Calculate performance metrics\n",
        "sharpe_ratio = np.sqrt(252) * portfolio_returns.mean() / portfolio_returns.std()\n",
        "annual_return = (1 + portfolio_returns.mean())**252 - 1\n",
        "max_drawdown = (portfolio_returns / (1 + portfolio_returns)).cumprod().cummax() - 1\n",
        "\n",
        "print(f'Sharpe ratio: {sharpe_ratio:.2f}')\n",
        "print(f'Annual return: {annual_return:.2f}')\n",
        "print(f'Max drawdown: {max_drawdown.min():.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "EvG_pOE4-xCK",
        "outputId": "4b26d897-1d54-4c2e-cb22-e2c2b6d0068e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe ratio: 0.39\n",
            "Annual return: 146.61\n",
            "Max drawdown: -1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Momentum-based TAA Strategy"
      ],
      "metadata": {
        "id": "Qz8WAJrhDCRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define lookback periods\n",
        "lookback_short = 20\n",
        "lookback_long = 50\n",
        "\n",
        "# Initialize portfolio weights\n",
        "weights = pd.DataFrame(columns=assets.columns, index=assets.index)\n",
        "\n",
        "# Iterate over each day\n",
        "for i in range(lookback_long, len(assets)):\n",
        "\n",
        "    # Calculate returns over lookback periods\n",
        "    returns_short = assets.iloc[i-lookback_short:i].pct_change().dropna()\n",
        "    returns_long = assets.iloc[i-lookback_long:i].pct_change().dropna()\n",
        "\n",
        "    # Calculate momentum\n",
        "    momentum = returns_short.sum() / abs(returns_short).sum() - returns_long.sum() / abs(returns_long).sum()\n",
        "\n",
        "    # Calculate weights based on momentum\n",
        "    weights.iloc[i] = momentum / momentum.sum()\n",
        "\n",
        "# Add a small constant to avoid division by zero\n",
        "weights_sum = weights.sum(axis=1) + 1e-6\n",
        "\n",
        "# Normalize weights\n",
        "weights = weights.div(weights_sum, axis=0)\n",
        "\n",
        "# Calculate daily portfolio returns\n",
        "portfolio_returns = (weights.shift(1) * assets.pct_change()).sum(axis=1)\n",
        "plt.plot(portfolio_returns)\n",
        "\n",
        "# Calculate performance metrics\n",
        "sharpe_ratio = np.sqrt(252) * portfolio_returns.mean() / portfolio_returns.std()\n",
        "annual_return = (1 + portfolio_returns.mean())**252 - 1\n",
        "max_drawdown = (portfolio_returns / (1 + portfolio_returns)).cumprod().cummax() - 1\n",
        "\n",
        "print(f'Sharpe ratio: {sharpe_ratio:.2f}')\n",
        "print(f'Annual return: {annual_return:.2f}')\n",
        "print(f'Max drawdown: {max_drawdown.min():.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "IcXT4Q9t-8Qu",
        "outputId": "174c10f5-4e0c-49a0-8596-6b52b1306375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe ratio: 0.19\n",
            "Annual return: 31.88\n",
            "Max drawdown: -1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network"
      ],
      "metadata": {
        "id": "z4oSRBpKH69S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = assets\n",
        "\n",
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Train the neural network\n",
        "net = Net()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    inputs = torch.tensor(data[:-1].values, dtype=torch.float32)\n",
        "    targets = torch.tensor(data[1:].values, dtype=torch.float32)\n",
        "\n",
        "    print(net(inputs))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch: %d, Loss: %.6f' % (epoch+1, loss.item()))\n",
        "\n",
        "# Use the trained neural network to make predictions\n",
        "with torch.no_grad():\n",
        "    inputs = torch.tensor(data.values, dtype=torch.float32)\n",
        "    outputs = net(inputs)\n",
        "    predictions = outputs.numpy()\n",
        "\n",
        "# Calculate daily returns and annualized volatility\n",
        "returns = np.diff(data.values, axis=0) / data.values[:-1]\n",
        "volatility = np.std(returns, axis=0) * np.sqrt(252)\n",
        "\n",
        "\n",
        "# Use the predictions to optimize portfolio weights\n",
        "weights = np.zeros(10)\n",
        "for i in range(10):\n",
        "    weights[i] = predictions[-1, i] / volatility[i]\n",
        "\n",
        "weights = weights / np.sum(weights)\n",
        "\n",
        "# Print the optimized weights and Sharpe Ratio\n",
        "print('Optimized Weights:', weights)\n",
        "print('Sharpe Ratio:', np.dot(returns[-1], weights) / np.std(returns[-1]) * np.sqrt(252))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGLLQL63BS_7",
        "outputId": "99a292b1-2c4c-470a-d872-aeab73ffe09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "tensor([[ 3.3893, -1.1421, -0.4926,  ..., -4.1014, -1.7597,  0.7981],\n",
            "        [ 3.3893, -1.1421, -0.4926,  ..., -4.1014, -1.7597,  0.7981],\n",
            "        [ 3.3893, -1.1421, -0.4926,  ..., -4.1014, -1.7597,  0.7981],\n",
            "        ...,\n",
            "        [ 3.3893, -1.1421, -0.4926,  ..., -4.1014, -1.7597,  0.7981],\n",
            "        [ 3.3893, -1.1421, -0.4926,  ..., -4.1014, -1.7597,  0.7981],\n",
            "        [ 3.3893, -1.1421, -0.4926,  ..., -4.1014, -1.7597,  0.7981]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 448, Loss: 67376.562500\n",
            "tensor([[ 3.4305, -1.0182, -0.4707,  ..., -4.0670, -1.7491,  0.8117],\n",
            "        [ 3.4305, -1.0182, -0.4707,  ..., -4.0670, -1.7491,  0.8117],\n",
            "        [ 3.4305, -1.0182, -0.4707,  ..., -4.0670, -1.7491,  0.8117],\n",
            "        ...,\n",
            "        [ 3.4305, -1.0182, -0.4707,  ..., -4.0670, -1.7491,  0.8117],\n",
            "        [ 3.4305, -1.0182, -0.4707,  ..., -4.0670, -1.7491,  0.8117],\n",
            "        [ 3.4305, -1.0182, -0.4707,  ..., -4.0670, -1.7491,  0.8117]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 449, Loss: 67356.437500\n",
            "tensor([[ 3.4716, -0.8944, -0.4489,  ..., -4.0327, -1.7386,  0.8254],\n",
            "        [ 3.4716, -0.8944, -0.4489,  ..., -4.0327, -1.7386,  0.8254],\n",
            "        [ 3.4716, -0.8944, -0.4489,  ..., -4.0327, -1.7386,  0.8254],\n",
            "        ...,\n",
            "        [ 3.4716, -0.8944, -0.4489,  ..., -4.0327, -1.7386,  0.8254],\n",
            "        [ 3.4716, -0.8944, -0.4489,  ..., -4.0327, -1.7386,  0.8254],\n",
            "        [ 3.4716, -0.8944, -0.4489,  ..., -4.0327, -1.7386,  0.8254]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 450, Loss: 67336.304688\n",
            "tensor([[ 3.5127, -0.7706, -0.4271,  ..., -3.9983, -1.7280,  0.8390],\n",
            "        [ 3.5127, -0.7706, -0.4271,  ..., -3.9983, -1.7280,  0.8390],\n",
            "        [ 3.5127, -0.7706, -0.4271,  ..., -3.9983, -1.7280,  0.8390],\n",
            "        ...,\n",
            "        [ 3.5127, -0.7706, -0.4271,  ..., -3.9983, -1.7280,  0.8390],\n",
            "        [ 3.5127, -0.7706, -0.4271,  ..., -3.9983, -1.7280,  0.8390],\n",
            "        [ 3.5127, -0.7706, -0.4271,  ..., -3.9983, -1.7280,  0.8390]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 451, Loss: 67316.195312\n",
            "tensor([[ 3.5538, -0.6468, -0.4053,  ..., -3.9639, -1.7174,  0.8526],\n",
            "        [ 3.5538, -0.6468, -0.4053,  ..., -3.9639, -1.7174,  0.8526],\n",
            "        [ 3.5538, -0.6468, -0.4053,  ..., -3.9639, -1.7174,  0.8526],\n",
            "        ...,\n",
            "        [ 3.5538, -0.6468, -0.4053,  ..., -3.9639, -1.7174,  0.8526],\n",
            "        [ 3.5538, -0.6468, -0.4053,  ..., -3.9639, -1.7174,  0.8526],\n",
            "        [ 3.5538, -0.6468, -0.4053,  ..., -3.9639, -1.7174,  0.8526]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 452, Loss: 67296.101562\n",
            "tensor([[ 3.5949, -0.5230, -0.3834,  ..., -3.9296, -1.7068,  0.8663],\n",
            "        [ 3.5949, -0.5230, -0.3834,  ..., -3.9296, -1.7068,  0.8663],\n",
            "        [ 3.5949, -0.5230, -0.3834,  ..., -3.9296, -1.7068,  0.8663],\n",
            "        ...,\n",
            "        [ 3.5949, -0.5230, -0.3834,  ..., -3.9296, -1.7068,  0.8663],\n",
            "        [ 3.5949, -0.5230, -0.3834,  ..., -3.9296, -1.7068,  0.8663],\n",
            "        [ 3.5949, -0.5230, -0.3834,  ..., -3.9296, -1.7068,  0.8663]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 453, Loss: 67276.000000\n",
            "tensor([[ 3.6360, -0.3993, -0.3616,  ..., -3.8953, -1.6963,  0.8799],\n",
            "        [ 3.6360, -0.3993, -0.3616,  ..., -3.8953, -1.6963,  0.8799],\n",
            "        [ 3.6360, -0.3993, -0.3616,  ..., -3.8953, -1.6963,  0.8799],\n",
            "        ...,\n",
            "        [ 3.6360, -0.3993, -0.3616,  ..., -3.8953, -1.6963,  0.8799],\n",
            "        [ 3.6360, -0.3993, -0.3616,  ..., -3.8953, -1.6963,  0.8799],\n",
            "        [ 3.6360, -0.3993, -0.3616,  ..., -3.8953, -1.6963,  0.8799]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 454, Loss: 67255.914062\n",
            "tensor([[ 3.6770, -0.2756, -0.3398,  ..., -3.8609, -1.6857,  0.8935],\n",
            "        [ 3.6770, -0.2756, -0.3398,  ..., -3.8609, -1.6857,  0.8935],\n",
            "        [ 3.6770, -0.2756, -0.3398,  ..., -3.8609, -1.6857,  0.8935],\n",
            "        ...,\n",
            "        [ 3.6770, -0.2756, -0.3398,  ..., -3.8609, -1.6857,  0.8935],\n",
            "        [ 3.6770, -0.2756, -0.3398,  ..., -3.8609, -1.6857,  0.8935],\n",
            "        [ 3.6770, -0.2756, -0.3398,  ..., -3.8609, -1.6857,  0.8935]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 455, Loss: 67235.828125\n",
            "tensor([[ 3.7181, -0.1519, -0.3180,  ..., -3.8266, -1.6751,  0.9072],\n",
            "        [ 3.7181, -0.1519, -0.3180,  ..., -3.8266, -1.6751,  0.9072],\n",
            "        [ 3.7181, -0.1519, -0.3180,  ..., -3.8266, -1.6751,  0.9072],\n",
            "        ...,\n",
            "        [ 3.7181, -0.1519, -0.3180,  ..., -3.8266, -1.6751,  0.9072],\n",
            "        [ 3.7181, -0.1519, -0.3180,  ..., -3.8266, -1.6751,  0.9072],\n",
            "        [ 3.7181, -0.1519, -0.3180,  ..., -3.8266, -1.6751,  0.9072]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 456, Loss: 67215.757812\n",
            "tensor([[ 3.7591, -0.0282, -0.2962,  ..., -3.7923, -1.6645,  0.9208],\n",
            "        [ 3.7591, -0.0282, -0.2962,  ..., -3.7923, -1.6645,  0.9208],\n",
            "        [ 3.7591, -0.0282, -0.2962,  ..., -3.7923, -1.6645,  0.9208],\n",
            "        ...,\n",
            "        [ 3.7591, -0.0282, -0.2962,  ..., -3.7923, -1.6645,  0.9208],\n",
            "        [ 3.7591, -0.0282, -0.2962,  ..., -3.7923, -1.6645,  0.9208],\n",
            "        [ 3.7591, -0.0282, -0.2962,  ..., -3.7923, -1.6645,  0.9208]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 457, Loss: 67195.687500\n",
            "tensor([[ 3.8002,  0.0954, -0.2744,  ..., -3.7580, -1.6540,  0.9344],\n",
            "        [ 3.8002,  0.0954, -0.2744,  ..., -3.7580, -1.6540,  0.9344],\n",
            "        [ 3.8002,  0.0954, -0.2744,  ..., -3.7580, -1.6540,  0.9344],\n",
            "        ...,\n",
            "        [ 3.8002,  0.0954, -0.2744,  ..., -3.7580, -1.6540,  0.9344],\n",
            "        [ 3.8002,  0.0954, -0.2744,  ..., -3.7580, -1.6540,  0.9344],\n",
            "        [ 3.8002,  0.0954, -0.2744,  ..., -3.7580, -1.6540,  0.9344]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 458, Loss: 67175.632812\n",
            "tensor([[ 3.8412,  0.2190, -0.2526,  ..., -3.7237, -1.6434,  0.9480],\n",
            "        [ 3.8412,  0.2190, -0.2526,  ..., -3.7237, -1.6434,  0.9480],\n",
            "        [ 3.8412,  0.2190, -0.2526,  ..., -3.7237, -1.6434,  0.9480],\n",
            "        ...,\n",
            "        [ 3.8412,  0.2190, -0.2526,  ..., -3.7237, -1.6434,  0.9480],\n",
            "        [ 3.8412,  0.2190, -0.2526,  ..., -3.7237, -1.6434,  0.9480],\n",
            "        [ 3.8412,  0.2190, -0.2526,  ..., -3.7237, -1.6434,  0.9480]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 459, Loss: 67155.578125\n",
            "tensor([[ 3.8823,  0.3426, -0.2308,  ..., -3.6894, -1.6329,  0.9617],\n",
            "        [ 3.8823,  0.3426, -0.2308,  ..., -3.6894, -1.6329,  0.9617],\n",
            "        [ 3.8823,  0.3426, -0.2308,  ..., -3.6894, -1.6329,  0.9617],\n",
            "        ...,\n",
            "        [ 3.8823,  0.3426, -0.2308,  ..., -3.6894, -1.6329,  0.9617],\n",
            "        [ 3.8823,  0.3426, -0.2308,  ..., -3.6894, -1.6329,  0.9617],\n",
            "        [ 3.8823,  0.3426, -0.2308,  ..., -3.6894, -1.6329,  0.9617]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 460, Loss: 67135.546875\n",
            "tensor([[ 3.9233,  0.4661, -0.2090,  ..., -3.6551, -1.6223,  0.9753],\n",
            "        [ 3.9233,  0.4661, -0.2090,  ..., -3.6551, -1.6223,  0.9753],\n",
            "        [ 3.9233,  0.4661, -0.2090,  ..., -3.6551, -1.6223,  0.9753],\n",
            "        ...,\n",
            "        [ 3.9233,  0.4661, -0.2090,  ..., -3.6551, -1.6223,  0.9753],\n",
            "        [ 3.9233,  0.4661, -0.2090,  ..., -3.6551, -1.6223,  0.9753],\n",
            "        [ 3.9233,  0.4661, -0.2090,  ..., -3.6551, -1.6223,  0.9753]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 461, Loss: 67115.515625\n",
            "tensor([[ 3.9643,  0.5897, -0.1873,  ..., -3.6208, -1.6117,  0.9889],\n",
            "        [ 3.9643,  0.5897, -0.1873,  ..., -3.6208, -1.6117,  0.9889],\n",
            "        [ 3.9643,  0.5897, -0.1873,  ..., -3.6208, -1.6117,  0.9889],\n",
            "        ...,\n",
            "        [ 3.9643,  0.5897, -0.1873,  ..., -3.6208, -1.6117,  0.9889],\n",
            "        [ 3.9643,  0.5897, -0.1873,  ..., -3.6208, -1.6117,  0.9889],\n",
            "        [ 3.9643,  0.5897, -0.1873,  ..., -3.6208, -1.6117,  0.9889]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 462, Loss: 67095.484375\n",
            "tensor([[ 4.0053,  0.7132, -0.1655,  ..., -3.5865, -1.6012,  1.0025],\n",
            "        [ 4.0053,  0.7132, -0.1655,  ..., -3.5865, -1.6012,  1.0025],\n",
            "        [ 4.0053,  0.7132, -0.1655,  ..., -3.5865, -1.6012,  1.0025],\n",
            "        ...,\n",
            "        [ 4.0053,  0.7132, -0.1655,  ..., -3.5865, -1.6012,  1.0025],\n",
            "        [ 4.0053,  0.7132, -0.1655,  ..., -3.5865, -1.6012,  1.0025],\n",
            "        [ 4.0053,  0.7132, -0.1655,  ..., -3.5865, -1.6012,  1.0025]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 463, Loss: 67075.476562\n",
            "tensor([[ 4.0463,  0.8367, -0.1437,  ..., -3.5522, -1.5906,  1.0161],\n",
            "        [ 4.0463,  0.8367, -0.1437,  ..., -3.5522, -1.5906,  1.0161],\n",
            "        [ 4.0463,  0.8367, -0.1437,  ..., -3.5522, -1.5906,  1.0161],\n",
            "        ...,\n",
            "        [ 4.0463,  0.8367, -0.1437,  ..., -3.5522, -1.5906,  1.0161],\n",
            "        [ 4.0463,  0.8367, -0.1437,  ..., -3.5522, -1.5906,  1.0161],\n",
            "        [ 4.0463,  0.8367, -0.1437,  ..., -3.5522, -1.5906,  1.0161]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 464, Loss: 67055.468750\n",
            "tensor([[ 4.0873,  0.9601, -0.1220,  ..., -3.5180, -1.5801,  1.0297],\n",
            "        [ 4.0873,  0.9601, -0.1220,  ..., -3.5180, -1.5801,  1.0297],\n",
            "        [ 4.0873,  0.9601, -0.1220,  ..., -3.5180, -1.5801,  1.0297],\n",
            "        ...,\n",
            "        [ 4.0873,  0.9601, -0.1220,  ..., -3.5180, -1.5801,  1.0297],\n",
            "        [ 4.0873,  0.9601, -0.1220,  ..., -3.5180, -1.5801,  1.0297],\n",
            "        [ 4.0873,  0.9601, -0.1220,  ..., -3.5180, -1.5801,  1.0297]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 465, Loss: 67035.468750\n",
            "tensor([[ 4.1283,  1.0836, -0.1002,  ..., -3.4837, -1.5695,  1.0433],\n",
            "        [ 4.1283,  1.0836, -0.1002,  ..., -3.4837, -1.5695,  1.0433],\n",
            "        [ 4.1283,  1.0836, -0.1002,  ..., -3.4837, -1.5695,  1.0433],\n",
            "        ...,\n",
            "        [ 4.1283,  1.0836, -0.1002,  ..., -3.4837, -1.5695,  1.0433],\n",
            "        [ 4.1283,  1.0836, -0.1002,  ..., -3.4837, -1.5695,  1.0433],\n",
            "        [ 4.1283,  1.0836, -0.1002,  ..., -3.4837, -1.5695,  1.0433]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 466, Loss: 67015.468750\n",
            "tensor([[ 4.1693,  1.2070, -0.0784,  ..., -3.4495, -1.5590,  1.0569],\n",
            "        [ 4.1693,  1.2070, -0.0784,  ..., -3.4495, -1.5590,  1.0569],\n",
            "        [ 4.1693,  1.2070, -0.0784,  ..., -3.4495, -1.5590,  1.0569],\n",
            "        ...,\n",
            "        [ 4.1693,  1.2070, -0.0784,  ..., -3.4495, -1.5590,  1.0569],\n",
            "        [ 4.1693,  1.2070, -0.0784,  ..., -3.4495, -1.5590,  1.0569],\n",
            "        [ 4.1693,  1.2070, -0.0784,  ..., -3.4495, -1.5590,  1.0569]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 467, Loss: 66995.484375\n",
            "tensor([[ 4.2102,  1.3304, -0.0567,  ..., -3.4152, -1.5484,  1.0705],\n",
            "        [ 4.2102,  1.3304, -0.0567,  ..., -3.4152, -1.5484,  1.0705],\n",
            "        [ 4.2102,  1.3304, -0.0567,  ..., -3.4152, -1.5484,  1.0705],\n",
            "        ...,\n",
            "        [ 4.2102,  1.3304, -0.0567,  ..., -3.4152, -1.5484,  1.0705],\n",
            "        [ 4.2102,  1.3304, -0.0567,  ..., -3.4152, -1.5484,  1.0705],\n",
            "        [ 4.2102,  1.3304, -0.0567,  ..., -3.4152, -1.5484,  1.0705]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 468, Loss: 66975.515625\n",
            "tensor([[ 4.2512,  1.4537, -0.0349,  ..., -3.3810, -1.5379,  1.0841],\n",
            "        [ 4.2512,  1.4537, -0.0349,  ..., -3.3810, -1.5379,  1.0841],\n",
            "        [ 4.2512,  1.4537, -0.0349,  ..., -3.3810, -1.5379,  1.0841],\n",
            "        ...,\n",
            "        [ 4.2512,  1.4537, -0.0349,  ..., -3.3810, -1.5379,  1.0841],\n",
            "        [ 4.2512,  1.4537, -0.0349,  ..., -3.3810, -1.5379,  1.0841],\n",
            "        [ 4.2512,  1.4537, -0.0349,  ..., -3.3810, -1.5379,  1.0841]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 469, Loss: 66955.546875\n",
            "tensor([[ 4.2921,  1.5771, -0.0132,  ..., -3.3467, -1.5274,  1.0977],\n",
            "        [ 4.2921,  1.5771, -0.0132,  ..., -3.3467, -1.5274,  1.0977],\n",
            "        [ 4.2921,  1.5771, -0.0132,  ..., -3.3467, -1.5274,  1.0977],\n",
            "        ...,\n",
            "        [ 4.2921,  1.5771, -0.0132,  ..., -3.3467, -1.5274,  1.0977],\n",
            "        [ 4.2921,  1.5771, -0.0132,  ..., -3.3467, -1.5274,  1.0977],\n",
            "        [ 4.2921,  1.5771, -0.0132,  ..., -3.3467, -1.5274,  1.0977]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 470, Loss: 66935.578125\n",
            "tensor([[ 4.3331,  1.7004,  0.0085,  ..., -3.3125, -1.5168,  1.1113],\n",
            "        [ 4.3331,  1.7004,  0.0085,  ..., -3.3125, -1.5168,  1.1113],\n",
            "        [ 4.3331,  1.7004,  0.0085,  ..., -3.3125, -1.5168,  1.1113],\n",
            "        ...,\n",
            "        [ 4.3331,  1.7004,  0.0085,  ..., -3.3125, -1.5168,  1.1113],\n",
            "        [ 4.3331,  1.7004,  0.0085,  ..., -3.3125, -1.5168,  1.1113],\n",
            "        [ 4.3331,  1.7004,  0.0085,  ..., -3.3125, -1.5168,  1.1113]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 471, Loss: 66915.625000\n",
            "tensor([[ 4.3740,  1.8237,  0.0303,  ..., -3.2783, -1.5063,  1.1249],\n",
            "        [ 4.3740,  1.8237,  0.0303,  ..., -3.2783, -1.5063,  1.1249],\n",
            "        [ 4.3740,  1.8237,  0.0303,  ..., -3.2783, -1.5063,  1.1249],\n",
            "        ...,\n",
            "        [ 4.3740,  1.8237,  0.0303,  ..., -3.2783, -1.5063,  1.1249],\n",
            "        [ 4.3740,  1.8237,  0.0303,  ..., -3.2783, -1.5063,  1.1249],\n",
            "        [ 4.3740,  1.8237,  0.0303,  ..., -3.2783, -1.5063,  1.1249]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 472, Loss: 66895.687500\n",
            "tensor([[ 4.4149,  1.9469,  0.0520,  ..., -3.2441, -1.4958,  1.1384],\n",
            "        [ 4.4149,  1.9469,  0.0520,  ..., -3.2441, -1.4958,  1.1384],\n",
            "        [ 4.4149,  1.9469,  0.0520,  ..., -3.2441, -1.4958,  1.1384],\n",
            "        ...,\n",
            "        [ 4.4149,  1.9469,  0.0520,  ..., -3.2441, -1.4958,  1.1384],\n",
            "        [ 4.4149,  1.9469,  0.0520,  ..., -3.2441, -1.4958,  1.1384],\n",
            "        [ 4.4149,  1.9469,  0.0520,  ..., -3.2441, -1.4958,  1.1384]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 473, Loss: 66875.757812\n",
            "tensor([[ 4.4558,  2.0702,  0.0737,  ..., -3.2099, -1.4852,  1.1520],\n",
            "        [ 4.4558,  2.0702,  0.0737,  ..., -3.2099, -1.4852,  1.1520],\n",
            "        [ 4.4558,  2.0702,  0.0737,  ..., -3.2099, -1.4852,  1.1520],\n",
            "        ...,\n",
            "        [ 4.4558,  2.0702,  0.0737,  ..., -3.2099, -1.4852,  1.1520],\n",
            "        [ 4.4558,  2.0702,  0.0737,  ..., -3.2099, -1.4852,  1.1520],\n",
            "        [ 4.4558,  2.0702,  0.0737,  ..., -3.2099, -1.4852,  1.1520]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 474, Loss: 66855.820312\n",
            "tensor([[ 4.4967,  2.1934,  0.0955,  ..., -3.1757, -1.4747,  1.1656],\n",
            "        [ 4.4967,  2.1934,  0.0955,  ..., -3.1757, -1.4747,  1.1656],\n",
            "        [ 4.4967,  2.1934,  0.0955,  ..., -3.1757, -1.4747,  1.1656],\n",
            "        ...,\n",
            "        [ 4.4967,  2.1934,  0.0955,  ..., -3.1757, -1.4747,  1.1656],\n",
            "        [ 4.4967,  2.1934,  0.0955,  ..., -3.1757, -1.4747,  1.1656],\n",
            "        [ 4.4967,  2.1934,  0.0955,  ..., -3.1757, -1.4747,  1.1656]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 475, Loss: 66835.906250\n",
            "tensor([[ 4.5376,  2.3166,  0.1172,  ..., -3.1415, -1.4642,  1.1792],\n",
            "        [ 4.5376,  2.3166,  0.1172,  ..., -3.1415, -1.4642,  1.1792],\n",
            "        [ 4.5376,  2.3166,  0.1172,  ..., -3.1415, -1.4642,  1.1792],\n",
            "        ...,\n",
            "        [ 4.5376,  2.3166,  0.1172,  ..., -3.1415, -1.4642,  1.1792],\n",
            "        [ 4.5376,  2.3166,  0.1172,  ..., -3.1415, -1.4642,  1.1792],\n",
            "        [ 4.5376,  2.3166,  0.1172,  ..., -3.1415, -1.4642,  1.1792]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 476, Loss: 66815.984375\n",
            "tensor([[ 4.5785,  2.4397,  0.1389,  ..., -3.1073, -1.4536,  1.1927],\n",
            "        [ 4.5785,  2.4397,  0.1389,  ..., -3.1073, -1.4536,  1.1927],\n",
            "        [ 4.5785,  2.4397,  0.1389,  ..., -3.1073, -1.4536,  1.1927],\n",
            "        ...,\n",
            "        [ 4.5785,  2.4397,  0.1389,  ..., -3.1073, -1.4536,  1.1927],\n",
            "        [ 4.5785,  2.4397,  0.1389,  ..., -3.1073, -1.4536,  1.1927],\n",
            "        [ 4.5785,  2.4397,  0.1389,  ..., -3.1073, -1.4536,  1.1927]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 477, Loss: 66796.078125\n",
            "tensor([[ 4.6194,  2.5629,  0.1606,  ..., -3.0731, -1.4431,  1.2063],\n",
            "        [ 4.6194,  2.5629,  0.1606,  ..., -3.0731, -1.4431,  1.2063],\n",
            "        [ 4.6194,  2.5629,  0.1606,  ..., -3.0731, -1.4431,  1.2063],\n",
            "        ...,\n",
            "        [ 4.6194,  2.5629,  0.1606,  ..., -3.0731, -1.4431,  1.2063],\n",
            "        [ 4.6194,  2.5629,  0.1606,  ..., -3.0731, -1.4431,  1.2063],\n",
            "        [ 4.6194,  2.5629,  0.1606,  ..., -3.0731, -1.4431,  1.2063]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 478, Loss: 66776.179688\n",
            "tensor([[ 4.6603,  2.6860,  0.1823,  ..., -3.0390, -1.4326,  1.2199],\n",
            "        [ 4.6603,  2.6860,  0.1823,  ..., -3.0390, -1.4326,  1.2199],\n",
            "        [ 4.6603,  2.6860,  0.1823,  ..., -3.0390, -1.4326,  1.2199],\n",
            "        ...,\n",
            "        [ 4.6603,  2.6860,  0.1823,  ..., -3.0390, -1.4326,  1.2199],\n",
            "        [ 4.6603,  2.6860,  0.1823,  ..., -3.0390, -1.4326,  1.2199],\n",
            "        [ 4.6603,  2.6860,  0.1823,  ..., -3.0390, -1.4326,  1.2199]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 479, Loss: 66756.296875\n",
            "tensor([[ 4.7012,  2.8091,  0.2040,  ..., -3.0048, -1.4221,  1.2334],\n",
            "        [ 4.7012,  2.8091,  0.2040,  ..., -3.0048, -1.4221,  1.2334],\n",
            "        [ 4.7012,  2.8091,  0.2040,  ..., -3.0048, -1.4221,  1.2334],\n",
            "        ...,\n",
            "        [ 4.7012,  2.8091,  0.2040,  ..., -3.0048, -1.4221,  1.2334],\n",
            "        [ 4.7012,  2.8091,  0.2040,  ..., -3.0048, -1.4221,  1.2334],\n",
            "        [ 4.7012,  2.8091,  0.2040,  ..., -3.0048, -1.4221,  1.2334]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 480, Loss: 66736.414062\n",
            "tensor([[ 4.7420,  2.9322,  0.2257,  ..., -2.9707, -1.4116,  1.2470],\n",
            "        [ 4.7420,  2.9322,  0.2257,  ..., -2.9707, -1.4116,  1.2470],\n",
            "        [ 4.7420,  2.9322,  0.2257,  ..., -2.9707, -1.4116,  1.2470],\n",
            "        ...,\n",
            "        [ 4.7420,  2.9322,  0.2257,  ..., -2.9707, -1.4116,  1.2470],\n",
            "        [ 4.7420,  2.9322,  0.2257,  ..., -2.9707, -1.4116,  1.2470],\n",
            "        [ 4.7420,  2.9322,  0.2257,  ..., -2.9707, -1.4116,  1.2470]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 481, Loss: 66716.539062\n",
            "tensor([[ 4.7829,  3.0552,  0.2474,  ..., -2.9365, -1.4010,  1.2606],\n",
            "        [ 4.7829,  3.0552,  0.2474,  ..., -2.9365, -1.4010,  1.2606],\n",
            "        [ 4.7829,  3.0552,  0.2474,  ..., -2.9365, -1.4010,  1.2606],\n",
            "        ...,\n",
            "        [ 4.7829,  3.0552,  0.2474,  ..., -2.9365, -1.4010,  1.2606],\n",
            "        [ 4.7829,  3.0552,  0.2474,  ..., -2.9365, -1.4010,  1.2606],\n",
            "        [ 4.7829,  3.0552,  0.2474,  ..., -2.9365, -1.4010,  1.2606]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 482, Loss: 66696.679688\n",
            "tensor([[ 4.8237,  3.1782,  0.2691,  ..., -2.9024, -1.3905,  1.2741],\n",
            "        [ 4.8237,  3.1782,  0.2691,  ..., -2.9024, -1.3905,  1.2741],\n",
            "        [ 4.8237,  3.1782,  0.2691,  ..., -2.9024, -1.3905,  1.2741],\n",
            "        ...,\n",
            "        [ 4.8237,  3.1782,  0.2691,  ..., -2.9024, -1.3905,  1.2741],\n",
            "        [ 4.8237,  3.1782,  0.2691,  ..., -2.9024, -1.3905,  1.2741],\n",
            "        [ 4.8237,  3.1782,  0.2691,  ..., -2.9024, -1.3905,  1.2741]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 483, Loss: 66676.812500\n",
            "tensor([[ 4.8646,  3.3012,  0.2908,  ..., -2.8682, -1.3800,  1.2877],\n",
            "        [ 4.8646,  3.3012,  0.2908,  ..., -2.8682, -1.3800,  1.2877],\n",
            "        [ 4.8646,  3.3012,  0.2908,  ..., -2.8682, -1.3800,  1.2877],\n",
            "        ...,\n",
            "        [ 4.8646,  3.3012,  0.2908,  ..., -2.8682, -1.3800,  1.2877],\n",
            "        [ 4.8646,  3.3012,  0.2908,  ..., -2.8682, -1.3800,  1.2877],\n",
            "        [ 4.8646,  3.3012,  0.2908,  ..., -2.8682, -1.3800,  1.2877]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 484, Loss: 66656.960938\n",
            "tensor([[ 4.9054,  3.4242,  0.3124,  ..., -2.8341, -1.3695,  1.3012],\n",
            "        [ 4.9054,  3.4242,  0.3124,  ..., -2.8341, -1.3695,  1.3012],\n",
            "        [ 4.9054,  3.4242,  0.3124,  ..., -2.8341, -1.3695,  1.3012],\n",
            "        ...,\n",
            "        [ 4.9054,  3.4242,  0.3124,  ..., -2.8341, -1.3695,  1.3012],\n",
            "        [ 4.9054,  3.4242,  0.3124,  ..., -2.8341, -1.3695,  1.3012],\n",
            "        [ 4.9054,  3.4242,  0.3124,  ..., -2.8341, -1.3695,  1.3012]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 485, Loss: 66637.132812\n",
            "tensor([[ 4.9462,  3.5471,  0.3341,  ..., -2.8000, -1.3590,  1.3148],\n",
            "        [ 4.9462,  3.5471,  0.3341,  ..., -2.8000, -1.3590,  1.3148],\n",
            "        [ 4.9462,  3.5471,  0.3341,  ..., -2.8000, -1.3590,  1.3148],\n",
            "        ...,\n",
            "        [ 4.9462,  3.5471,  0.3341,  ..., -2.8000, -1.3590,  1.3148],\n",
            "        [ 4.9462,  3.5471,  0.3341,  ..., -2.8000, -1.3590,  1.3148],\n",
            "        [ 4.9462,  3.5471,  0.3341,  ..., -2.8000, -1.3590,  1.3148]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 486, Loss: 66617.304688\n",
            "tensor([[ 4.9870,  3.6700,  0.3558,  ..., -2.7659, -1.3485,  1.3283],\n",
            "        [ 4.9870,  3.6700,  0.3558,  ..., -2.7659, -1.3485,  1.3283],\n",
            "        [ 4.9870,  3.6700,  0.3558,  ..., -2.7659, -1.3485,  1.3283],\n",
            "        ...,\n",
            "        [ 4.9870,  3.6700,  0.3558,  ..., -2.7659, -1.3485,  1.3283],\n",
            "        [ 4.9870,  3.6700,  0.3558,  ..., -2.7659, -1.3485,  1.3283],\n",
            "        [ 4.9870,  3.6700,  0.3558,  ..., -2.7659, -1.3485,  1.3283]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 487, Loss: 66597.468750\n",
            "tensor([[ 5.0278,  3.7929,  0.3774,  ..., -2.7318, -1.3380,  1.3418],\n",
            "        [ 5.0278,  3.7929,  0.3774,  ..., -2.7318, -1.3380,  1.3418],\n",
            "        [ 5.0278,  3.7929,  0.3774,  ..., -2.7318, -1.3380,  1.3418],\n",
            "        ...,\n",
            "        [ 5.0278,  3.7929,  0.3774,  ..., -2.7318, -1.3380,  1.3418],\n",
            "        [ 5.0278,  3.7929,  0.3774,  ..., -2.7318, -1.3380,  1.3418],\n",
            "        [ 5.0278,  3.7929,  0.3774,  ..., -2.7318, -1.3380,  1.3418]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 488, Loss: 66577.656250\n",
            "tensor([[ 5.0686,  3.9158,  0.3991,  ..., -2.6977, -1.3275,  1.3554],\n",
            "        [ 5.0686,  3.9158,  0.3991,  ..., -2.6977, -1.3275,  1.3554],\n",
            "        [ 5.0686,  3.9158,  0.3991,  ..., -2.6977, -1.3275,  1.3554],\n",
            "        ...,\n",
            "        [ 5.0686,  3.9158,  0.3991,  ..., -2.6977, -1.3275,  1.3554],\n",
            "        [ 5.0686,  3.9158,  0.3991,  ..., -2.6977, -1.3275,  1.3554],\n",
            "        [ 5.0686,  3.9158,  0.3991,  ..., -2.6977, -1.3275,  1.3554]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 489, Loss: 66557.843750\n",
            "tensor([[ 5.1094,  4.0387,  0.4208,  ..., -2.6636, -1.3170,  1.3689],\n",
            "        [ 5.1094,  4.0387,  0.4208,  ..., -2.6636, -1.3170,  1.3689],\n",
            "        [ 5.1094,  4.0387,  0.4208,  ..., -2.6636, -1.3170,  1.3689],\n",
            "        ...,\n",
            "        [ 5.1094,  4.0387,  0.4208,  ..., -2.6636, -1.3170,  1.3689],\n",
            "        [ 5.1094,  4.0387,  0.4208,  ..., -2.6636, -1.3170,  1.3689],\n",
            "        [ 5.1094,  4.0387,  0.4208,  ..., -2.6636, -1.3170,  1.3689]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 490, Loss: 66538.046875\n",
            "tensor([[ 5.1502,  4.1615,  0.4424,  ..., -2.6295, -1.3065,  1.3824],\n",
            "        [ 5.1502,  4.1615,  0.4424,  ..., -2.6295, -1.3065,  1.3824],\n",
            "        [ 5.1502,  4.1615,  0.4424,  ..., -2.6295, -1.3065,  1.3824],\n",
            "        ...,\n",
            "        [ 5.1502,  4.1615,  0.4424,  ..., -2.6295, -1.3065,  1.3824],\n",
            "        [ 5.1502,  4.1615,  0.4424,  ..., -2.6295, -1.3065,  1.3824],\n",
            "        [ 5.1502,  4.1615,  0.4424,  ..., -2.6295, -1.3065,  1.3824]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 491, Loss: 66518.250000\n",
            "tensor([[ 5.1909,  4.2843,  0.4641,  ..., -2.5954, -1.2960,  1.3960],\n",
            "        [ 5.1909,  4.2843,  0.4641,  ..., -2.5954, -1.2960,  1.3960],\n",
            "        [ 5.1909,  4.2843,  0.4641,  ..., -2.5954, -1.2960,  1.3960],\n",
            "        ...,\n",
            "        [ 5.1909,  4.2843,  0.4641,  ..., -2.5954, -1.2960,  1.3960],\n",
            "        [ 5.1909,  4.2843,  0.4641,  ..., -2.5954, -1.2960,  1.3960],\n",
            "        [ 5.1909,  4.2843,  0.4641,  ..., -2.5954, -1.2960,  1.3960]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 492, Loss: 66498.460938\n",
            "tensor([[ 5.2317,  4.4070,  0.4857,  ..., -2.5613, -1.2855,  1.4095],\n",
            "        [ 5.2317,  4.4070,  0.4857,  ..., -2.5613, -1.2855,  1.4095],\n",
            "        [ 5.2317,  4.4070,  0.4857,  ..., -2.5613, -1.2855,  1.4095],\n",
            "        ...,\n",
            "        [ 5.2317,  4.4070,  0.4857,  ..., -2.5613, -1.2855,  1.4095],\n",
            "        [ 5.2317,  4.4070,  0.4857,  ..., -2.5613, -1.2855,  1.4095],\n",
            "        [ 5.2317,  4.4070,  0.4857,  ..., -2.5613, -1.2855,  1.4095]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 493, Loss: 66478.687500\n",
            "tensor([[ 5.2725,  4.5298,  0.5073,  ..., -2.5273, -1.2750,  1.4230],\n",
            "        [ 5.2725,  4.5298,  0.5073,  ..., -2.5273, -1.2750,  1.4230],\n",
            "        [ 5.2725,  4.5298,  0.5073,  ..., -2.5273, -1.2750,  1.4230],\n",
            "        ...,\n",
            "        [ 5.2725,  4.5298,  0.5073,  ..., -2.5273, -1.2750,  1.4230],\n",
            "        [ 5.2725,  4.5298,  0.5073,  ..., -2.5273, -1.2750,  1.4230],\n",
            "        [ 5.2725,  4.5298,  0.5073,  ..., -2.5273, -1.2750,  1.4230]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 494, Loss: 66458.921875\n",
            "tensor([[ 5.3132,  4.6525,  0.5290,  ..., -2.4932, -1.2645,  1.4365],\n",
            "        [ 5.3132,  4.6525,  0.5290,  ..., -2.4932, -1.2645,  1.4365],\n",
            "        [ 5.3132,  4.6525,  0.5290,  ..., -2.4932, -1.2645,  1.4365],\n",
            "        ...,\n",
            "        [ 5.3132,  4.6525,  0.5290,  ..., -2.4932, -1.2645,  1.4365],\n",
            "        [ 5.3132,  4.6525,  0.5290,  ..., -2.4932, -1.2645,  1.4365],\n",
            "        [ 5.3132,  4.6525,  0.5290,  ..., -2.4932, -1.2645,  1.4365]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 495, Loss: 66439.156250\n",
            "tensor([[ 5.3539,  4.7752,  0.5506,  ..., -2.4591, -1.2541,  1.4501],\n",
            "        [ 5.3539,  4.7752,  0.5506,  ..., -2.4591, -1.2541,  1.4501],\n",
            "        [ 5.3539,  4.7752,  0.5506,  ..., -2.4591, -1.2541,  1.4501],\n",
            "        ...,\n",
            "        [ 5.3539,  4.7752,  0.5506,  ..., -2.4591, -1.2541,  1.4501],\n",
            "        [ 5.3539,  4.7752,  0.5506,  ..., -2.4591, -1.2541,  1.4501],\n",
            "        [ 5.3539,  4.7752,  0.5506,  ..., -2.4591, -1.2541,  1.4501]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 496, Loss: 66419.406250\n",
            "tensor([[ 5.3947,  4.8979,  0.5722,  ..., -2.4251, -1.2436,  1.4636],\n",
            "        [ 5.3947,  4.8979,  0.5722,  ..., -2.4251, -1.2436,  1.4636],\n",
            "        [ 5.3947,  4.8979,  0.5722,  ..., -2.4251, -1.2436,  1.4636],\n",
            "        ...,\n",
            "        [ 5.3947,  4.8979,  0.5722,  ..., -2.4251, -1.2436,  1.4636],\n",
            "        [ 5.3947,  4.8979,  0.5722,  ..., -2.4251, -1.2436,  1.4636],\n",
            "        [ 5.3947,  4.8979,  0.5722,  ..., -2.4251, -1.2436,  1.4636]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 497, Loss: 66399.656250\n",
            "tensor([[ 5.4354,  5.0205,  0.5939,  ..., -2.3911, -1.2331,  1.4771],\n",
            "        [ 5.4354,  5.0205,  0.5939,  ..., -2.3911, -1.2331,  1.4771],\n",
            "        [ 5.4354,  5.0205,  0.5939,  ..., -2.3911, -1.2331,  1.4771],\n",
            "        ...,\n",
            "        [ 5.4354,  5.0205,  0.5939,  ..., -2.3911, -1.2331,  1.4771],\n",
            "        [ 5.4354,  5.0205,  0.5939,  ..., -2.3911, -1.2331,  1.4771],\n",
            "        [ 5.4354,  5.0205,  0.5939,  ..., -2.3911, -1.2331,  1.4771]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 498, Loss: 66379.914062\n",
            "tensor([[ 5.4761,  5.1432,  0.6155,  ..., -2.3570, -1.2226,  1.4906],\n",
            "        [ 5.4761,  5.1432,  0.6155,  ..., -2.3570, -1.2226,  1.4906],\n",
            "        [ 5.4761,  5.1432,  0.6155,  ..., -2.3570, -1.2226,  1.4906],\n",
            "        ...,\n",
            "        [ 5.4761,  5.1432,  0.6155,  ..., -2.3570, -1.2226,  1.4906],\n",
            "        [ 5.4761,  5.1432,  0.6155,  ..., -2.3570, -1.2226,  1.4906],\n",
            "        [ 5.4761,  5.1432,  0.6155,  ..., -2.3570, -1.2226,  1.4906]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 499, Loss: 66360.187500\n",
            "tensor([[ 5.5168,  5.2658,  0.6371,  ..., -2.3230, -1.2121,  1.5041],\n",
            "        [ 5.5168,  5.2658,  0.6371,  ..., -2.3230, -1.2121,  1.5041],\n",
            "        [ 5.5168,  5.2658,  0.6371,  ..., -2.3230, -1.2121,  1.5041],\n",
            "        ...,\n",
            "        [ 5.5168,  5.2658,  0.6371,  ..., -2.3230, -1.2121,  1.5041],\n",
            "        [ 5.5168,  5.2658,  0.6371,  ..., -2.3230, -1.2121,  1.5041],\n",
            "        [ 5.5168,  5.2658,  0.6371,  ..., -2.3230, -1.2121,  1.5041]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 500, Loss: 66340.460938\n",
            "tensor([[ 5.5575,  5.3883,  0.6587,  ..., -2.2890, -1.2017,  1.5176],\n",
            "        [ 5.5575,  5.3883,  0.6587,  ..., -2.2890, -1.2017,  1.5176],\n",
            "        [ 5.5575,  5.3883,  0.6587,  ..., -2.2890, -1.2017,  1.5176],\n",
            "        ...,\n",
            "        [ 5.5575,  5.3883,  0.6587,  ..., -2.2890, -1.2017,  1.5176],\n",
            "        [ 5.5575,  5.3883,  0.6587,  ..., -2.2890, -1.2017,  1.5176],\n",
            "        [ 5.5575,  5.3883,  0.6587,  ..., -2.2890, -1.2017,  1.5176]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 501, Loss: 66320.757812\n",
            "tensor([[ 5.5982,  5.5109,  0.6803,  ..., -2.2550, -1.1912,  1.5311],\n",
            "        [ 5.5982,  5.5109,  0.6803,  ..., -2.2550, -1.1912,  1.5311],\n",
            "        [ 5.5982,  5.5109,  0.6803,  ..., -2.2550, -1.1912,  1.5311],\n",
            "        ...,\n",
            "        [ 5.5982,  5.5109,  0.6803,  ..., -2.2550, -1.1912,  1.5311],\n",
            "        [ 5.5982,  5.5109,  0.6803,  ..., -2.2550, -1.1912,  1.5311],\n",
            "        [ 5.5982,  5.5109,  0.6803,  ..., -2.2550, -1.1912,  1.5311]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 502, Loss: 66301.046875\n",
            "tensor([[ 5.6389,  5.6334,  0.7019,  ..., -2.2210, -1.1807,  1.5446],\n",
            "        [ 5.6389,  5.6334,  0.7019,  ..., -2.2210, -1.1807,  1.5446],\n",
            "        [ 5.6389,  5.6334,  0.7019,  ..., -2.2210, -1.1807,  1.5446],\n",
            "        ...,\n",
            "        [ 5.6389,  5.6334,  0.7019,  ..., -2.2210, -1.1807,  1.5446],\n",
            "        [ 5.6389,  5.6334,  0.7019,  ..., -2.2210, -1.1807,  1.5446],\n",
            "        [ 5.6389,  5.6334,  0.7019,  ..., -2.2210, -1.1807,  1.5446]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 503, Loss: 66281.343750\n",
            "tensor([[ 5.6795,  5.7559,  0.7235,  ..., -2.1870, -1.1703,  1.5581],\n",
            "        [ 5.6795,  5.7559,  0.7235,  ..., -2.1870, -1.1703,  1.5581],\n",
            "        [ 5.6795,  5.7559,  0.7235,  ..., -2.1870, -1.1703,  1.5581],\n",
            "        ...,\n",
            "        [ 5.6795,  5.7559,  0.7235,  ..., -2.1870, -1.1703,  1.5581],\n",
            "        [ 5.6795,  5.7559,  0.7235,  ..., -2.1870, -1.1703,  1.5581],\n",
            "        [ 5.6795,  5.7559,  0.7235,  ..., -2.1870, -1.1703,  1.5581]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 504, Loss: 66261.656250\n",
            "tensor([[ 5.7202,  5.8784,  0.7451,  ..., -2.1530, -1.1598,  1.5716],\n",
            "        [ 5.7202,  5.8784,  0.7451,  ..., -2.1530, -1.1598,  1.5716],\n",
            "        [ 5.7202,  5.8784,  0.7451,  ..., -2.1530, -1.1598,  1.5716],\n",
            "        ...,\n",
            "        [ 5.7202,  5.8784,  0.7451,  ..., -2.1530, -1.1598,  1.5716],\n",
            "        [ 5.7202,  5.8784,  0.7451,  ..., -2.1530, -1.1598,  1.5716],\n",
            "        [ 5.7202,  5.8784,  0.7451,  ..., -2.1530, -1.1598,  1.5716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 505, Loss: 66241.968750\n",
            "tensor([[ 5.7609,  6.0008,  0.7667,  ..., -2.1190, -1.1493,  1.5851],\n",
            "        [ 5.7609,  6.0008,  0.7667,  ..., -2.1190, -1.1493,  1.5851],\n",
            "        [ 5.7609,  6.0008,  0.7667,  ..., -2.1190, -1.1493,  1.5851],\n",
            "        ...,\n",
            "        [ 5.7609,  6.0008,  0.7667,  ..., -2.1190, -1.1493,  1.5851],\n",
            "        [ 5.7609,  6.0008,  0.7667,  ..., -2.1190, -1.1493,  1.5851],\n",
            "        [ 5.7609,  6.0008,  0.7667,  ..., -2.1190, -1.1493,  1.5851]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 506, Loss: 66222.289062\n",
            "tensor([[ 5.8015,  6.1233,  0.7883,  ..., -2.0850, -1.1389,  1.5986],\n",
            "        [ 5.8015,  6.1233,  0.7883,  ..., -2.0850, -1.1389,  1.5986],\n",
            "        [ 5.8015,  6.1233,  0.7883,  ..., -2.0850, -1.1389,  1.5986],\n",
            "        ...,\n",
            "        [ 5.8015,  6.1233,  0.7883,  ..., -2.0850, -1.1389,  1.5986],\n",
            "        [ 5.8015,  6.1233,  0.7883,  ..., -2.0850, -1.1389,  1.5986],\n",
            "        [ 5.8015,  6.1233,  0.7883,  ..., -2.0850, -1.1389,  1.5986]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 507, Loss: 66202.625000\n",
            "tensor([[ 5.8421,  6.2457,  0.8098,  ..., -2.0510, -1.1284,  1.6121],\n",
            "        [ 5.8421,  6.2457,  0.8098,  ..., -2.0510, -1.1284,  1.6121],\n",
            "        [ 5.8421,  6.2457,  0.8098,  ..., -2.0510, -1.1284,  1.6121],\n",
            "        ...,\n",
            "        [ 5.8421,  6.2457,  0.8098,  ..., -2.0510, -1.1284,  1.6121],\n",
            "        [ 5.8421,  6.2457,  0.8098,  ..., -2.0510, -1.1284,  1.6121],\n",
            "        [ 5.8421,  6.2457,  0.8098,  ..., -2.0510, -1.1284,  1.6121]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 508, Loss: 66182.968750\n",
            "tensor([[ 5.8828,  6.3680,  0.8314,  ..., -2.0171, -1.1179,  1.6256],\n",
            "        [ 5.8828,  6.3680,  0.8314,  ..., -2.0171, -1.1179,  1.6256],\n",
            "        [ 5.8828,  6.3680,  0.8314,  ..., -2.0171, -1.1179,  1.6256],\n",
            "        ...,\n",
            "        [ 5.8828,  6.3680,  0.8314,  ..., -2.0171, -1.1179,  1.6256],\n",
            "        [ 5.8828,  6.3680,  0.8314,  ..., -2.0171, -1.1179,  1.6256],\n",
            "        [ 5.8828,  6.3680,  0.8314,  ..., -2.0171, -1.1179,  1.6256]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 509, Loss: 66163.320312\n",
            "tensor([[ 5.9234,  6.4904,  0.8530,  ..., -1.9831, -1.1075,  1.6391],\n",
            "        [ 5.9234,  6.4904,  0.8530,  ..., -1.9831, -1.1075,  1.6391],\n",
            "        [ 5.9234,  6.4904,  0.8530,  ..., -1.9831, -1.1075,  1.6391],\n",
            "        ...,\n",
            "        [ 5.9234,  6.4904,  0.8530,  ..., -1.9831, -1.1075,  1.6391],\n",
            "        [ 5.9234,  6.4904,  0.8530,  ..., -1.9831, -1.1075,  1.6391],\n",
            "        [ 5.9234,  6.4904,  0.8530,  ..., -1.9831, -1.1075,  1.6391]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 510, Loss: 66143.679688\n",
            "tensor([[ 5.9640,  6.6127,  0.8746,  ..., -1.9492, -1.0970,  1.6525],\n",
            "        [ 5.9640,  6.6127,  0.8746,  ..., -1.9492, -1.0970,  1.6525],\n",
            "        [ 5.9640,  6.6127,  0.8746,  ..., -1.9492, -1.0970,  1.6525],\n",
            "        ...,\n",
            "        [ 5.9640,  6.6127,  0.8746,  ..., -1.9492, -1.0970,  1.6525],\n",
            "        [ 5.9640,  6.6127,  0.8746,  ..., -1.9492, -1.0970,  1.6525],\n",
            "        [ 5.9640,  6.6127,  0.8746,  ..., -1.9492, -1.0970,  1.6525]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 511, Loss: 66124.039062\n",
            "tensor([[ 6.0046,  6.7350,  0.8961,  ..., -1.9152, -1.0866,  1.6660],\n",
            "        [ 6.0046,  6.7350,  0.8961,  ..., -1.9152, -1.0866,  1.6660],\n",
            "        [ 6.0046,  6.7350,  0.8961,  ..., -1.9152, -1.0866,  1.6660],\n",
            "        ...,\n",
            "        [ 6.0046,  6.7350,  0.8961,  ..., -1.9152, -1.0866,  1.6660],\n",
            "        [ 6.0046,  6.7350,  0.8961,  ..., -1.9152, -1.0866,  1.6660],\n",
            "        [ 6.0046,  6.7350,  0.8961,  ..., -1.9152, -1.0866,  1.6660]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 512, Loss: 66104.406250\n",
            "tensor([[ 6.0452,  6.8573,  0.9177,  ..., -1.8813, -1.0761,  1.6795],\n",
            "        [ 6.0452,  6.8573,  0.9177,  ..., -1.8813, -1.0761,  1.6795],\n",
            "        [ 6.0452,  6.8573,  0.9177,  ..., -1.8813, -1.0761,  1.6795],\n",
            "        ...,\n",
            "        [ 6.0452,  6.8573,  0.9177,  ..., -1.8813, -1.0761,  1.6795],\n",
            "        [ 6.0452,  6.8573,  0.9177,  ..., -1.8813, -1.0761,  1.6795],\n",
            "        [ 6.0452,  6.8573,  0.9177,  ..., -1.8813, -1.0761,  1.6795]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 513, Loss: 66084.789062\n",
            "tensor([[ 6.0858,  6.9796,  0.9392,  ..., -1.8474, -1.0657,  1.6930],\n",
            "        [ 6.0858,  6.9796,  0.9392,  ..., -1.8474, -1.0657,  1.6930],\n",
            "        [ 6.0858,  6.9796,  0.9392,  ..., -1.8474, -1.0657,  1.6930],\n",
            "        ...,\n",
            "        [ 6.0858,  6.9796,  0.9392,  ..., -1.8474, -1.0657,  1.6930],\n",
            "        [ 6.0858,  6.9796,  0.9392,  ..., -1.8474, -1.0657,  1.6930],\n",
            "        [ 6.0858,  6.9796,  0.9392,  ..., -1.8474, -1.0657,  1.6930]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 514, Loss: 66065.171875\n",
            "tensor([[ 6.1264,  7.1018,  0.9608,  ..., -1.8134, -1.0552,  1.7064],\n",
            "        [ 6.1264,  7.1018,  0.9608,  ..., -1.8134, -1.0552,  1.7064],\n",
            "        [ 6.1264,  7.1018,  0.9608,  ..., -1.8134, -1.0552,  1.7064],\n",
            "        ...,\n",
            "        [ 6.1264,  7.1018,  0.9608,  ..., -1.8134, -1.0552,  1.7064],\n",
            "        [ 6.1264,  7.1018,  0.9608,  ..., -1.8134, -1.0552,  1.7064],\n",
            "        [ 6.1264,  7.1018,  0.9608,  ..., -1.8134, -1.0552,  1.7064]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 515, Loss: 66045.578125\n",
            "tensor([[ 6.1670,  7.2240,  0.9823,  ..., -1.7795, -1.0448,  1.7199],\n",
            "        [ 6.1670,  7.2240,  0.9823,  ..., -1.7795, -1.0448,  1.7199],\n",
            "        [ 6.1670,  7.2240,  0.9823,  ..., -1.7795, -1.0448,  1.7199],\n",
            "        ...,\n",
            "        [ 6.1670,  7.2240,  0.9823,  ..., -1.7795, -1.0448,  1.7199],\n",
            "        [ 6.1670,  7.2240,  0.9823,  ..., -1.7795, -1.0448,  1.7199],\n",
            "        [ 6.1670,  7.2240,  0.9823,  ..., -1.7795, -1.0448,  1.7199]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 516, Loss: 66025.976562\n",
            "tensor([[ 6.2075,  7.3462,  1.0039,  ..., -1.7456, -1.0344,  1.7334],\n",
            "        [ 6.2075,  7.3462,  1.0039,  ..., -1.7456, -1.0344,  1.7334],\n",
            "        [ 6.2075,  7.3462,  1.0039,  ..., -1.7456, -1.0344,  1.7334],\n",
            "        ...,\n",
            "        [ 6.2075,  7.3462,  1.0039,  ..., -1.7456, -1.0344,  1.7334],\n",
            "        [ 6.2075,  7.3462,  1.0039,  ..., -1.7456, -1.0344,  1.7334],\n",
            "        [ 6.2075,  7.3462,  1.0039,  ..., -1.7456, -1.0344,  1.7334]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 517, Loss: 66006.390625\n",
            "tensor([[ 6.2481,  7.4684,  1.0254,  ..., -1.7117, -1.0239,  1.7468],\n",
            "        [ 6.2481,  7.4684,  1.0254,  ..., -1.7117, -1.0239,  1.7468],\n",
            "        [ 6.2481,  7.4684,  1.0254,  ..., -1.7117, -1.0239,  1.7468],\n",
            "        ...,\n",
            "        [ 6.2481,  7.4684,  1.0254,  ..., -1.7117, -1.0239,  1.7468],\n",
            "        [ 6.2481,  7.4684,  1.0254,  ..., -1.7117, -1.0239,  1.7468],\n",
            "        [ 6.2481,  7.4684,  1.0254,  ..., -1.7117, -1.0239,  1.7468]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 518, Loss: 65986.804688\n",
            "tensor([[ 6.2886,  7.5905,  1.0469,  ..., -1.6778, -1.0135,  1.7603],\n",
            "        [ 6.2886,  7.5905,  1.0469,  ..., -1.6778, -1.0135,  1.7603],\n",
            "        [ 6.2886,  7.5905,  1.0469,  ..., -1.6778, -1.0135,  1.7603],\n",
            "        ...,\n",
            "        [ 6.2886,  7.5905,  1.0469,  ..., -1.6778, -1.0135,  1.7603],\n",
            "        [ 6.2886,  7.5905,  1.0469,  ..., -1.6778, -1.0135,  1.7603],\n",
            "        [ 6.2886,  7.5905,  1.0469,  ..., -1.6778, -1.0135,  1.7603]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 519, Loss: 65967.234375\n",
            "tensor([[ 6.3292,  7.7126,  1.0685,  ..., -1.6439, -1.0030,  1.7737],\n",
            "        [ 6.3292,  7.7126,  1.0685,  ..., -1.6439, -1.0030,  1.7737],\n",
            "        [ 6.3292,  7.7126,  1.0685,  ..., -1.6439, -1.0030,  1.7737],\n",
            "        ...,\n",
            "        [ 6.3292,  7.7126,  1.0685,  ..., -1.6439, -1.0030,  1.7737],\n",
            "        [ 6.3292,  7.7126,  1.0685,  ..., -1.6439, -1.0030,  1.7737],\n",
            "        [ 6.3292,  7.7126,  1.0685,  ..., -1.6439, -1.0030,  1.7737]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 520, Loss: 65947.671875\n",
            "tensor([[ 6.3697,  7.8347,  1.0900,  ..., -1.6100, -0.9926,  1.7872],\n",
            "        [ 6.3697,  7.8347,  1.0900,  ..., -1.6100, -0.9926,  1.7872],\n",
            "        [ 6.3697,  7.8347,  1.0900,  ..., -1.6100, -0.9926,  1.7872],\n",
            "        ...,\n",
            "        [ 6.3697,  7.8347,  1.0900,  ..., -1.6100, -0.9926,  1.7872],\n",
            "        [ 6.3697,  7.8347,  1.0900,  ..., -1.6100, -0.9926,  1.7872],\n",
            "        [ 6.3697,  7.8347,  1.0900,  ..., -1.6100, -0.9926,  1.7872]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 521, Loss: 65928.109375\n",
            "tensor([[ 6.4102,  7.9567,  1.1115,  ..., -1.5762, -0.9822,  1.8006],\n",
            "        [ 6.4102,  7.9567,  1.1115,  ..., -1.5762, -0.9822,  1.8006],\n",
            "        [ 6.4102,  7.9567,  1.1115,  ..., -1.5762, -0.9822,  1.8006],\n",
            "        ...,\n",
            "        [ 6.4102,  7.9567,  1.1115,  ..., -1.5762, -0.9822,  1.8006],\n",
            "        [ 6.4102,  7.9567,  1.1115,  ..., -1.5762, -0.9822,  1.8006],\n",
            "        [ 6.4102,  7.9567,  1.1115,  ..., -1.5762, -0.9822,  1.8006]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 522, Loss: 65908.562500\n",
            "tensor([[ 6.4508,  8.0788,  1.1330,  ..., -1.5423, -0.9718,  1.8141],\n",
            "        [ 6.4508,  8.0788,  1.1330,  ..., -1.5423, -0.9718,  1.8141],\n",
            "        [ 6.4508,  8.0788,  1.1330,  ..., -1.5423, -0.9718,  1.8141],\n",
            "        ...,\n",
            "        [ 6.4508,  8.0788,  1.1330,  ..., -1.5423, -0.9718,  1.8141],\n",
            "        [ 6.4508,  8.0788,  1.1330,  ..., -1.5423, -0.9718,  1.8141],\n",
            "        [ 6.4508,  8.0788,  1.1330,  ..., -1.5423, -0.9718,  1.8141]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 523, Loss: 65889.023438\n",
            "tensor([[ 6.4913,  8.2008,  1.1545,  ..., -1.5084, -0.9613,  1.8275],\n",
            "        [ 6.4913,  8.2008,  1.1545,  ..., -1.5084, -0.9613,  1.8275],\n",
            "        [ 6.4913,  8.2008,  1.1545,  ..., -1.5084, -0.9613,  1.8275],\n",
            "        ...,\n",
            "        [ 6.4913,  8.2008,  1.1545,  ..., -1.5084, -0.9613,  1.8275],\n",
            "        [ 6.4913,  8.2008,  1.1545,  ..., -1.5084, -0.9613,  1.8275],\n",
            "        [ 6.4913,  8.2008,  1.1545,  ..., -1.5084, -0.9613,  1.8275]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 524, Loss: 65869.484375\n",
            "tensor([[ 6.5318,  8.3228,  1.1760,  ..., -1.4746, -0.9509,  1.8410],\n",
            "        [ 6.5318,  8.3228,  1.1760,  ..., -1.4746, -0.9509,  1.8410],\n",
            "        [ 6.5318,  8.3228,  1.1760,  ..., -1.4746, -0.9509,  1.8410],\n",
            "        ...,\n",
            "        [ 6.5318,  8.3228,  1.1760,  ..., -1.4746, -0.9509,  1.8410],\n",
            "        [ 6.5318,  8.3228,  1.1760,  ..., -1.4746, -0.9509,  1.8410],\n",
            "        [ 6.5318,  8.3228,  1.1760,  ..., -1.4746, -0.9509,  1.8410]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 525, Loss: 65849.960938\n",
            "tensor([[ 6.5723,  8.4448,  1.1975,  ..., -1.4407, -0.9405,  1.8544],\n",
            "        [ 6.5723,  8.4448,  1.1975,  ..., -1.4407, -0.9405,  1.8544],\n",
            "        [ 6.5723,  8.4448,  1.1975,  ..., -1.4407, -0.9405,  1.8544],\n",
            "        ...,\n",
            "        [ 6.5723,  8.4448,  1.1975,  ..., -1.4407, -0.9405,  1.8544],\n",
            "        [ 6.5723,  8.4448,  1.1975,  ..., -1.4407, -0.9405,  1.8544],\n",
            "        [ 6.5723,  8.4448,  1.1975,  ..., -1.4407, -0.9405,  1.8544]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 526, Loss: 65830.437500\n",
            "tensor([[ 6.6128,  8.5667,  1.2190,  ..., -1.4069, -0.9301,  1.8678],\n",
            "        [ 6.6128,  8.5667,  1.2190,  ..., -1.4069, -0.9301,  1.8678],\n",
            "        [ 6.6128,  8.5667,  1.2190,  ..., -1.4069, -0.9301,  1.8678],\n",
            "        ...,\n",
            "        [ 6.6128,  8.5667,  1.2190,  ..., -1.4069, -0.9301,  1.8678],\n",
            "        [ 6.6128,  8.5667,  1.2190,  ..., -1.4069, -0.9301,  1.8678],\n",
            "        [ 6.6128,  8.5667,  1.2190,  ..., -1.4069, -0.9301,  1.8678]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 527, Loss: 65810.929688\n",
            "tensor([[ 6.6532,  8.6886,  1.2405,  ..., -1.3730, -0.9196,  1.8813],\n",
            "        [ 6.6532,  8.6886,  1.2405,  ..., -1.3730, -0.9196,  1.8813],\n",
            "        [ 6.6532,  8.6886,  1.2405,  ..., -1.3730, -0.9196,  1.8813],\n",
            "        ...,\n",
            "        [ 6.6532,  8.6886,  1.2405,  ..., -1.3730, -0.9196,  1.8813],\n",
            "        [ 6.6532,  8.6886,  1.2405,  ..., -1.3730, -0.9196,  1.8813],\n",
            "        [ 6.6532,  8.6886,  1.2405,  ..., -1.3730, -0.9196,  1.8813]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 528, Loss: 65791.429688\n",
            "tensor([[ 6.6937,  8.8105,  1.2620,  ..., -1.3392, -0.9092,  1.8947],\n",
            "        [ 6.6937,  8.8105,  1.2620,  ..., -1.3392, -0.9092,  1.8947],\n",
            "        [ 6.6937,  8.8105,  1.2620,  ..., -1.3392, -0.9092,  1.8947],\n",
            "        ...,\n",
            "        [ 6.6937,  8.8105,  1.2620,  ..., -1.3392, -0.9092,  1.8947],\n",
            "        [ 6.6937,  8.8105,  1.2620,  ..., -1.3392, -0.9092,  1.8947],\n",
            "        [ 6.6937,  8.8105,  1.2620,  ..., -1.3392, -0.9092,  1.8947]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 529, Loss: 65771.937500\n",
            "tensor([[ 6.7342,  8.9324,  1.2835,  ..., -1.3054, -0.8988,  1.9081],\n",
            "        [ 6.7342,  8.9324,  1.2835,  ..., -1.3054, -0.8988,  1.9081],\n",
            "        [ 6.7342,  8.9324,  1.2835,  ..., -1.3054, -0.8988,  1.9081],\n",
            "        ...,\n",
            "        [ 6.7342,  8.9324,  1.2835,  ..., -1.3054, -0.8988,  1.9081],\n",
            "        [ 6.7342,  8.9324,  1.2835,  ..., -1.3054, -0.8988,  1.9081],\n",
            "        [ 6.7342,  8.9324,  1.2835,  ..., -1.3054, -0.8988,  1.9081]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 530, Loss: 65752.445312\n",
            "tensor([[ 6.7746,  9.0542,  1.3050,  ..., -1.2716, -0.8884,  1.9215],\n",
            "        [ 6.7746,  9.0542,  1.3050,  ..., -1.2716, -0.8884,  1.9215],\n",
            "        [ 6.7746,  9.0542,  1.3050,  ..., -1.2716, -0.8884,  1.9215],\n",
            "        ...,\n",
            "        [ 6.7746,  9.0542,  1.3050,  ..., -1.2716, -0.8884,  1.9215],\n",
            "        [ 6.7746,  9.0542,  1.3050,  ..., -1.2716, -0.8884,  1.9215],\n",
            "        [ 6.7746,  9.0542,  1.3050,  ..., -1.2716, -0.8884,  1.9215]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 531, Loss: 65732.960938\n",
            "tensor([[ 6.8151,  9.1760,  1.3264,  ..., -1.2378, -0.8780,  1.9350],\n",
            "        [ 6.8151,  9.1760,  1.3264,  ..., -1.2378, -0.8780,  1.9350],\n",
            "        [ 6.8151,  9.1760,  1.3264,  ..., -1.2378, -0.8780,  1.9350],\n",
            "        ...,\n",
            "        [ 6.8151,  9.1760,  1.3264,  ..., -1.2378, -0.8780,  1.9350],\n",
            "        [ 6.8151,  9.1760,  1.3264,  ..., -1.2378, -0.8780,  1.9350],\n",
            "        [ 6.8151,  9.1760,  1.3264,  ..., -1.2378, -0.8780,  1.9350]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 532, Loss: 65713.500000\n",
            "tensor([[ 6.8555,  9.2978,  1.3479,  ..., -1.2040, -0.8676,  1.9484],\n",
            "        [ 6.8555,  9.2978,  1.3479,  ..., -1.2040, -0.8676,  1.9484],\n",
            "        [ 6.8555,  9.2978,  1.3479,  ..., -1.2040, -0.8676,  1.9484],\n",
            "        ...,\n",
            "        [ 6.8555,  9.2978,  1.3479,  ..., -1.2040, -0.8676,  1.9484],\n",
            "        [ 6.8555,  9.2978,  1.3479,  ..., -1.2040, -0.8676,  1.9484],\n",
            "        [ 6.8555,  9.2978,  1.3479,  ..., -1.2040, -0.8676,  1.9484]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 533, Loss: 65694.023438\n",
            "tensor([[ 6.8959,  9.4196,  1.3694,  ..., -1.1702, -0.8572,  1.9618],\n",
            "        [ 6.8959,  9.4196,  1.3694,  ..., -1.1702, -0.8572,  1.9618],\n",
            "        [ 6.8959,  9.4196,  1.3694,  ..., -1.1702, -0.8572,  1.9618],\n",
            "        ...,\n",
            "        [ 6.8959,  9.4196,  1.3694,  ..., -1.1702, -0.8572,  1.9618],\n",
            "        [ 6.8959,  9.4196,  1.3694,  ..., -1.1702, -0.8572,  1.9618],\n",
            "        [ 6.8959,  9.4196,  1.3694,  ..., -1.1702, -0.8572,  1.9618]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 534, Loss: 65674.578125\n",
            "tensor([[ 6.9363,  9.5413,  1.3908,  ..., -1.1364, -0.8468,  1.9752],\n",
            "        [ 6.9363,  9.5413,  1.3908,  ..., -1.1364, -0.8468,  1.9752],\n",
            "        [ 6.9363,  9.5413,  1.3908,  ..., -1.1364, -0.8468,  1.9752],\n",
            "        ...,\n",
            "        [ 6.9363,  9.5413,  1.3908,  ..., -1.1364, -0.8468,  1.9752],\n",
            "        [ 6.9363,  9.5413,  1.3908,  ..., -1.1364, -0.8468,  1.9752],\n",
            "        [ 6.9363,  9.5413,  1.3908,  ..., -1.1364, -0.8468,  1.9752]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 535, Loss: 65655.125000\n",
            "tensor([[ 6.9768,  9.6630,  1.4123,  ..., -1.1026, -0.8364,  1.9886],\n",
            "        [ 6.9768,  9.6630,  1.4123,  ..., -1.1026, -0.8364,  1.9886],\n",
            "        [ 6.9768,  9.6630,  1.4123,  ..., -1.1026, -0.8364,  1.9886],\n",
            "        ...,\n",
            "        [ 6.9768,  9.6630,  1.4123,  ..., -1.1026, -0.8364,  1.9886],\n",
            "        [ 6.9768,  9.6630,  1.4123,  ..., -1.1026, -0.8364,  1.9886],\n",
            "        [ 6.9768,  9.6630,  1.4123,  ..., -1.1026, -0.8364,  1.9886]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 536, Loss: 65635.687500\n",
            "tensor([[ 7.0172,  9.7847,  1.4338,  ..., -1.0688, -0.8260,  2.0020],\n",
            "        [ 7.0172,  9.7847,  1.4338,  ..., -1.0688, -0.8260,  2.0020],\n",
            "        [ 7.0172,  9.7847,  1.4338,  ..., -1.0688, -0.8260,  2.0020],\n",
            "        ...,\n",
            "        [ 7.0172,  9.7847,  1.4338,  ..., -1.0688, -0.8260,  2.0020],\n",
            "        [ 7.0172,  9.7847,  1.4338,  ..., -1.0688, -0.8260,  2.0020],\n",
            "        [ 7.0172,  9.7847,  1.4338,  ..., -1.0688, -0.8260,  2.0020]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 537, Loss: 65616.250000\n",
            "tensor([[ 7.0576,  9.9064,  1.4552,  ..., -1.0350, -0.8156,  2.0155],\n",
            "        [ 7.0576,  9.9064,  1.4552,  ..., -1.0350, -0.8156,  2.0155],\n",
            "        [ 7.0576,  9.9064,  1.4552,  ..., -1.0350, -0.8156,  2.0155],\n",
            "        ...,\n",
            "        [ 7.0576,  9.9064,  1.4552,  ..., -1.0350, -0.8156,  2.0155],\n",
            "        [ 7.0576,  9.9064,  1.4552,  ..., -1.0350, -0.8156,  2.0155],\n",
            "        [ 7.0576,  9.9064,  1.4552,  ..., -1.0350, -0.8156,  2.0155]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 538, Loss: 65596.828125\n",
            "tensor([[ 7.0979, 10.0281,  1.4767,  ..., -1.0013, -0.8052,  2.0289],\n",
            "        [ 7.0979, 10.0281,  1.4767,  ..., -1.0013, -0.8052,  2.0289],\n",
            "        [ 7.0979, 10.0281,  1.4767,  ..., -1.0013, -0.8052,  2.0289],\n",
            "        ...,\n",
            "        [ 7.0979, 10.0281,  1.4767,  ..., -1.0013, -0.8052,  2.0289],\n",
            "        [ 7.0979, 10.0281,  1.4767,  ..., -1.0013, -0.8052,  2.0289],\n",
            "        [ 7.0979, 10.0281,  1.4767,  ..., -1.0013, -0.8052,  2.0289]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 539, Loss: 65577.421875\n",
            "tensor([[ 7.1383, 10.1497,  1.4981,  ..., -0.9675, -0.7948,  2.0423],\n",
            "        [ 7.1383, 10.1497,  1.4981,  ..., -0.9675, -0.7948,  2.0423],\n",
            "        [ 7.1383, 10.1497,  1.4981,  ..., -0.9675, -0.7948,  2.0423],\n",
            "        ...,\n",
            "        [ 7.1383, 10.1497,  1.4981,  ..., -0.9675, -0.7948,  2.0423],\n",
            "        [ 7.1383, 10.1497,  1.4981,  ..., -0.9675, -0.7948,  2.0423],\n",
            "        [ 7.1383, 10.1497,  1.4981,  ..., -0.9675, -0.7948,  2.0423]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 540, Loss: 65558.000000\n",
            "tensor([[ 7.1787, 10.2713,  1.5195,  ..., -0.9338, -0.7844,  2.0557],\n",
            "        [ 7.1787, 10.2713,  1.5195,  ..., -0.9338, -0.7844,  2.0557],\n",
            "        [ 7.1787, 10.2713,  1.5195,  ..., -0.9338, -0.7844,  2.0557],\n",
            "        ...,\n",
            "        [ 7.1787, 10.2713,  1.5195,  ..., -0.9338, -0.7844,  2.0557],\n",
            "        [ 7.1787, 10.2713,  1.5195,  ..., -0.9338, -0.7844,  2.0557],\n",
            "        [ 7.1787, 10.2713,  1.5195,  ..., -0.9338, -0.7844,  2.0557]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 541, Loss: 65538.609375\n",
            "tensor([[ 7.2191, 10.3929,  1.5410,  ..., -0.9000, -0.7740,  2.0690],\n",
            "        [ 7.2191, 10.3929,  1.5410,  ..., -0.9000, -0.7740,  2.0690],\n",
            "        [ 7.2191, 10.3929,  1.5410,  ..., -0.9000, -0.7740,  2.0690],\n",
            "        ...,\n",
            "        [ 7.2191, 10.3929,  1.5410,  ..., -0.9000, -0.7740,  2.0690],\n",
            "        [ 7.2191, 10.3929,  1.5410,  ..., -0.9000, -0.7740,  2.0690],\n",
            "        [ 7.2191, 10.3929,  1.5410,  ..., -0.9000, -0.7740,  2.0690]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 542, Loss: 65519.210938\n",
            "tensor([[ 7.2594, 10.5144,  1.5624,  ..., -0.8663, -0.7636,  2.0824],\n",
            "        [ 7.2594, 10.5144,  1.5624,  ..., -0.8663, -0.7636,  2.0824],\n",
            "        [ 7.2594, 10.5144,  1.5624,  ..., -0.8663, -0.7636,  2.0824],\n",
            "        ...,\n",
            "        [ 7.2594, 10.5144,  1.5624,  ..., -0.8663, -0.7636,  2.0824],\n",
            "        [ 7.2594, 10.5144,  1.5624,  ..., -0.8663, -0.7636,  2.0824],\n",
            "        [ 7.2594, 10.5144,  1.5624,  ..., -0.8663, -0.7636,  2.0824]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 543, Loss: 65499.820312\n",
            "tensor([[ 7.2998, 10.6359,  1.5838,  ..., -0.8326, -0.7532,  2.0958],\n",
            "        [ 7.2998, 10.6359,  1.5838,  ..., -0.8326, -0.7532,  2.0958],\n",
            "        [ 7.2998, 10.6359,  1.5838,  ..., -0.8326, -0.7532,  2.0958],\n",
            "        ...,\n",
            "        [ 7.2998, 10.6359,  1.5838,  ..., -0.8326, -0.7532,  2.0958],\n",
            "        [ 7.2998, 10.6359,  1.5838,  ..., -0.8326, -0.7532,  2.0958],\n",
            "        [ 7.2998, 10.6359,  1.5838,  ..., -0.8326, -0.7532,  2.0958]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 544, Loss: 65480.445312\n",
            "tensor([[ 7.3401, 10.7574,  1.6052,  ..., -0.7989, -0.7428,  2.1092],\n",
            "        [ 7.3401, 10.7574,  1.6052,  ..., -0.7989, -0.7428,  2.1092],\n",
            "        [ 7.3401, 10.7574,  1.6052,  ..., -0.7989, -0.7428,  2.1092],\n",
            "        ...,\n",
            "        [ 7.3401, 10.7574,  1.6052,  ..., -0.7989, -0.7428,  2.1092],\n",
            "        [ 7.3401, 10.7574,  1.6052,  ..., -0.7989, -0.7428,  2.1092],\n",
            "        [ 7.3401, 10.7574,  1.6052,  ..., -0.7989, -0.7428,  2.1092]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 545, Loss: 65461.070312\n",
            "tensor([[ 7.3804, 10.8789,  1.6267,  ..., -0.7651, -0.7325,  2.1226],\n",
            "        [ 7.3804, 10.8789,  1.6267,  ..., -0.7651, -0.7325,  2.1226],\n",
            "        [ 7.3804, 10.8789,  1.6267,  ..., -0.7651, -0.7325,  2.1226],\n",
            "        ...,\n",
            "        [ 7.3804, 10.8789,  1.6267,  ..., -0.7651, -0.7325,  2.1226],\n",
            "        [ 7.3804, 10.8789,  1.6267,  ..., -0.7651, -0.7325,  2.1226],\n",
            "        [ 7.3804, 10.8789,  1.6267,  ..., -0.7651, -0.7325,  2.1226]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 546, Loss: 65441.710938\n",
            "tensor([[ 7.4208, 11.0004,  1.6481,  ..., -0.7314, -0.7221,  2.1360],\n",
            "        [ 7.4208, 11.0004,  1.6481,  ..., -0.7314, -0.7221,  2.1360],\n",
            "        [ 7.4208, 11.0004,  1.6481,  ..., -0.7314, -0.7221,  2.1360],\n",
            "        ...,\n",
            "        [ 7.4208, 11.0004,  1.6481,  ..., -0.7314, -0.7221,  2.1360],\n",
            "        [ 7.4208, 11.0004,  1.6481,  ..., -0.7314, -0.7221,  2.1360],\n",
            "        [ 7.4208, 11.0004,  1.6481,  ..., -0.7314, -0.7221,  2.1360]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 547, Loss: 65422.359375\n",
            "tensor([[ 7.4611, 11.1218,  1.6695,  ..., -0.6977, -0.7117,  2.1494],\n",
            "        [ 7.4611, 11.1218,  1.6695,  ..., -0.6977, -0.7117,  2.1494],\n",
            "        [ 7.4611, 11.1218,  1.6695,  ..., -0.6977, -0.7117,  2.1494],\n",
            "        ...,\n",
            "        [ 7.4611, 11.1218,  1.6695,  ..., -0.6977, -0.7117,  2.1494],\n",
            "        [ 7.4611, 11.1218,  1.6695,  ..., -0.6977, -0.7117,  2.1494],\n",
            "        [ 7.4611, 11.1218,  1.6695,  ..., -0.6977, -0.7117,  2.1494]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 548, Loss: 65403.011719\n",
            "tensor([[ 7.5014, 11.2432,  1.6909,  ..., -0.6640, -0.7013,  2.1627],\n",
            "        [ 7.5014, 11.2432,  1.6909,  ..., -0.6640, -0.7013,  2.1627],\n",
            "        [ 7.5014, 11.2432,  1.6909,  ..., -0.6640, -0.7013,  2.1627],\n",
            "        ...,\n",
            "        [ 7.5014, 11.2432,  1.6909,  ..., -0.6640, -0.7013,  2.1627],\n",
            "        [ 7.5014, 11.2432,  1.6909,  ..., -0.6640, -0.7013,  2.1627],\n",
            "        [ 7.5014, 11.2432,  1.6909,  ..., -0.6640, -0.7013,  2.1627]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 549, Loss: 65383.671875\n",
            "tensor([[ 7.5417, 11.3646,  1.7123,  ..., -0.6304, -0.6910,  2.1761],\n",
            "        [ 7.5417, 11.3646,  1.7123,  ..., -0.6304, -0.6910,  2.1761],\n",
            "        [ 7.5417, 11.3646,  1.7123,  ..., -0.6304, -0.6910,  2.1761],\n",
            "        ...,\n",
            "        [ 7.5417, 11.3646,  1.7123,  ..., -0.6304, -0.6910,  2.1761],\n",
            "        [ 7.5417, 11.3646,  1.7123,  ..., -0.6304, -0.6910,  2.1761],\n",
            "        [ 7.5417, 11.3646,  1.7123,  ..., -0.6304, -0.6910,  2.1761]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 550, Loss: 65364.339844\n",
            "tensor([[ 7.5820, 11.4859,  1.7337,  ..., -0.5967, -0.6806,  2.1895],\n",
            "        [ 7.5820, 11.4859,  1.7337,  ..., -0.5967, -0.6806,  2.1895],\n",
            "        [ 7.5820, 11.4859,  1.7337,  ..., -0.5967, -0.6806,  2.1895],\n",
            "        ...,\n",
            "        [ 7.5820, 11.4859,  1.7337,  ..., -0.5967, -0.6806,  2.1895],\n",
            "        [ 7.5820, 11.4859,  1.7337,  ..., -0.5967, -0.6806,  2.1895],\n",
            "        [ 7.5820, 11.4859,  1.7337,  ..., -0.5967, -0.6806,  2.1895]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 551, Loss: 65345.019531\n",
            "tensor([[ 7.6223, 11.6073,  1.7551,  ..., -0.5630, -0.6702,  2.2029],\n",
            "        [ 7.6223, 11.6073,  1.7551,  ..., -0.5630, -0.6702,  2.2029],\n",
            "        [ 7.6223, 11.6073,  1.7551,  ..., -0.5630, -0.6702,  2.2029],\n",
            "        ...,\n",
            "        [ 7.6223, 11.6073,  1.7551,  ..., -0.5630, -0.6702,  2.2029],\n",
            "        [ 7.6223, 11.6073,  1.7551,  ..., -0.5630, -0.6702,  2.2029],\n",
            "        [ 7.6223, 11.6073,  1.7551,  ..., -0.5630, -0.6702,  2.2029]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 552, Loss: 65325.691406\n",
            "tensor([[ 7.6625, 11.7286,  1.7764,  ..., -0.5293, -0.6599,  2.2162],\n",
            "        [ 7.6625, 11.7286,  1.7764,  ..., -0.5293, -0.6599,  2.2162],\n",
            "        [ 7.6625, 11.7286,  1.7764,  ..., -0.5293, -0.6599,  2.2162],\n",
            "        ...,\n",
            "        [ 7.6625, 11.7286,  1.7764,  ..., -0.5293, -0.6599,  2.2162],\n",
            "        [ 7.6625, 11.7286,  1.7764,  ..., -0.5293, -0.6599,  2.2162],\n",
            "        [ 7.6625, 11.7286,  1.7764,  ..., -0.5293, -0.6599,  2.2162]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 553, Loss: 65306.394531\n",
            "tensor([[ 7.7028, 11.8498,  1.7978,  ..., -0.4957, -0.6495,  2.2296],\n",
            "        [ 7.7028, 11.8498,  1.7978,  ..., -0.4957, -0.6495,  2.2296],\n",
            "        [ 7.7028, 11.8498,  1.7978,  ..., -0.4957, -0.6495,  2.2296],\n",
            "        ...,\n",
            "        [ 7.7028, 11.8498,  1.7978,  ..., -0.4957, -0.6495,  2.2296],\n",
            "        [ 7.7028, 11.8498,  1.7978,  ..., -0.4957, -0.6495,  2.2296],\n",
            "        [ 7.7028, 11.8498,  1.7978,  ..., -0.4957, -0.6495,  2.2296]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 554, Loss: 65287.082031\n",
            "tensor([[ 7.7431, 11.9711,  1.8192,  ..., -0.4620, -0.6391,  2.2429],\n",
            "        [ 7.7431, 11.9711,  1.8192,  ..., -0.4620, -0.6391,  2.2429],\n",
            "        [ 7.7431, 11.9711,  1.8192,  ..., -0.4620, -0.6391,  2.2429],\n",
            "        ...,\n",
            "        [ 7.7431, 11.9711,  1.8192,  ..., -0.4620, -0.6391,  2.2429],\n",
            "        [ 7.7431, 11.9711,  1.8192,  ..., -0.4620, -0.6391,  2.2429],\n",
            "        [ 7.7431, 11.9711,  1.8192,  ..., -0.4620, -0.6391,  2.2429]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 555, Loss: 65267.792969\n",
            "tensor([[ 7.7833, 12.0923,  1.8406,  ..., -0.4284, -0.6288,  2.2563],\n",
            "        [ 7.7833, 12.0923,  1.8406,  ..., -0.4284, -0.6288,  2.2563],\n",
            "        [ 7.7833, 12.0923,  1.8406,  ..., -0.4284, -0.6288,  2.2563],\n",
            "        ...,\n",
            "        [ 7.7833, 12.0923,  1.8406,  ..., -0.4284, -0.6288,  2.2563],\n",
            "        [ 7.7833, 12.0923,  1.8406,  ..., -0.4284, -0.6288,  2.2563],\n",
            "        [ 7.7833, 12.0923,  1.8406,  ..., -0.4284, -0.6288,  2.2563]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 556, Loss: 65248.515625\n",
            "tensor([[ 7.8236, 12.2136,  1.8619,  ..., -0.3947, -0.6184,  2.2697],\n",
            "        [ 7.8236, 12.2136,  1.8619,  ..., -0.3947, -0.6184,  2.2697],\n",
            "        [ 7.8236, 12.2136,  1.8619,  ..., -0.3947, -0.6184,  2.2697],\n",
            "        ...,\n",
            "        [ 7.8236, 12.2136,  1.8619,  ..., -0.3947, -0.6184,  2.2697],\n",
            "        [ 7.8236, 12.2136,  1.8619,  ..., -0.3947, -0.6184,  2.2697],\n",
            "        [ 7.8236, 12.2136,  1.8619,  ..., -0.3947, -0.6184,  2.2697]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 557, Loss: 65229.238281\n",
            "tensor([[ 7.8638, 12.3347,  1.8833,  ..., -0.3611, -0.6081,  2.2830],\n",
            "        [ 7.8638, 12.3347,  1.8833,  ..., -0.3611, -0.6081,  2.2830],\n",
            "        [ 7.8638, 12.3347,  1.8833,  ..., -0.3611, -0.6081,  2.2830],\n",
            "        ...,\n",
            "        [ 7.8638, 12.3347,  1.8833,  ..., -0.3611, -0.6081,  2.2830],\n",
            "        [ 7.8638, 12.3347,  1.8833,  ..., -0.3611, -0.6081,  2.2830],\n",
            "        [ 7.8638, 12.3347,  1.8833,  ..., -0.3611, -0.6081,  2.2830]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 558, Loss: 65209.968750\n",
            "tensor([[ 7.9040, 12.4559,  1.9047,  ..., -0.3275, -0.5977,  2.2964],\n",
            "        [ 7.9040, 12.4559,  1.9047,  ..., -0.3275, -0.5977,  2.2964],\n",
            "        [ 7.9040, 12.4559,  1.9047,  ..., -0.3275, -0.5977,  2.2964],\n",
            "        ...,\n",
            "        [ 7.9040, 12.4559,  1.9047,  ..., -0.3275, -0.5977,  2.2964],\n",
            "        [ 7.9040, 12.4559,  1.9047,  ..., -0.3275, -0.5977,  2.2964],\n",
            "        [ 7.9040, 12.4559,  1.9047,  ..., -0.3275, -0.5977,  2.2964]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 559, Loss: 65190.699219\n",
            "tensor([[ 7.9442, 12.5770,  1.9260,  ..., -0.2939, -0.5873,  2.3097],\n",
            "        [ 7.9442, 12.5770,  1.9260,  ..., -0.2939, -0.5873,  2.3097],\n",
            "        [ 7.9442, 12.5770,  1.9260,  ..., -0.2939, -0.5873,  2.3097],\n",
            "        ...,\n",
            "        [ 7.9442, 12.5770,  1.9260,  ..., -0.2939, -0.5873,  2.3097],\n",
            "        [ 7.9442, 12.5770,  1.9260,  ..., -0.2939, -0.5873,  2.3097],\n",
            "        [ 7.9442, 12.5770,  1.9260,  ..., -0.2939, -0.5873,  2.3097]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 560, Loss: 65171.445312\n",
            "tensor([[ 7.9844, 12.6981,  1.9474,  ..., -0.2602, -0.5770,  2.3231],\n",
            "        [ 7.9844, 12.6981,  1.9474,  ..., -0.2602, -0.5770,  2.3231],\n",
            "        [ 7.9844, 12.6981,  1.9474,  ..., -0.2602, -0.5770,  2.3231],\n",
            "        ...,\n",
            "        [ 7.9844, 12.6981,  1.9474,  ..., -0.2602, -0.5770,  2.3231],\n",
            "        [ 7.9844, 12.6981,  1.9474,  ..., -0.2602, -0.5770,  2.3231],\n",
            "        [ 7.9844, 12.6981,  1.9474,  ..., -0.2602, -0.5770,  2.3231]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 561, Loss: 65152.203125\n",
            "tensor([[ 8.0247, 12.8192,  1.9687,  ..., -0.2266, -0.5666,  2.3364],\n",
            "        [ 8.0247, 12.8192,  1.9687,  ..., -0.2266, -0.5666,  2.3364],\n",
            "        [ 8.0247, 12.8192,  1.9687,  ..., -0.2266, -0.5666,  2.3364],\n",
            "        ...,\n",
            "        [ 8.0247, 12.8192,  1.9687,  ..., -0.2266, -0.5666,  2.3364],\n",
            "        [ 8.0247, 12.8192,  1.9687,  ..., -0.2266, -0.5666,  2.3364],\n",
            "        [ 8.0247, 12.8192,  1.9687,  ..., -0.2266, -0.5666,  2.3364]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 562, Loss: 65132.960938\n",
            "tensor([[ 8.0648, 12.9403,  1.9901,  ..., -0.1930, -0.5563,  2.3497],\n",
            "        [ 8.0648, 12.9403,  1.9901,  ..., -0.1930, -0.5563,  2.3497],\n",
            "        [ 8.0648, 12.9403,  1.9901,  ..., -0.1930, -0.5563,  2.3497],\n",
            "        ...,\n",
            "        [ 8.0648, 12.9403,  1.9901,  ..., -0.1930, -0.5563,  2.3497],\n",
            "        [ 8.0648, 12.9403,  1.9901,  ..., -0.1930, -0.5563,  2.3497],\n",
            "        [ 8.0648, 12.9403,  1.9901,  ..., -0.1930, -0.5563,  2.3497]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 563, Loss: 65113.726562\n",
            "tensor([[ 8.1050, 13.0613,  2.0114,  ..., -0.1594, -0.5460,  2.3631],\n",
            "        [ 8.1050, 13.0613,  2.0114,  ..., -0.1594, -0.5460,  2.3631],\n",
            "        [ 8.1050, 13.0613,  2.0114,  ..., -0.1594, -0.5460,  2.3631],\n",
            "        ...,\n",
            "        [ 8.1050, 13.0613,  2.0114,  ..., -0.1594, -0.5460,  2.3631],\n",
            "        [ 8.1050, 13.0613,  2.0114,  ..., -0.1594, -0.5460,  2.3631],\n",
            "        [ 8.1050, 13.0613,  2.0114,  ..., -0.1594, -0.5460,  2.3631]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 564, Loss: 65094.492188\n",
            "tensor([[ 8.1452, 13.1824,  2.0327,  ..., -0.1259, -0.5356,  2.3764],\n",
            "        [ 8.1452, 13.1824,  2.0327,  ..., -0.1259, -0.5356,  2.3764],\n",
            "        [ 8.1452, 13.1824,  2.0327,  ..., -0.1259, -0.5356,  2.3764],\n",
            "        ...,\n",
            "        [ 8.1452, 13.1824,  2.0327,  ..., -0.1259, -0.5356,  2.3764],\n",
            "        [ 8.1452, 13.1824,  2.0327,  ..., -0.1259, -0.5356,  2.3764],\n",
            "        [ 8.1452, 13.1824,  2.0327,  ..., -0.1259, -0.5356,  2.3764]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 565, Loss: 65075.292969\n",
            "tensor([[ 8.1854, 13.3033,  2.0541,  ..., -0.0923, -0.5253,  2.3897],\n",
            "        [ 8.1854, 13.3033,  2.0541,  ..., -0.0923, -0.5253,  2.3897],\n",
            "        [ 8.1854, 13.3033,  2.0541,  ..., -0.0923, -0.5253,  2.3897],\n",
            "        ...,\n",
            "        [ 8.1854, 13.3033,  2.0541,  ..., -0.0923, -0.5253,  2.3897],\n",
            "        [ 8.1854, 13.3033,  2.0541,  ..., -0.0923, -0.5253,  2.3897],\n",
            "        [ 8.1854, 13.3033,  2.0541,  ..., -0.0923, -0.5253,  2.3897]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 566, Loss: 65056.082031\n",
            "tensor([[ 8.2255, 13.4243,  2.0754,  ..., -0.0587, -0.5149,  2.4031],\n",
            "        [ 8.2255, 13.4243,  2.0754,  ..., -0.0587, -0.5149,  2.4031],\n",
            "        [ 8.2255, 13.4243,  2.0754,  ..., -0.0587, -0.5149,  2.4031],\n",
            "        ...,\n",
            "        [ 8.2255, 13.4243,  2.0754,  ..., -0.0587, -0.5149,  2.4031],\n",
            "        [ 8.2255, 13.4243,  2.0754,  ..., -0.0587, -0.5149,  2.4031],\n",
            "        [ 8.2255, 13.4243,  2.0754,  ..., -0.0587, -0.5149,  2.4031]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 567, Loss: 65036.882812\n",
            "tensor([[ 8.2657, 13.5453,  2.0967,  ..., -0.0251, -0.5046,  2.4164],\n",
            "        [ 8.2657, 13.5453,  2.0967,  ..., -0.0251, -0.5046,  2.4164],\n",
            "        [ 8.2657, 13.5453,  2.0967,  ..., -0.0251, -0.5046,  2.4164],\n",
            "        ...,\n",
            "        [ 8.2657, 13.5453,  2.0967,  ..., -0.0251, -0.5046,  2.4164],\n",
            "        [ 8.2657, 13.5453,  2.0967,  ..., -0.0251, -0.5046,  2.4164],\n",
            "        [ 8.2657, 13.5453,  2.0967,  ..., -0.0251, -0.5046,  2.4164]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 568, Loss: 65017.679688\n",
            "tensor([[ 8.3058e+00,  1.3666e+01,  2.1180e+00,  ...,  8.4239e-03,\n",
            "         -4.9427e-01,  2.4297e+00],\n",
            "        [ 8.3058e+00,  1.3666e+01,  2.1180e+00,  ...,  8.4239e-03,\n",
            "         -4.9427e-01,  2.4297e+00],\n",
            "        [ 8.3058e+00,  1.3666e+01,  2.1180e+00,  ...,  8.4239e-03,\n",
            "         -4.9427e-01,  2.4297e+00],\n",
            "        ...,\n",
            "        [ 8.3058e+00,  1.3666e+01,  2.1180e+00,  ...,  8.4239e-03,\n",
            "         -4.9427e-01,  2.4297e+00],\n",
            "        [ 8.3058e+00,  1.3666e+01,  2.1180e+00,  ...,  8.4239e-03,\n",
            "         -4.9427e-01,  2.4297e+00],\n",
            "        [ 8.3058e+00,  1.3666e+01,  2.1180e+00,  ...,  8.4239e-03,\n",
            "         -4.9427e-01,  2.4297e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 569, Loss: 64998.500000\n",
            "tensor([[ 8.3460, 13.7871,  2.1393,  ...,  0.0420, -0.4839,  2.4430],\n",
            "        [ 8.3460, 13.7871,  2.1393,  ...,  0.0420, -0.4839,  2.4430],\n",
            "        [ 8.3460, 13.7871,  2.1393,  ...,  0.0420, -0.4839,  2.4430],\n",
            "        ...,\n",
            "        [ 8.3460, 13.7871,  2.1393,  ...,  0.0420, -0.4839,  2.4430],\n",
            "        [ 8.3460, 13.7871,  2.1393,  ...,  0.0420, -0.4839,  2.4430],\n",
            "        [ 8.3460, 13.7871,  2.1393,  ...,  0.0420, -0.4839,  2.4430]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 570, Loss: 64979.324219\n",
            "tensor([[ 8.3861, 13.9079,  2.1606,  ...,  0.0755, -0.4736,  2.4564],\n",
            "        [ 8.3861, 13.9079,  2.1606,  ...,  0.0755, -0.4736,  2.4564],\n",
            "        [ 8.3861, 13.9079,  2.1606,  ...,  0.0755, -0.4736,  2.4564],\n",
            "        ...,\n",
            "        [ 8.3861, 13.9079,  2.1606,  ...,  0.0755, -0.4736,  2.4564],\n",
            "        [ 8.3861, 13.9079,  2.1606,  ...,  0.0755, -0.4736,  2.4564],\n",
            "        [ 8.3861, 13.9079,  2.1606,  ...,  0.0755, -0.4736,  2.4564]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 571, Loss: 64960.156250\n",
            "tensor([[ 8.4262, 14.0288,  2.1820,  ...,  0.1091, -0.4633,  2.4697],\n",
            "        [ 8.4262, 14.0288,  2.1820,  ...,  0.1091, -0.4633,  2.4697],\n",
            "        [ 8.4262, 14.0288,  2.1820,  ...,  0.1091, -0.4633,  2.4697],\n",
            "        ...,\n",
            "        [ 8.4262, 14.0288,  2.1820,  ...,  0.1091, -0.4633,  2.4697],\n",
            "        [ 8.4262, 14.0288,  2.1820,  ...,  0.1091, -0.4633,  2.4697],\n",
            "        [ 8.4262, 14.0288,  2.1820,  ...,  0.1091, -0.4633,  2.4697]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 572, Loss: 64940.984375\n",
            "tensor([[ 8.4663, 14.1496,  2.2033,  ...,  0.1426, -0.4530,  2.4830],\n",
            "        [ 8.4663, 14.1496,  2.2033,  ...,  0.1426, -0.4530,  2.4830],\n",
            "        [ 8.4663, 14.1496,  2.2033,  ...,  0.1426, -0.4530,  2.4830],\n",
            "        ...,\n",
            "        [ 8.4663, 14.1496,  2.2033,  ...,  0.1426, -0.4530,  2.4830],\n",
            "        [ 8.4663, 14.1496,  2.2033,  ...,  0.1426, -0.4530,  2.4830],\n",
            "        [ 8.4663, 14.1496,  2.2033,  ...,  0.1426, -0.4530,  2.4830]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 573, Loss: 64921.832031\n",
            "tensor([[ 8.5065, 14.2704,  2.2245,  ...,  0.1761, -0.4426,  2.4963],\n",
            "        [ 8.5065, 14.2704,  2.2245,  ...,  0.1761, -0.4426,  2.4963],\n",
            "        [ 8.5065, 14.2704,  2.2245,  ...,  0.1761, -0.4426,  2.4963],\n",
            "        ...,\n",
            "        [ 8.5065, 14.2704,  2.2245,  ...,  0.1761, -0.4426,  2.4963],\n",
            "        [ 8.5065, 14.2704,  2.2245,  ...,  0.1761, -0.4426,  2.4963],\n",
            "        [ 8.5065, 14.2704,  2.2245,  ...,  0.1761, -0.4426,  2.4963]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 574, Loss: 64902.687500\n",
            "tensor([[ 8.5466, 14.3912,  2.2458,  ...,  0.2096, -0.4323,  2.5096],\n",
            "        [ 8.5466, 14.3912,  2.2458,  ...,  0.2096, -0.4323,  2.5096],\n",
            "        [ 8.5466, 14.3912,  2.2458,  ...,  0.2096, -0.4323,  2.5096],\n",
            "        ...,\n",
            "        [ 8.5466, 14.3912,  2.2458,  ...,  0.2096, -0.4323,  2.5096],\n",
            "        [ 8.5466, 14.3912,  2.2458,  ...,  0.2096, -0.4323,  2.5096],\n",
            "        [ 8.5466, 14.3912,  2.2458,  ...,  0.2096, -0.4323,  2.5096]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 575, Loss: 64883.546875\n",
            "tensor([[ 8.5866, 14.5119,  2.2671,  ...,  0.2432, -0.4220,  2.5229],\n",
            "        [ 8.5866, 14.5119,  2.2671,  ...,  0.2432, -0.4220,  2.5229],\n",
            "        [ 8.5866, 14.5119,  2.2671,  ...,  0.2432, -0.4220,  2.5229],\n",
            "        ...,\n",
            "        [ 8.5866, 14.5119,  2.2671,  ...,  0.2432, -0.4220,  2.5229],\n",
            "        [ 8.5866, 14.5119,  2.2671,  ...,  0.2432, -0.4220,  2.5229],\n",
            "        [ 8.5866, 14.5119,  2.2671,  ...,  0.2432, -0.4220,  2.5229]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 576, Loss: 64864.417969\n",
            "tensor([[ 8.6267, 14.6327,  2.2884,  ...,  0.2767, -0.4117,  2.5362],\n",
            "        [ 8.6267, 14.6327,  2.2884,  ...,  0.2767, -0.4117,  2.5362],\n",
            "        [ 8.6267, 14.6327,  2.2884,  ...,  0.2767, -0.4117,  2.5362],\n",
            "        ...,\n",
            "        [ 8.6267, 14.6327,  2.2884,  ...,  0.2767, -0.4117,  2.5362],\n",
            "        [ 8.6267, 14.6327,  2.2884,  ...,  0.2767, -0.4117,  2.5362],\n",
            "        [ 8.6267, 14.6327,  2.2884,  ...,  0.2767, -0.4117,  2.5362]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 577, Loss: 64845.292969\n",
            "tensor([[ 8.6668, 14.7534,  2.3097,  ...,  0.3102, -0.4014,  2.5495],\n",
            "        [ 8.6668, 14.7534,  2.3097,  ...,  0.3102, -0.4014,  2.5495],\n",
            "        [ 8.6668, 14.7534,  2.3097,  ...,  0.3102, -0.4014,  2.5495],\n",
            "        ...,\n",
            "        [ 8.6668, 14.7534,  2.3097,  ...,  0.3102, -0.4014,  2.5495],\n",
            "        [ 8.6668, 14.7534,  2.3097,  ...,  0.3102, -0.4014,  2.5495],\n",
            "        [ 8.6668, 14.7534,  2.3097,  ...,  0.3102, -0.4014,  2.5495]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 578, Loss: 64826.171875\n",
            "tensor([[ 8.7069, 14.8740,  2.3310,  ...,  0.3437, -0.3911,  2.5628],\n",
            "        [ 8.7069, 14.8740,  2.3310,  ...,  0.3437, -0.3911,  2.5628],\n",
            "        [ 8.7069, 14.8740,  2.3310,  ...,  0.3437, -0.3911,  2.5628],\n",
            "        ...,\n",
            "        [ 8.7069, 14.8740,  2.3310,  ...,  0.3437, -0.3911,  2.5628],\n",
            "        [ 8.7069, 14.8740,  2.3310,  ...,  0.3437, -0.3911,  2.5628],\n",
            "        [ 8.7069, 14.8740,  2.3310,  ...,  0.3437, -0.3911,  2.5628]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 579, Loss: 64807.070312\n",
            "tensor([[ 8.7469, 14.9947,  2.3522,  ...,  0.3771, -0.3807,  2.5761],\n",
            "        [ 8.7469, 14.9947,  2.3522,  ...,  0.3771, -0.3807,  2.5761],\n",
            "        [ 8.7469, 14.9947,  2.3522,  ...,  0.3771, -0.3807,  2.5761],\n",
            "        ...,\n",
            "        [ 8.7469, 14.9947,  2.3522,  ...,  0.3771, -0.3807,  2.5761],\n",
            "        [ 8.7469, 14.9947,  2.3522,  ...,  0.3771, -0.3807,  2.5761],\n",
            "        [ 8.7469, 14.9947,  2.3522,  ...,  0.3771, -0.3807,  2.5761]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 580, Loss: 64787.960938\n",
            "tensor([[ 8.7870, 15.1153,  2.3735,  ...,  0.4106, -0.3704,  2.5894],\n",
            "        [ 8.7870, 15.1153,  2.3735,  ...,  0.4106, -0.3704,  2.5894],\n",
            "        [ 8.7870, 15.1153,  2.3735,  ...,  0.4106, -0.3704,  2.5894],\n",
            "        ...,\n",
            "        [ 8.7870, 15.1153,  2.3735,  ...,  0.4106, -0.3704,  2.5894],\n",
            "        [ 8.7870, 15.1153,  2.3735,  ...,  0.4106, -0.3704,  2.5894],\n",
            "        [ 8.7870, 15.1153,  2.3735,  ...,  0.4106, -0.3704,  2.5894]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 581, Loss: 64768.867188\n",
            "tensor([[ 8.8270, 15.2359,  2.3948,  ...,  0.4441, -0.3601,  2.6027],\n",
            "        [ 8.8270, 15.2359,  2.3948,  ...,  0.4441, -0.3601,  2.6027],\n",
            "        [ 8.8270, 15.2359,  2.3948,  ...,  0.4441, -0.3601,  2.6027],\n",
            "        ...,\n",
            "        [ 8.8270, 15.2359,  2.3948,  ...,  0.4441, -0.3601,  2.6027],\n",
            "        [ 8.8270, 15.2359,  2.3948,  ...,  0.4441, -0.3601,  2.6027],\n",
            "        [ 8.8270, 15.2359,  2.3948,  ...,  0.4441, -0.3601,  2.6027]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 582, Loss: 64749.789062\n",
            "tensor([[ 8.8671, 15.3565,  2.4160,  ...,  0.4776, -0.3498,  2.6160],\n",
            "        [ 8.8671, 15.3565,  2.4160,  ...,  0.4776, -0.3498,  2.6160],\n",
            "        [ 8.8671, 15.3565,  2.4160,  ...,  0.4776, -0.3498,  2.6160],\n",
            "        ...,\n",
            "        [ 8.8671, 15.3565,  2.4160,  ...,  0.4776, -0.3498,  2.6160],\n",
            "        [ 8.8671, 15.3565,  2.4160,  ...,  0.4776, -0.3498,  2.6160],\n",
            "        [ 8.8671, 15.3565,  2.4160,  ...,  0.4776, -0.3498,  2.6160]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 583, Loss: 64730.703125\n",
            "tensor([[ 8.9071, 15.4771,  2.4373,  ...,  0.5110, -0.3395,  2.6293],\n",
            "        [ 8.9071, 15.4771,  2.4373,  ...,  0.5110, -0.3395,  2.6293],\n",
            "        [ 8.9071, 15.4771,  2.4373,  ...,  0.5110, -0.3395,  2.6293],\n",
            "        ...,\n",
            "        [ 8.9071, 15.4771,  2.4373,  ...,  0.5110, -0.3395,  2.6293],\n",
            "        [ 8.9071, 15.4771,  2.4373,  ...,  0.5110, -0.3395,  2.6293],\n",
            "        [ 8.9071, 15.4771,  2.4373,  ...,  0.5110, -0.3395,  2.6293]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 584, Loss: 64711.636719\n",
            "tensor([[ 8.9471, 15.5976,  2.4585,  ...,  0.5445, -0.3292,  2.6425],\n",
            "        [ 8.9471, 15.5976,  2.4585,  ...,  0.5445, -0.3292,  2.6425],\n",
            "        [ 8.9471, 15.5976,  2.4585,  ...,  0.5445, -0.3292,  2.6425],\n",
            "        ...,\n",
            "        [ 8.9471, 15.5976,  2.4585,  ...,  0.5445, -0.3292,  2.6425],\n",
            "        [ 8.9471, 15.5976,  2.4585,  ...,  0.5445, -0.3292,  2.6425],\n",
            "        [ 8.9471, 15.5976,  2.4585,  ...,  0.5445, -0.3292,  2.6425]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 585, Loss: 64692.570312\n",
            "tensor([[ 8.9871, 15.7181,  2.4798,  ...,  0.5779, -0.3189,  2.6558],\n",
            "        [ 8.9871, 15.7181,  2.4798,  ...,  0.5779, -0.3189,  2.6558],\n",
            "        [ 8.9871, 15.7181,  2.4798,  ...,  0.5779, -0.3189,  2.6558],\n",
            "        ...,\n",
            "        [ 8.9871, 15.7181,  2.4798,  ...,  0.5779, -0.3189,  2.6558],\n",
            "        [ 8.9871, 15.7181,  2.4798,  ...,  0.5779, -0.3189,  2.6558],\n",
            "        [ 8.9871, 15.7181,  2.4798,  ...,  0.5779, -0.3189,  2.6558]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 586, Loss: 64673.511719\n",
            "tensor([[ 9.0271, 15.8386,  2.5010,  ...,  0.6113, -0.3086,  2.6691],\n",
            "        [ 9.0271, 15.8386,  2.5010,  ...,  0.6113, -0.3086,  2.6691],\n",
            "        [ 9.0271, 15.8386,  2.5010,  ...,  0.6113, -0.3086,  2.6691],\n",
            "        ...,\n",
            "        [ 9.0271, 15.8386,  2.5010,  ...,  0.6113, -0.3086,  2.6691],\n",
            "        [ 9.0271, 15.8386,  2.5010,  ...,  0.6113, -0.3086,  2.6691],\n",
            "        [ 9.0271, 15.8386,  2.5010,  ...,  0.6113, -0.3086,  2.6691]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 587, Loss: 64654.464844\n",
            "tensor([[ 9.0671, 15.9591,  2.5222,  ...,  0.6448, -0.2983,  2.6824],\n",
            "        [ 9.0671, 15.9591,  2.5222,  ...,  0.6448, -0.2983,  2.6824],\n",
            "        [ 9.0671, 15.9591,  2.5222,  ...,  0.6448, -0.2983,  2.6824],\n",
            "        ...,\n",
            "        [ 9.0671, 15.9591,  2.5222,  ...,  0.6448, -0.2983,  2.6824],\n",
            "        [ 9.0671, 15.9591,  2.5222,  ...,  0.6448, -0.2983,  2.6824],\n",
            "        [ 9.0671, 15.9591,  2.5222,  ...,  0.6448, -0.2983,  2.6824]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 588, Loss: 64635.425781\n",
            "tensor([[ 9.1071, 16.0795,  2.5435,  ...,  0.6782, -0.2880,  2.6956],\n",
            "        [ 9.1071, 16.0795,  2.5435,  ...,  0.6782, -0.2880,  2.6956],\n",
            "        [ 9.1071, 16.0795,  2.5435,  ...,  0.6782, -0.2880,  2.6956],\n",
            "        ...,\n",
            "        [ 9.1071, 16.0795,  2.5435,  ...,  0.6782, -0.2880,  2.6956],\n",
            "        [ 9.1071, 16.0795,  2.5435,  ...,  0.6782, -0.2880,  2.6956],\n",
            "        [ 9.1071, 16.0795,  2.5435,  ...,  0.6782, -0.2880,  2.6956]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 589, Loss: 64616.402344\n",
            "tensor([[ 9.1471, 16.1999,  2.5647,  ...,  0.7116, -0.2777,  2.7089],\n",
            "        [ 9.1471, 16.1999,  2.5647,  ...,  0.7116, -0.2777,  2.7089],\n",
            "        [ 9.1471, 16.1999,  2.5647,  ...,  0.7116, -0.2777,  2.7089],\n",
            "        ...,\n",
            "        [ 9.1471, 16.1999,  2.5647,  ...,  0.7116, -0.2777,  2.7089],\n",
            "        [ 9.1471, 16.1999,  2.5647,  ...,  0.7116, -0.2777,  2.7089],\n",
            "        [ 9.1471, 16.1999,  2.5647,  ...,  0.7116, -0.2777,  2.7089]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 590, Loss: 64597.371094\n",
            "tensor([[ 9.1870, 16.3203,  2.5859,  ...,  0.7450, -0.2675,  2.7222],\n",
            "        [ 9.1870, 16.3203,  2.5859,  ...,  0.7450, -0.2675,  2.7222],\n",
            "        [ 9.1870, 16.3203,  2.5859,  ...,  0.7450, -0.2675,  2.7222],\n",
            "        ...,\n",
            "        [ 9.1870, 16.3203,  2.5859,  ...,  0.7450, -0.2675,  2.7222],\n",
            "        [ 9.1870, 16.3203,  2.5859,  ...,  0.7450, -0.2675,  2.7222],\n",
            "        [ 9.1870, 16.3203,  2.5859,  ...,  0.7450, -0.2675,  2.7222]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 591, Loss: 64578.351562\n",
            "tensor([[ 9.2270, 16.4407,  2.6071,  ...,  0.7784, -0.2572,  2.7354],\n",
            "        [ 9.2270, 16.4407,  2.6071,  ...,  0.7784, -0.2572,  2.7354],\n",
            "        [ 9.2270, 16.4407,  2.6071,  ...,  0.7784, -0.2572,  2.7354],\n",
            "        ...,\n",
            "        [ 9.2270, 16.4407,  2.6071,  ...,  0.7784, -0.2572,  2.7354],\n",
            "        [ 9.2270, 16.4407,  2.6071,  ...,  0.7784, -0.2572,  2.7354],\n",
            "        [ 9.2270, 16.4407,  2.6071,  ...,  0.7784, -0.2572,  2.7354]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 592, Loss: 64559.343750\n",
            "tensor([[ 9.2670, 16.5610,  2.6284,  ...,  0.8118, -0.2469,  2.7487],\n",
            "        [ 9.2670, 16.5610,  2.6284,  ...,  0.8118, -0.2469,  2.7487],\n",
            "        [ 9.2670, 16.5610,  2.6284,  ...,  0.8118, -0.2469,  2.7487],\n",
            "        ...,\n",
            "        [ 9.2670, 16.5610,  2.6284,  ...,  0.8118, -0.2469,  2.7487],\n",
            "        [ 9.2670, 16.5610,  2.6284,  ...,  0.8118, -0.2469,  2.7487],\n",
            "        [ 9.2670, 16.5610,  2.6284,  ...,  0.8118, -0.2469,  2.7487]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 593, Loss: 64540.339844\n",
            "tensor([[ 9.3069, 16.6813,  2.6496,  ...,  0.8452, -0.2366,  2.7619],\n",
            "        [ 9.3069, 16.6813,  2.6496,  ...,  0.8452, -0.2366,  2.7619],\n",
            "        [ 9.3069, 16.6813,  2.6496,  ...,  0.8452, -0.2366,  2.7619],\n",
            "        ...,\n",
            "        [ 9.3069, 16.6813,  2.6496,  ...,  0.8452, -0.2366,  2.7619],\n",
            "        [ 9.3069, 16.6813,  2.6496,  ...,  0.8452, -0.2366,  2.7619],\n",
            "        [ 9.3069, 16.6813,  2.6496,  ...,  0.8452, -0.2366,  2.7619]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 594, Loss: 64521.351562\n",
            "tensor([[ 9.3468, 16.8016,  2.6708,  ...,  0.8786, -0.2263,  2.7752],\n",
            "        [ 9.3468, 16.8016,  2.6708,  ...,  0.8786, -0.2263,  2.7752],\n",
            "        [ 9.3468, 16.8016,  2.6708,  ...,  0.8786, -0.2263,  2.7752],\n",
            "        ...,\n",
            "        [ 9.3468, 16.8016,  2.6708,  ...,  0.8786, -0.2263,  2.7752],\n",
            "        [ 9.3468, 16.8016,  2.6708,  ...,  0.8786, -0.2263,  2.7752],\n",
            "        [ 9.3468, 16.8016,  2.6708,  ...,  0.8786, -0.2263,  2.7752]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 595, Loss: 64502.355469\n",
            "tensor([[ 9.3868, 16.9219,  2.6920,  ...,  0.9120, -0.2161,  2.7884],\n",
            "        [ 9.3868, 16.9219,  2.6920,  ...,  0.9120, -0.2161,  2.7884],\n",
            "        [ 9.3868, 16.9219,  2.6920,  ...,  0.9120, -0.2161,  2.7884],\n",
            "        ...,\n",
            "        [ 9.3868, 16.9219,  2.6920,  ...,  0.9120, -0.2161,  2.7884],\n",
            "        [ 9.3868, 16.9219,  2.6920,  ...,  0.9120, -0.2161,  2.7884],\n",
            "        [ 9.3868, 16.9219,  2.6920,  ...,  0.9120, -0.2161,  2.7884]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 596, Loss: 64483.382812\n",
            "tensor([[ 9.4267, 17.0421,  2.7132,  ...,  0.9454, -0.2058,  2.8017],\n",
            "        [ 9.4267, 17.0421,  2.7132,  ...,  0.9454, -0.2058,  2.8017],\n",
            "        [ 9.4267, 17.0421,  2.7132,  ...,  0.9454, -0.2058,  2.8017],\n",
            "        ...,\n",
            "        [ 9.4267, 17.0421,  2.7132,  ...,  0.9454, -0.2058,  2.8017],\n",
            "        [ 9.4267, 17.0421,  2.7132,  ...,  0.9454, -0.2058,  2.8017],\n",
            "        [ 9.4267, 17.0421,  2.7132,  ...,  0.9454, -0.2058,  2.8017]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 597, Loss: 64464.406250\n",
            "tensor([[ 9.4666, 17.1623,  2.7344,  ...,  0.9787, -0.1955,  2.8149],\n",
            "        [ 9.4666, 17.1623,  2.7344,  ...,  0.9787, -0.1955,  2.8149],\n",
            "        [ 9.4666, 17.1623,  2.7344,  ...,  0.9787, -0.1955,  2.8149],\n",
            "        ...,\n",
            "        [ 9.4666, 17.1623,  2.7344,  ...,  0.9787, -0.1955,  2.8149],\n",
            "        [ 9.4666, 17.1623,  2.7344,  ...,  0.9787, -0.1955,  2.8149],\n",
            "        [ 9.4666, 17.1623,  2.7344,  ...,  0.9787, -0.1955,  2.8149]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 598, Loss: 64445.449219\n",
            "tensor([[ 9.5065, 17.2825,  2.7556,  ...,  1.0121, -0.1852,  2.8282],\n",
            "        [ 9.5065, 17.2825,  2.7556,  ...,  1.0121, -0.1852,  2.8282],\n",
            "        [ 9.5065, 17.2825,  2.7556,  ...,  1.0121, -0.1852,  2.8282],\n",
            "        ...,\n",
            "        [ 9.5065, 17.2825,  2.7556,  ...,  1.0121, -0.1852,  2.8282],\n",
            "        [ 9.5065, 17.2825,  2.7556,  ...,  1.0121, -0.1852,  2.8282],\n",
            "        [ 9.5065, 17.2825,  2.7556,  ...,  1.0121, -0.1852,  2.8282]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 599, Loss: 64426.492188\n",
            "tensor([[ 9.5464, 17.4027,  2.7768,  ...,  1.0454, -0.1750,  2.8414],\n",
            "        [ 9.5464, 17.4027,  2.7768,  ...,  1.0454, -0.1750,  2.8414],\n",
            "        [ 9.5464, 17.4027,  2.7768,  ...,  1.0454, -0.1750,  2.8414],\n",
            "        ...,\n",
            "        [ 9.5464, 17.4027,  2.7768,  ...,  1.0454, -0.1750,  2.8414],\n",
            "        [ 9.5464, 17.4027,  2.7768,  ...,  1.0454, -0.1750,  2.8414],\n",
            "        [ 9.5464, 17.4027,  2.7768,  ...,  1.0454, -0.1750,  2.8414]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 600, Loss: 64407.546875\n",
            "tensor([[ 9.5863, 17.5229,  2.7979,  ...,  1.0788, -0.1647,  2.8547],\n",
            "        [ 9.5863, 17.5229,  2.7979,  ...,  1.0788, -0.1647,  2.8547],\n",
            "        [ 9.5863, 17.5229,  2.7979,  ...,  1.0788, -0.1647,  2.8547],\n",
            "        ...,\n",
            "        [ 9.5863, 17.5229,  2.7979,  ...,  1.0788, -0.1647,  2.8547],\n",
            "        [ 9.5863, 17.5229,  2.7979,  ...,  1.0788, -0.1647,  2.8547],\n",
            "        [ 9.5863, 17.5229,  2.7979,  ...,  1.0788, -0.1647,  2.8547]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 601, Loss: 64388.605469\n",
            "tensor([[ 9.6262, 17.6430,  2.8191,  ...,  1.1121, -0.1544,  2.8679],\n",
            "        [ 9.6262, 17.6430,  2.8191,  ...,  1.1121, -0.1544,  2.8679],\n",
            "        [ 9.6262, 17.6430,  2.8191,  ...,  1.1121, -0.1544,  2.8679],\n",
            "        ...,\n",
            "        [ 9.6262, 17.6430,  2.8191,  ...,  1.1121, -0.1544,  2.8679],\n",
            "        [ 9.6262, 17.6430,  2.8191,  ...,  1.1121, -0.1544,  2.8679],\n",
            "        [ 9.6262, 17.6430,  2.8191,  ...,  1.1121, -0.1544,  2.8679]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 602, Loss: 64369.671875\n",
            "tensor([[ 9.6661, 17.7631,  2.8403,  ...,  1.1455, -0.1442,  2.8811],\n",
            "        [ 9.6661, 17.7631,  2.8403,  ...,  1.1455, -0.1442,  2.8811],\n",
            "        [ 9.6661, 17.7631,  2.8403,  ...,  1.1455, -0.1442,  2.8811],\n",
            "        ...,\n",
            "        [ 9.6661, 17.7631,  2.8403,  ...,  1.1455, -0.1442,  2.8811],\n",
            "        [ 9.6661, 17.7631,  2.8403,  ...,  1.1455, -0.1442,  2.8811],\n",
            "        [ 9.6661, 17.7631,  2.8403,  ...,  1.1455, -0.1442,  2.8811]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 603, Loss: 64350.742188\n",
            "tensor([[ 9.7059, 17.8832,  2.8615,  ...,  1.1788, -0.1339,  2.8944],\n",
            "        [ 9.7059, 17.8832,  2.8615,  ...,  1.1788, -0.1339,  2.8944],\n",
            "        [ 9.7059, 17.8832,  2.8615,  ...,  1.1788, -0.1339,  2.8944],\n",
            "        ...,\n",
            "        [ 9.7059, 17.8832,  2.8615,  ...,  1.1788, -0.1339,  2.8944],\n",
            "        [ 9.7059, 17.8832,  2.8615,  ...,  1.1788, -0.1339,  2.8944],\n",
            "        [ 9.7059, 17.8832,  2.8615,  ...,  1.1788, -0.1339,  2.8944]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 604, Loss: 64331.824219\n",
            "tensor([[ 9.7458, 18.0032,  2.8826,  ...,  1.2121, -0.1236,  2.9076],\n",
            "        [ 9.7458, 18.0032,  2.8826,  ...,  1.2121, -0.1236,  2.9076],\n",
            "        [ 9.7458, 18.0032,  2.8826,  ...,  1.2121, -0.1236,  2.9076],\n",
            "        ...,\n",
            "        [ 9.7458, 18.0032,  2.8826,  ...,  1.2121, -0.1236,  2.9076],\n",
            "        [ 9.7458, 18.0032,  2.8826,  ...,  1.2121, -0.1236,  2.9076],\n",
            "        [ 9.7458, 18.0032,  2.8826,  ...,  1.2121, -0.1236,  2.9076]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 605, Loss: 64312.917969\n",
            "tensor([[ 9.7856, 18.1232,  2.9038,  ...,  1.2454, -0.1134,  2.9208],\n",
            "        [ 9.7856, 18.1232,  2.9038,  ...,  1.2454, -0.1134,  2.9208],\n",
            "        [ 9.7856, 18.1232,  2.9038,  ...,  1.2454, -0.1134,  2.9208],\n",
            "        ...,\n",
            "        [ 9.7856, 18.1232,  2.9038,  ...,  1.2454, -0.1134,  2.9208],\n",
            "        [ 9.7856, 18.1232,  2.9038,  ...,  1.2454, -0.1134,  2.9208],\n",
            "        [ 9.7856, 18.1232,  2.9038,  ...,  1.2454, -0.1134,  2.9208]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 606, Loss: 64294.007812\n",
            "tensor([[ 9.8255, 18.2432,  2.9249,  ...,  1.2787, -0.1031,  2.9340],\n",
            "        [ 9.8255, 18.2432,  2.9249,  ...,  1.2787, -0.1031,  2.9340],\n",
            "        [ 9.8255, 18.2432,  2.9249,  ...,  1.2787, -0.1031,  2.9340],\n",
            "        ...,\n",
            "        [ 9.8255, 18.2432,  2.9249,  ...,  1.2787, -0.1031,  2.9340],\n",
            "        [ 9.8255, 18.2432,  2.9249,  ...,  1.2787, -0.1031,  2.9340],\n",
            "        [ 9.8255, 18.2432,  2.9249,  ...,  1.2787, -0.1031,  2.9340]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 607, Loss: 64275.105469\n",
            "tensor([[ 9.8653, 18.3632,  2.9461,  ...,  1.3120, -0.0929,  2.9473],\n",
            "        [ 9.8653, 18.3632,  2.9461,  ...,  1.3120, -0.0929,  2.9473],\n",
            "        [ 9.8653, 18.3632,  2.9461,  ...,  1.3120, -0.0929,  2.9473],\n",
            "        ...,\n",
            "        [ 9.8653, 18.3632,  2.9461,  ...,  1.3120, -0.0929,  2.9473],\n",
            "        [ 9.8653, 18.3632,  2.9461,  ...,  1.3120, -0.0929,  2.9473],\n",
            "        [ 9.8653, 18.3632,  2.9461,  ...,  1.3120, -0.0929,  2.9473]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 608, Loss: 64256.230469\n",
            "tensor([[ 9.9051, 18.4832,  2.9672,  ...,  1.3453, -0.0826,  2.9605],\n",
            "        [ 9.9051, 18.4832,  2.9672,  ...,  1.3453, -0.0826,  2.9605],\n",
            "        [ 9.9051, 18.4832,  2.9672,  ...,  1.3453, -0.0826,  2.9605],\n",
            "        ...,\n",
            "        [ 9.9051, 18.4832,  2.9672,  ...,  1.3453, -0.0826,  2.9605],\n",
            "        [ 9.9051, 18.4832,  2.9672,  ...,  1.3453, -0.0826,  2.9605],\n",
            "        [ 9.9051, 18.4832,  2.9672,  ...,  1.3453, -0.0826,  2.9605]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 609, Loss: 64237.347656\n",
            "tensor([[ 9.9450, 18.6031,  2.9884,  ...,  1.3786, -0.0724,  2.9737],\n",
            "        [ 9.9450, 18.6031,  2.9884,  ...,  1.3786, -0.0724,  2.9737],\n",
            "        [ 9.9450, 18.6031,  2.9884,  ...,  1.3786, -0.0724,  2.9737],\n",
            "        ...,\n",
            "        [ 9.9450, 18.6031,  2.9884,  ...,  1.3786, -0.0724,  2.9737],\n",
            "        [ 9.9450, 18.6031,  2.9884,  ...,  1.3786, -0.0724,  2.9737],\n",
            "        [ 9.9450, 18.6031,  2.9884,  ...,  1.3786, -0.0724,  2.9737]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 610, Loss: 64218.468750\n",
            "tensor([[ 9.9848, 18.7230,  3.0095,  ...,  1.4119, -0.0621,  2.9869],\n",
            "        [ 9.9848, 18.7230,  3.0095,  ...,  1.4119, -0.0621,  2.9869],\n",
            "        [ 9.9848, 18.7230,  3.0095,  ...,  1.4119, -0.0621,  2.9869],\n",
            "        ...,\n",
            "        [ 9.9848, 18.7230,  3.0095,  ...,  1.4119, -0.0621,  2.9869],\n",
            "        [ 9.9848, 18.7230,  3.0095,  ...,  1.4119, -0.0621,  2.9869],\n",
            "        [ 9.9848, 18.7230,  3.0095,  ...,  1.4119, -0.0621,  2.9869]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 611, Loss: 64199.597656\n",
            "tensor([[10.0246, 18.8429,  3.0306,  ...,  1.4452, -0.0519,  3.0001],\n",
            "        [10.0246, 18.8429,  3.0306,  ...,  1.4452, -0.0519,  3.0001],\n",
            "        [10.0246, 18.8429,  3.0306,  ...,  1.4452, -0.0519,  3.0001],\n",
            "        ...,\n",
            "        [10.0246, 18.8429,  3.0306,  ...,  1.4452, -0.0519,  3.0001],\n",
            "        [10.0246, 18.8429,  3.0306,  ...,  1.4452, -0.0519,  3.0001],\n",
            "        [10.0246, 18.8429,  3.0306,  ...,  1.4452, -0.0519,  3.0001]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 612, Loss: 64180.746094\n",
            "tensor([[10.0644, 18.9628,  3.0518,  ...,  1.4784, -0.0416,  3.0133],\n",
            "        [10.0644, 18.9628,  3.0518,  ...,  1.4784, -0.0416,  3.0133],\n",
            "        [10.0644, 18.9628,  3.0518,  ...,  1.4784, -0.0416,  3.0133],\n",
            "        ...,\n",
            "        [10.0644, 18.9628,  3.0518,  ...,  1.4784, -0.0416,  3.0133],\n",
            "        [10.0644, 18.9628,  3.0518,  ...,  1.4784, -0.0416,  3.0133],\n",
            "        [10.0644, 18.9628,  3.0518,  ...,  1.4784, -0.0416,  3.0133]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 613, Loss: 64161.894531\n",
            "tensor([[10.1042, 19.0826,  3.0729,  ...,  1.5117, -0.0314,  3.0265],\n",
            "        [10.1042, 19.0826,  3.0729,  ...,  1.5117, -0.0314,  3.0265],\n",
            "        [10.1042, 19.0826,  3.0729,  ...,  1.5117, -0.0314,  3.0265],\n",
            "        ...,\n",
            "        [10.1042, 19.0826,  3.0729,  ...,  1.5117, -0.0314,  3.0265],\n",
            "        [10.1042, 19.0826,  3.0729,  ...,  1.5117, -0.0314,  3.0265],\n",
            "        [10.1042, 19.0826,  3.0729,  ...,  1.5117, -0.0314,  3.0265]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 614, Loss: 64143.050781\n",
            "tensor([[10.1439, 19.2024,  3.0940,  ...,  1.5449, -0.0212,  3.0397],\n",
            "        [10.1439, 19.2024,  3.0940,  ...,  1.5449, -0.0212,  3.0397],\n",
            "        [10.1439, 19.2024,  3.0940,  ...,  1.5449, -0.0212,  3.0397],\n",
            "        ...,\n",
            "        [10.1439, 19.2024,  3.0940,  ...,  1.5449, -0.0212,  3.0397],\n",
            "        [10.1439, 19.2024,  3.0940,  ...,  1.5449, -0.0212,  3.0397],\n",
            "        [10.1439, 19.2024,  3.0940,  ...,  1.5449, -0.0212,  3.0397]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 615, Loss: 64124.218750\n",
            "tensor([[ 1.0184e+01,  1.9322e+01,  3.1151e+00,  ...,  1.5782e+00,\n",
            "         -1.0930e-02,  3.0529e+00],\n",
            "        [ 1.0184e+01,  1.9322e+01,  3.1151e+00,  ...,  1.5782e+00,\n",
            "         -1.0930e-02,  3.0529e+00],\n",
            "        [ 1.0184e+01,  1.9322e+01,  3.1151e+00,  ...,  1.5782e+00,\n",
            "         -1.0930e-02,  3.0529e+00],\n",
            "        ...,\n",
            "        [ 1.0184e+01,  1.9322e+01,  3.1151e+00,  ...,  1.5782e+00,\n",
            "         -1.0930e-02,  3.0529e+00],\n",
            "        [ 1.0184e+01,  1.9322e+01,  3.1151e+00,  ...,  1.5782e+00,\n",
            "         -1.0930e-02,  3.0529e+00],\n",
            "        [ 1.0184e+01,  1.9322e+01,  3.1151e+00,  ...,  1.5782e+00,\n",
            "         -1.0930e-02,  3.0529e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 616, Loss: 64105.386719\n",
            "tensor([[ 1.0223e+01,  1.9442e+01,  3.1363e+00,  ...,  1.6114e+00,\n",
            "         -6.9510e-04,  3.0661e+00],\n",
            "        [ 1.0223e+01,  1.9442e+01,  3.1363e+00,  ...,  1.6114e+00,\n",
            "         -6.9510e-04,  3.0661e+00],\n",
            "        [ 1.0223e+01,  1.9442e+01,  3.1363e+00,  ...,  1.6114e+00,\n",
            "         -6.9510e-04,  3.0661e+00],\n",
            "        ...,\n",
            "        [ 1.0223e+01,  1.9442e+01,  3.1363e+00,  ...,  1.6114e+00,\n",
            "         -6.9510e-04,  3.0661e+00],\n",
            "        [ 1.0223e+01,  1.9442e+01,  3.1363e+00,  ...,  1.6114e+00,\n",
            "         -6.9510e-04,  3.0661e+00],\n",
            "        [ 1.0223e+01,  1.9442e+01,  3.1363e+00,  ...,  1.6114e+00,\n",
            "         -6.9510e-04,  3.0661e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 617, Loss: 64086.570312\n",
            "tensor([[1.0263e+01, 1.9562e+01, 3.1574e+00,  ..., 1.6446e+00, 9.5374e-03,\n",
            "         3.0793e+00],\n",
            "        [1.0263e+01, 1.9562e+01, 3.1574e+00,  ..., 1.6446e+00, 9.5374e-03,\n",
            "         3.0793e+00],\n",
            "        [1.0263e+01, 1.9562e+01, 3.1574e+00,  ..., 1.6446e+00, 9.5374e-03,\n",
            "         3.0793e+00],\n",
            "        ...,\n",
            "        [1.0263e+01, 1.9562e+01, 3.1574e+00,  ..., 1.6446e+00, 9.5374e-03,\n",
            "         3.0793e+00],\n",
            "        [1.0263e+01, 1.9562e+01, 3.1574e+00,  ..., 1.6446e+00, 9.5374e-03,\n",
            "         3.0793e+00],\n",
            "        [1.0263e+01, 1.9562e+01, 3.1574e+00,  ..., 1.6446e+00, 9.5374e-03,\n",
            "         3.0793e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 618, Loss: 64067.761719\n",
            "tensor([[10.3030, 19.6814,  3.1785,  ...,  1.6779,  0.0198,  3.0925],\n",
            "        [10.3030, 19.6814,  3.1785,  ...,  1.6779,  0.0198,  3.0925],\n",
            "        [10.3030, 19.6814,  3.1785,  ...,  1.6779,  0.0198,  3.0925],\n",
            "        ...,\n",
            "        [10.3030, 19.6814,  3.1785,  ...,  1.6779,  0.0198,  3.0925],\n",
            "        [10.3030, 19.6814,  3.1785,  ...,  1.6779,  0.0198,  3.0925],\n",
            "        [10.3030, 19.6814,  3.1785,  ...,  1.6779,  0.0198,  3.0925]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 619, Loss: 64048.949219\n",
            "tensor([[10.3427, 19.8011,  3.1996,  ...,  1.7111,  0.0300,  3.1057],\n",
            "        [10.3427, 19.8011,  3.1996,  ...,  1.7111,  0.0300,  3.1057],\n",
            "        [10.3427, 19.8011,  3.1996,  ...,  1.7111,  0.0300,  3.1057],\n",
            "        ...,\n",
            "        [10.3427, 19.8011,  3.1996,  ...,  1.7111,  0.0300,  3.1057],\n",
            "        [10.3427, 19.8011,  3.1996,  ...,  1.7111,  0.0300,  3.1057],\n",
            "        [10.3427, 19.8011,  3.1996,  ...,  1.7111,  0.0300,  3.1057]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 620, Loss: 64030.152344\n",
            "tensor([[10.3824, 19.9208,  3.2207,  ...,  1.7443,  0.0402,  3.1189],\n",
            "        [10.3824, 19.9208,  3.2207,  ...,  1.7443,  0.0402,  3.1189],\n",
            "        [10.3824, 19.9208,  3.2207,  ...,  1.7443,  0.0402,  3.1189],\n",
            "        ...,\n",
            "        [10.3824, 19.9208,  3.2207,  ...,  1.7443,  0.0402,  3.1189],\n",
            "        [10.3824, 19.9208,  3.2207,  ...,  1.7443,  0.0402,  3.1189],\n",
            "        [10.3824, 19.9208,  3.2207,  ...,  1.7443,  0.0402,  3.1189]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 621, Loss: 64011.363281\n",
            "tensor([[10.4222, 20.0404,  3.2418,  ...,  1.7775,  0.0504,  3.1321],\n",
            "        [10.4222, 20.0404,  3.2418,  ...,  1.7775,  0.0504,  3.1321],\n",
            "        [10.4222, 20.0404,  3.2418,  ...,  1.7775,  0.0504,  3.1321],\n",
            "        ...,\n",
            "        [10.4222, 20.0404,  3.2418,  ...,  1.7775,  0.0504,  3.1321],\n",
            "        [10.4222, 20.0404,  3.2418,  ...,  1.7775,  0.0504,  3.1321],\n",
            "        [10.4222, 20.0404,  3.2418,  ...,  1.7775,  0.0504,  3.1321]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 622, Loss: 63992.582031\n",
            "tensor([[10.4619, 20.1600,  3.2628,  ...,  1.8107,  0.0607,  3.1452],\n",
            "        [10.4619, 20.1600,  3.2628,  ...,  1.8107,  0.0607,  3.1452],\n",
            "        [10.4619, 20.1600,  3.2628,  ...,  1.8107,  0.0607,  3.1452],\n",
            "        ...,\n",
            "        [10.4619, 20.1600,  3.2628,  ...,  1.8107,  0.0607,  3.1452],\n",
            "        [10.4619, 20.1600,  3.2628,  ...,  1.8107,  0.0607,  3.1452],\n",
            "        [10.4619, 20.1600,  3.2628,  ...,  1.8107,  0.0607,  3.1452]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 623, Loss: 63973.804688\n",
            "tensor([[10.5016, 20.2796,  3.2839,  ...,  1.8439,  0.0709,  3.1584],\n",
            "        [10.5016, 20.2796,  3.2839,  ...,  1.8439,  0.0709,  3.1584],\n",
            "        [10.5016, 20.2796,  3.2839,  ...,  1.8439,  0.0709,  3.1584],\n",
            "        ...,\n",
            "        [10.5016, 20.2796,  3.2839,  ...,  1.8439,  0.0709,  3.1584],\n",
            "        [10.5016, 20.2796,  3.2839,  ...,  1.8439,  0.0709,  3.1584],\n",
            "        [10.5016, 20.2796,  3.2839,  ...,  1.8439,  0.0709,  3.1584]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 624, Loss: 63955.031250\n",
            "tensor([[10.5413, 20.3992,  3.3050,  ...,  1.8771,  0.0811,  3.1716],\n",
            "        [10.5413, 20.3992,  3.3050,  ...,  1.8771,  0.0811,  3.1716],\n",
            "        [10.5413, 20.3992,  3.3050,  ...,  1.8771,  0.0811,  3.1716],\n",
            "        ...,\n",
            "        [10.5413, 20.3992,  3.3050,  ...,  1.8771,  0.0811,  3.1716],\n",
            "        [10.5413, 20.3992,  3.3050,  ...,  1.8771,  0.0811,  3.1716],\n",
            "        [10.5413, 20.3992,  3.3050,  ...,  1.8771,  0.0811,  3.1716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 625, Loss: 63936.273438\n",
            "tensor([[10.5810, 20.5187,  3.3261,  ...,  1.9103,  0.0913,  3.1848],\n",
            "        [10.5810, 20.5187,  3.3261,  ...,  1.9103,  0.0913,  3.1848],\n",
            "        [10.5810, 20.5187,  3.3261,  ...,  1.9103,  0.0913,  3.1848],\n",
            "        ...,\n",
            "        [10.5810, 20.5187,  3.3261,  ...,  1.9103,  0.0913,  3.1848],\n",
            "        [10.5810, 20.5187,  3.3261,  ...,  1.9103,  0.0913,  3.1848],\n",
            "        [10.5810, 20.5187,  3.3261,  ...,  1.9103,  0.0913,  3.1848]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 626, Loss: 63917.519531\n",
            "tensor([[10.6207, 20.6383,  3.3472,  ...,  1.9434,  0.1015,  3.1979],\n",
            "        [10.6207, 20.6383,  3.3472,  ...,  1.9434,  0.1015,  3.1979],\n",
            "        [10.6207, 20.6383,  3.3472,  ...,  1.9434,  0.1015,  3.1979],\n",
            "        ...,\n",
            "        [10.6207, 20.6383,  3.3472,  ...,  1.9434,  0.1015,  3.1979],\n",
            "        [10.6207, 20.6383,  3.3472,  ...,  1.9434,  0.1015,  3.1979],\n",
            "        [10.6207, 20.6383,  3.3472,  ...,  1.9434,  0.1015,  3.1979]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 627, Loss: 63898.773438\n",
            "tensor([[10.6603, 20.7578,  3.3682,  ...,  1.9766,  0.1118,  3.2111],\n",
            "        [10.6603, 20.7578,  3.3682,  ...,  1.9766,  0.1118,  3.2111],\n",
            "        [10.6603, 20.7578,  3.3682,  ...,  1.9766,  0.1118,  3.2111],\n",
            "        ...,\n",
            "        [10.6603, 20.7578,  3.3682,  ...,  1.9766,  0.1118,  3.2111],\n",
            "        [10.6603, 20.7578,  3.3682,  ...,  1.9766,  0.1118,  3.2111],\n",
            "        [10.6603, 20.7578,  3.3682,  ...,  1.9766,  0.1118,  3.2111]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 628, Loss: 63880.039062\n",
            "tensor([[10.7000, 20.8773,  3.3893,  ...,  2.0098,  0.1220,  3.2243],\n",
            "        [10.7000, 20.8773,  3.3893,  ...,  2.0098,  0.1220,  3.2243],\n",
            "        [10.7000, 20.8773,  3.3893,  ...,  2.0098,  0.1220,  3.2243],\n",
            "        ...,\n",
            "        [10.7000, 20.8773,  3.3893,  ...,  2.0098,  0.1220,  3.2243],\n",
            "        [10.7000, 20.8773,  3.3893,  ...,  2.0098,  0.1220,  3.2243],\n",
            "        [10.7000, 20.8773,  3.3893,  ...,  2.0098,  0.1220,  3.2243]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 629, Loss: 63861.312500\n",
            "tensor([[10.7397, 20.9967,  3.4103,  ...,  2.0429,  0.1322,  3.2374],\n",
            "        [10.7397, 20.9967,  3.4103,  ...,  2.0429,  0.1322,  3.2374],\n",
            "        [10.7397, 20.9967,  3.4103,  ...,  2.0429,  0.1322,  3.2374],\n",
            "        ...,\n",
            "        [10.7397, 20.9967,  3.4103,  ...,  2.0429,  0.1322,  3.2374],\n",
            "        [10.7397, 20.9967,  3.4103,  ...,  2.0429,  0.1322,  3.2374],\n",
            "        [10.7397, 20.9967,  3.4103,  ...,  2.0429,  0.1322,  3.2374]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 630, Loss: 63842.589844\n",
            "tensor([[10.7793, 21.1161,  3.4314,  ...,  2.0761,  0.1424,  3.2506],\n",
            "        [10.7793, 21.1161,  3.4314,  ...,  2.0761,  0.1424,  3.2506],\n",
            "        [10.7793, 21.1161,  3.4314,  ...,  2.0761,  0.1424,  3.2506],\n",
            "        ...,\n",
            "        [10.7793, 21.1161,  3.4314,  ...,  2.0761,  0.1424,  3.2506],\n",
            "        [10.7793, 21.1161,  3.4314,  ...,  2.0761,  0.1424,  3.2506],\n",
            "        [10.7793, 21.1161,  3.4314,  ...,  2.0761,  0.1424,  3.2506]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 631, Loss: 63823.871094\n",
            "tensor([[10.8190, 21.2355,  3.4525,  ...,  2.1092,  0.1526,  3.2637],\n",
            "        [10.8190, 21.2355,  3.4525,  ...,  2.1092,  0.1526,  3.2637],\n",
            "        [10.8190, 21.2355,  3.4525,  ...,  2.1092,  0.1526,  3.2637],\n",
            "        ...,\n",
            "        [10.8190, 21.2355,  3.4525,  ...,  2.1092,  0.1526,  3.2637],\n",
            "        [10.8190, 21.2355,  3.4525,  ...,  2.1092,  0.1526,  3.2637],\n",
            "        [10.8190, 21.2355,  3.4525,  ...,  2.1092,  0.1526,  3.2637]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 632, Loss: 63805.160156\n",
            "tensor([[10.8586, 21.3549,  3.4735,  ...,  2.1423,  0.1628,  3.2769],\n",
            "        [10.8586, 21.3549,  3.4735,  ...,  2.1423,  0.1628,  3.2769],\n",
            "        [10.8586, 21.3549,  3.4735,  ...,  2.1423,  0.1628,  3.2769],\n",
            "        ...,\n",
            "        [10.8586, 21.3549,  3.4735,  ...,  2.1423,  0.1628,  3.2769],\n",
            "        [10.8586, 21.3549,  3.4735,  ...,  2.1423,  0.1628,  3.2769],\n",
            "        [10.8586, 21.3549,  3.4735,  ...,  2.1423,  0.1628,  3.2769]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 633, Loss: 63786.460938\n",
            "tensor([[10.8982, 21.4743,  3.4945,  ...,  2.1755,  0.1730,  3.2901],\n",
            "        [10.8982, 21.4743,  3.4945,  ...,  2.1755,  0.1730,  3.2901],\n",
            "        [10.8982, 21.4743,  3.4945,  ...,  2.1755,  0.1730,  3.2901],\n",
            "        ...,\n",
            "        [10.8982, 21.4743,  3.4945,  ...,  2.1755,  0.1730,  3.2901],\n",
            "        [10.8982, 21.4743,  3.4945,  ...,  2.1755,  0.1730,  3.2901],\n",
            "        [10.8982, 21.4743,  3.4945,  ...,  2.1755,  0.1730,  3.2901]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 634, Loss: 63767.769531\n",
            "tensor([[10.9378, 21.5936,  3.5156,  ...,  2.2086,  0.1832,  3.3032],\n",
            "        [10.9378, 21.5936,  3.5156,  ...,  2.2086,  0.1832,  3.3032],\n",
            "        [10.9378, 21.5936,  3.5156,  ...,  2.2086,  0.1832,  3.3032],\n",
            "        ...,\n",
            "        [10.9378, 21.5936,  3.5156,  ...,  2.2086,  0.1832,  3.3032],\n",
            "        [10.9378, 21.5936,  3.5156,  ...,  2.2086,  0.1832,  3.3032],\n",
            "        [10.9378, 21.5936,  3.5156,  ...,  2.2086,  0.1832,  3.3032]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 635, Loss: 63749.085938\n",
            "tensor([[10.9774, 21.7129,  3.5366,  ...,  2.2417,  0.1934,  3.3163],\n",
            "        [10.9774, 21.7129,  3.5366,  ...,  2.2417,  0.1934,  3.3163],\n",
            "        [10.9774, 21.7129,  3.5366,  ...,  2.2417,  0.1934,  3.3163],\n",
            "        ...,\n",
            "        [10.9774, 21.7129,  3.5366,  ...,  2.2417,  0.1934,  3.3163],\n",
            "        [10.9774, 21.7129,  3.5366,  ...,  2.2417,  0.1934,  3.3163],\n",
            "        [10.9774, 21.7129,  3.5366,  ...,  2.2417,  0.1934,  3.3163]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 636, Loss: 63730.402344\n",
            "tensor([[11.0171, 21.8322,  3.5576,  ...,  2.2748,  0.2036,  3.3295],\n",
            "        [11.0171, 21.8322,  3.5576,  ...,  2.2748,  0.2036,  3.3295],\n",
            "        [11.0171, 21.8322,  3.5576,  ...,  2.2748,  0.2036,  3.3295],\n",
            "        ...,\n",
            "        [11.0171, 21.8322,  3.5576,  ...,  2.2748,  0.2036,  3.3295],\n",
            "        [11.0171, 21.8322,  3.5576,  ...,  2.2748,  0.2036,  3.3295],\n",
            "        [11.0171, 21.8322,  3.5576,  ...,  2.2748,  0.2036,  3.3295]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 637, Loss: 63711.734375\n",
            "tensor([[11.0566, 21.9515,  3.5787,  ...,  2.3079,  0.2138,  3.3426],\n",
            "        [11.0566, 21.9515,  3.5787,  ...,  2.3079,  0.2138,  3.3426],\n",
            "        [11.0566, 21.9515,  3.5787,  ...,  2.3079,  0.2138,  3.3426],\n",
            "        ...,\n",
            "        [11.0566, 21.9515,  3.5787,  ...,  2.3079,  0.2138,  3.3426],\n",
            "        [11.0566, 21.9515,  3.5787,  ...,  2.3079,  0.2138,  3.3426],\n",
            "        [11.0566, 21.9515,  3.5787,  ...,  2.3079,  0.2138,  3.3426]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 638, Loss: 63693.074219\n",
            "tensor([[11.0962, 22.0707,  3.5997,  ...,  2.3410,  0.2239,  3.3558],\n",
            "        [11.0962, 22.0707,  3.5997,  ...,  2.3410,  0.2239,  3.3558],\n",
            "        [11.0962, 22.0707,  3.5997,  ...,  2.3410,  0.2239,  3.3558],\n",
            "        ...,\n",
            "        [11.0962, 22.0707,  3.5997,  ...,  2.3410,  0.2239,  3.3558],\n",
            "        [11.0962, 22.0707,  3.5997,  ...,  2.3410,  0.2239,  3.3558],\n",
            "        [11.0962, 22.0707,  3.5997,  ...,  2.3410,  0.2239,  3.3558]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 639, Loss: 63674.414062\n",
            "tensor([[11.1358, 22.1899,  3.6207,  ...,  2.3741,  0.2341,  3.3689],\n",
            "        [11.1358, 22.1899,  3.6207,  ...,  2.3741,  0.2341,  3.3689],\n",
            "        [11.1358, 22.1899,  3.6207,  ...,  2.3741,  0.2341,  3.3689],\n",
            "        ...,\n",
            "        [11.1358, 22.1899,  3.6207,  ...,  2.3741,  0.2341,  3.3689],\n",
            "        [11.1358, 22.1899,  3.6207,  ...,  2.3741,  0.2341,  3.3689],\n",
            "        [11.1358, 22.1899,  3.6207,  ...,  2.3741,  0.2341,  3.3689]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 640, Loss: 63655.765625\n",
            "tensor([[11.1754, 22.3091,  3.6417,  ...,  2.4072,  0.2443,  3.3820],\n",
            "        [11.1754, 22.3091,  3.6417,  ...,  2.4072,  0.2443,  3.3820],\n",
            "        [11.1754, 22.3091,  3.6417,  ...,  2.4072,  0.2443,  3.3820],\n",
            "        ...,\n",
            "        [11.1754, 22.3091,  3.6417,  ...,  2.4072,  0.2443,  3.3820],\n",
            "        [11.1754, 22.3091,  3.6417,  ...,  2.4072,  0.2443,  3.3820],\n",
            "        [11.1754, 22.3091,  3.6417,  ...,  2.4072,  0.2443,  3.3820]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 641, Loss: 63637.128906\n",
            "tensor([[11.2150, 22.4283,  3.6627,  ...,  2.4402,  0.2545,  3.3952],\n",
            "        [11.2150, 22.4283,  3.6627,  ...,  2.4402,  0.2545,  3.3952],\n",
            "        [11.2150, 22.4283,  3.6627,  ...,  2.4402,  0.2545,  3.3952],\n",
            "        ...,\n",
            "        [11.2150, 22.4283,  3.6627,  ...,  2.4402,  0.2545,  3.3952],\n",
            "        [11.2150, 22.4283,  3.6627,  ...,  2.4402,  0.2545,  3.3952],\n",
            "        [11.2150, 22.4283,  3.6627,  ...,  2.4402,  0.2545,  3.3952]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 642, Loss: 63618.496094\n",
            "tensor([[11.2545, 22.5474,  3.6837,  ...,  2.4733,  0.2647,  3.4083],\n",
            "        [11.2545, 22.5474,  3.6837,  ...,  2.4733,  0.2647,  3.4083],\n",
            "        [11.2545, 22.5474,  3.6837,  ...,  2.4733,  0.2647,  3.4083],\n",
            "        ...,\n",
            "        [11.2545, 22.5474,  3.6837,  ...,  2.4733,  0.2647,  3.4083],\n",
            "        [11.2545, 22.5474,  3.6837,  ...,  2.4733,  0.2647,  3.4083],\n",
            "        [11.2545, 22.5474,  3.6837,  ...,  2.4733,  0.2647,  3.4083]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 643, Loss: 63599.871094\n",
            "tensor([[11.2941, 22.6665,  3.7047,  ...,  2.5064,  0.2749,  3.4214],\n",
            "        [11.2941, 22.6665,  3.7047,  ...,  2.5064,  0.2749,  3.4214],\n",
            "        [11.2941, 22.6665,  3.7047,  ...,  2.5064,  0.2749,  3.4214],\n",
            "        ...,\n",
            "        [11.2941, 22.6665,  3.7047,  ...,  2.5064,  0.2749,  3.4214],\n",
            "        [11.2941, 22.6665,  3.7047,  ...,  2.5064,  0.2749,  3.4214],\n",
            "        [11.2941, 22.6665,  3.7047,  ...,  2.5064,  0.2749,  3.4214]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 644, Loss: 63581.250000\n",
            "tensor([[11.3336, 22.7856,  3.7257,  ...,  2.5394,  0.2850,  3.4345],\n",
            "        [11.3336, 22.7856,  3.7257,  ...,  2.5394,  0.2850,  3.4345],\n",
            "        [11.3336, 22.7856,  3.7257,  ...,  2.5394,  0.2850,  3.4345],\n",
            "        ...,\n",
            "        [11.3336, 22.7856,  3.7257,  ...,  2.5394,  0.2850,  3.4345],\n",
            "        [11.3336, 22.7856,  3.7257,  ...,  2.5394,  0.2850,  3.4345],\n",
            "        [11.3336, 22.7856,  3.7257,  ...,  2.5394,  0.2850,  3.4345]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 645, Loss: 63562.640625\n",
            "tensor([[11.3731, 22.9047,  3.7467,  ...,  2.5725,  0.2952,  3.4477],\n",
            "        [11.3731, 22.9047,  3.7467,  ...,  2.5725,  0.2952,  3.4477],\n",
            "        [11.3731, 22.9047,  3.7467,  ...,  2.5725,  0.2952,  3.4477],\n",
            "        ...,\n",
            "        [11.3731, 22.9047,  3.7467,  ...,  2.5725,  0.2952,  3.4477],\n",
            "        [11.3731, 22.9047,  3.7467,  ...,  2.5725,  0.2952,  3.4477],\n",
            "        [11.3731, 22.9047,  3.7467,  ...,  2.5725,  0.2952,  3.4477]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 646, Loss: 63544.039062\n",
            "tensor([[11.4127, 23.0238,  3.7677,  ...,  2.6055,  0.3054,  3.4608],\n",
            "        [11.4127, 23.0238,  3.7677,  ...,  2.6055,  0.3054,  3.4608],\n",
            "        [11.4127, 23.0238,  3.7677,  ...,  2.6055,  0.3054,  3.4608],\n",
            "        ...,\n",
            "        [11.4127, 23.0238,  3.7677,  ...,  2.6055,  0.3054,  3.4608],\n",
            "        [11.4127, 23.0238,  3.7677,  ...,  2.6055,  0.3054,  3.4608],\n",
            "        [11.4127, 23.0238,  3.7677,  ...,  2.6055,  0.3054,  3.4608]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 647, Loss: 63525.441406\n",
            "tensor([[11.4522, 23.1428,  3.7887,  ...,  2.6385,  0.3156,  3.4739],\n",
            "        [11.4522, 23.1428,  3.7887,  ...,  2.6385,  0.3156,  3.4739],\n",
            "        [11.4522, 23.1428,  3.7887,  ...,  2.6385,  0.3156,  3.4739],\n",
            "        ...,\n",
            "        [11.4522, 23.1428,  3.7887,  ...,  2.6385,  0.3156,  3.4739],\n",
            "        [11.4522, 23.1428,  3.7887,  ...,  2.6385,  0.3156,  3.4739],\n",
            "        [11.4522, 23.1428,  3.7887,  ...,  2.6385,  0.3156,  3.4739]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 648, Loss: 63506.847656\n",
            "tensor([[11.4917, 23.2618,  3.8097,  ...,  2.6716,  0.3257,  3.4870],\n",
            "        [11.4917, 23.2618,  3.8097,  ...,  2.6716,  0.3257,  3.4870],\n",
            "        [11.4917, 23.2618,  3.8097,  ...,  2.6716,  0.3257,  3.4870],\n",
            "        ...,\n",
            "        [11.4917, 23.2618,  3.8097,  ...,  2.6716,  0.3257,  3.4870],\n",
            "        [11.4917, 23.2618,  3.8097,  ...,  2.6716,  0.3257,  3.4870],\n",
            "        [11.4917, 23.2618,  3.8097,  ...,  2.6716,  0.3257,  3.4870]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 649, Loss: 63488.269531\n",
            "tensor([[11.5312, 23.3808,  3.8306,  ...,  2.7046,  0.3359,  3.5001],\n",
            "        [11.5312, 23.3808,  3.8306,  ...,  2.7046,  0.3359,  3.5001],\n",
            "        [11.5312, 23.3808,  3.8306,  ...,  2.7046,  0.3359,  3.5001],\n",
            "        ...,\n",
            "        [11.5312, 23.3808,  3.8306,  ...,  2.7046,  0.3359,  3.5001],\n",
            "        [11.5312, 23.3808,  3.8306,  ...,  2.7046,  0.3359,  3.5001],\n",
            "        [11.5312, 23.3808,  3.8306,  ...,  2.7046,  0.3359,  3.5001]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 650, Loss: 63469.695312\n",
            "tensor([[11.5707, 23.4997,  3.8516,  ...,  2.7376,  0.3461,  3.5132],\n",
            "        [11.5707, 23.4997,  3.8516,  ...,  2.7376,  0.3461,  3.5132],\n",
            "        [11.5707, 23.4997,  3.8516,  ...,  2.7376,  0.3461,  3.5132],\n",
            "        ...,\n",
            "        [11.5707, 23.4997,  3.8516,  ...,  2.7376,  0.3461,  3.5132],\n",
            "        [11.5707, 23.4997,  3.8516,  ...,  2.7376,  0.3461,  3.5132],\n",
            "        [11.5707, 23.4997,  3.8516,  ...,  2.7376,  0.3461,  3.5132]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 651, Loss: 63451.125000\n",
            "tensor([[11.6102, 23.6186,  3.8726,  ...,  2.7706,  0.3562,  3.5263],\n",
            "        [11.6102, 23.6186,  3.8726,  ...,  2.7706,  0.3562,  3.5263],\n",
            "        [11.6102, 23.6186,  3.8726,  ...,  2.7706,  0.3562,  3.5263],\n",
            "        ...,\n",
            "        [11.6102, 23.6186,  3.8726,  ...,  2.7706,  0.3562,  3.5263],\n",
            "        [11.6102, 23.6186,  3.8726,  ...,  2.7706,  0.3562,  3.5263],\n",
            "        [11.6102, 23.6186,  3.8726,  ...,  2.7706,  0.3562,  3.5263]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 652, Loss: 63432.566406\n",
            "tensor([[11.6496, 23.7375,  3.8935,  ...,  2.8036,  0.3664,  3.5394],\n",
            "        [11.6496, 23.7375,  3.8935,  ...,  2.8036,  0.3664,  3.5394],\n",
            "        [11.6496, 23.7375,  3.8935,  ...,  2.8036,  0.3664,  3.5394],\n",
            "        ...,\n",
            "        [11.6496, 23.7375,  3.8935,  ...,  2.8036,  0.3664,  3.5394],\n",
            "        [11.6496, 23.7375,  3.8935,  ...,  2.8036,  0.3664,  3.5394],\n",
            "        [11.6496, 23.7375,  3.8935,  ...,  2.8036,  0.3664,  3.5394]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 653, Loss: 63414.019531\n",
            "tensor([[11.6891, 23.8564,  3.9145,  ...,  2.8366,  0.3765,  3.5525],\n",
            "        [11.6891, 23.8564,  3.9145,  ...,  2.8366,  0.3765,  3.5525],\n",
            "        [11.6891, 23.8564,  3.9145,  ...,  2.8366,  0.3765,  3.5525],\n",
            "        ...,\n",
            "        [11.6891, 23.8564,  3.9145,  ...,  2.8366,  0.3765,  3.5525],\n",
            "        [11.6891, 23.8564,  3.9145,  ...,  2.8366,  0.3765,  3.5525],\n",
            "        [11.6891, 23.8564,  3.9145,  ...,  2.8366,  0.3765,  3.5525]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 654, Loss: 63395.468750\n",
            "tensor([[11.7286, 23.9753,  3.9355,  ...,  2.8696,  0.3867,  3.5656],\n",
            "        [11.7286, 23.9753,  3.9355,  ...,  2.8696,  0.3867,  3.5656],\n",
            "        [11.7286, 23.9753,  3.9355,  ...,  2.8696,  0.3867,  3.5656],\n",
            "        ...,\n",
            "        [11.7286, 23.9753,  3.9355,  ...,  2.8696,  0.3867,  3.5656],\n",
            "        [11.7286, 23.9753,  3.9355,  ...,  2.8696,  0.3867,  3.5656],\n",
            "        [11.7286, 23.9753,  3.9355,  ...,  2.8696,  0.3867,  3.5656]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 655, Loss: 63376.929688\n",
            "tensor([[11.7680, 24.0941,  3.9564,  ...,  2.9026,  0.3969,  3.5787],\n",
            "        [11.7680, 24.0941,  3.9564,  ...,  2.9026,  0.3969,  3.5787],\n",
            "        [11.7680, 24.0941,  3.9564,  ...,  2.9026,  0.3969,  3.5787],\n",
            "        ...,\n",
            "        [11.7680, 24.0941,  3.9564,  ...,  2.9026,  0.3969,  3.5787],\n",
            "        [11.7680, 24.0941,  3.9564,  ...,  2.9026,  0.3969,  3.5787],\n",
            "        [11.7680, 24.0941,  3.9564,  ...,  2.9026,  0.3969,  3.5787]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 656, Loss: 63358.414062\n",
            "tensor([[11.8075, 24.2129,  3.9773,  ...,  2.9355,  0.4070,  3.5918],\n",
            "        [11.8075, 24.2129,  3.9773,  ...,  2.9355,  0.4070,  3.5918],\n",
            "        [11.8075, 24.2129,  3.9773,  ...,  2.9355,  0.4070,  3.5918],\n",
            "        ...,\n",
            "        [11.8075, 24.2129,  3.9773,  ...,  2.9355,  0.4070,  3.5918],\n",
            "        [11.8075, 24.2129,  3.9773,  ...,  2.9355,  0.4070,  3.5918],\n",
            "        [11.8075, 24.2129,  3.9773,  ...,  2.9355,  0.4070,  3.5918]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 657, Loss: 63339.886719\n",
            "tensor([[11.8469, 24.3317,  3.9983,  ...,  2.9685,  0.4172,  3.6049],\n",
            "        [11.8469, 24.3317,  3.9983,  ...,  2.9685,  0.4172,  3.6049],\n",
            "        [11.8469, 24.3317,  3.9983,  ...,  2.9685,  0.4172,  3.6049],\n",
            "        ...,\n",
            "        [11.8469, 24.3317,  3.9983,  ...,  2.9685,  0.4172,  3.6049],\n",
            "        [11.8469, 24.3317,  3.9983,  ...,  2.9685,  0.4172,  3.6049],\n",
            "        [11.8469, 24.3317,  3.9983,  ...,  2.9685,  0.4172,  3.6049]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 658, Loss: 63321.371094\n",
            "tensor([[11.8863, 24.4505,  4.0192,  ...,  3.0015,  0.4273,  3.6180],\n",
            "        [11.8863, 24.4505,  4.0192,  ...,  3.0015,  0.4273,  3.6180],\n",
            "        [11.8863, 24.4505,  4.0192,  ...,  3.0015,  0.4273,  3.6180],\n",
            "        ...,\n",
            "        [11.8863, 24.4505,  4.0192,  ...,  3.0015,  0.4273,  3.6180],\n",
            "        [11.8863, 24.4505,  4.0192,  ...,  3.0015,  0.4273,  3.6180],\n",
            "        [11.8863, 24.4505,  4.0192,  ...,  3.0015,  0.4273,  3.6180]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 659, Loss: 63302.863281\n",
            "tensor([[11.9258, 24.5692,  4.0402,  ...,  3.0344,  0.4375,  3.6311],\n",
            "        [11.9258, 24.5692,  4.0402,  ...,  3.0344,  0.4375,  3.6311],\n",
            "        [11.9258, 24.5692,  4.0402,  ...,  3.0344,  0.4375,  3.6311],\n",
            "        ...,\n",
            "        [11.9258, 24.5692,  4.0402,  ...,  3.0344,  0.4375,  3.6311],\n",
            "        [11.9258, 24.5692,  4.0402,  ...,  3.0344,  0.4375,  3.6311],\n",
            "        [11.9258, 24.5692,  4.0402,  ...,  3.0344,  0.4375,  3.6311]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 660, Loss: 63284.367188\n",
            "tensor([[11.9652, 24.6879,  4.0611,  ...,  3.0674,  0.4476,  3.6441],\n",
            "        [11.9652, 24.6879,  4.0611,  ...,  3.0674,  0.4476,  3.6441],\n",
            "        [11.9652, 24.6879,  4.0611,  ...,  3.0674,  0.4476,  3.6441],\n",
            "        ...,\n",
            "        [11.9652, 24.6879,  4.0611,  ...,  3.0674,  0.4476,  3.6441],\n",
            "        [11.9652, 24.6879,  4.0611,  ...,  3.0674,  0.4476,  3.6441],\n",
            "        [11.9652, 24.6879,  4.0611,  ...,  3.0674,  0.4476,  3.6441]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 661, Loss: 63265.871094\n",
            "tensor([[12.0046, 24.8066,  4.0820,  ...,  3.1003,  0.4577,  3.6572],\n",
            "        [12.0046, 24.8066,  4.0820,  ...,  3.1003,  0.4577,  3.6572],\n",
            "        [12.0046, 24.8066,  4.0820,  ...,  3.1003,  0.4577,  3.6572],\n",
            "        ...,\n",
            "        [12.0046, 24.8066,  4.0820,  ...,  3.1003,  0.4577,  3.6572],\n",
            "        [12.0046, 24.8066,  4.0820,  ...,  3.1003,  0.4577,  3.6572],\n",
            "        [12.0046, 24.8066,  4.0820,  ...,  3.1003,  0.4577,  3.6572]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 662, Loss: 63247.382812\n",
            "tensor([[12.0440, 24.9253,  4.1029,  ...,  3.1332,  0.4679,  3.6703],\n",
            "        [12.0440, 24.9253,  4.1029,  ...,  3.1332,  0.4679,  3.6703],\n",
            "        [12.0440, 24.9253,  4.1029,  ...,  3.1332,  0.4679,  3.6703],\n",
            "        ...,\n",
            "        [12.0440, 24.9253,  4.1029,  ...,  3.1332,  0.4679,  3.6703],\n",
            "        [12.0440, 24.9253,  4.1029,  ...,  3.1332,  0.4679,  3.6703],\n",
            "        [12.0440, 24.9253,  4.1029,  ...,  3.1332,  0.4679,  3.6703]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 663, Loss: 63228.910156\n",
            "tensor([[12.0834, 25.0439,  4.1238,  ...,  3.1662,  0.4780,  3.6834],\n",
            "        [12.0834, 25.0439,  4.1238,  ...,  3.1662,  0.4780,  3.6834],\n",
            "        [12.0834, 25.0439,  4.1238,  ...,  3.1662,  0.4780,  3.6834],\n",
            "        ...,\n",
            "        [12.0834, 25.0439,  4.1238,  ...,  3.1662,  0.4780,  3.6834],\n",
            "        [12.0834, 25.0439,  4.1238,  ...,  3.1662,  0.4780,  3.6834],\n",
            "        [12.0834, 25.0439,  4.1238,  ...,  3.1662,  0.4780,  3.6834]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 664, Loss: 63210.441406\n",
            "tensor([[12.1228, 25.1625,  4.1448,  ...,  3.1991,  0.4882,  3.6964],\n",
            "        [12.1228, 25.1625,  4.1448,  ...,  3.1991,  0.4882,  3.6964],\n",
            "        [12.1228, 25.1625,  4.1448,  ...,  3.1991,  0.4882,  3.6964],\n",
            "        ...,\n",
            "        [12.1228, 25.1625,  4.1448,  ...,  3.1991,  0.4882,  3.6964],\n",
            "        [12.1228, 25.1625,  4.1448,  ...,  3.1991,  0.4882,  3.6964],\n",
            "        [12.1228, 25.1625,  4.1448,  ...,  3.1991,  0.4882,  3.6964]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 665, Loss: 63191.980469\n",
            "tensor([[12.1621, 25.2811,  4.1657,  ...,  3.2320,  0.4983,  3.7095],\n",
            "        [12.1621, 25.2811,  4.1657,  ...,  3.2320,  0.4983,  3.7095],\n",
            "        [12.1621, 25.2811,  4.1657,  ...,  3.2320,  0.4983,  3.7095],\n",
            "        ...,\n",
            "        [12.1621, 25.2811,  4.1657,  ...,  3.2320,  0.4983,  3.7095],\n",
            "        [12.1621, 25.2811,  4.1657,  ...,  3.2320,  0.4983,  3.7095],\n",
            "        [12.1621, 25.2811,  4.1657,  ...,  3.2320,  0.4983,  3.7095]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 666, Loss: 63173.523438\n",
            "tensor([[12.2015, 25.3997,  4.1866,  ...,  3.2649,  0.5084,  3.7226],\n",
            "        [12.2015, 25.3997,  4.1866,  ...,  3.2649,  0.5084,  3.7226],\n",
            "        [12.2015, 25.3997,  4.1866,  ...,  3.2649,  0.5084,  3.7226],\n",
            "        ...,\n",
            "        [12.2015, 25.3997,  4.1866,  ...,  3.2649,  0.5084,  3.7226],\n",
            "        [12.2015, 25.3997,  4.1866,  ...,  3.2649,  0.5084,  3.7226],\n",
            "        [12.2015, 25.3997,  4.1866,  ...,  3.2649,  0.5084,  3.7226]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 667, Loss: 63155.078125\n",
            "tensor([[12.2409, 25.5183,  4.2075,  ...,  3.2978,  0.5186,  3.7356],\n",
            "        [12.2409, 25.5183,  4.2075,  ...,  3.2978,  0.5186,  3.7356],\n",
            "        [12.2409, 25.5183,  4.2075,  ...,  3.2978,  0.5186,  3.7356],\n",
            "        ...,\n",
            "        [12.2409, 25.5183,  4.2075,  ...,  3.2978,  0.5186,  3.7356],\n",
            "        [12.2409, 25.5183,  4.2075,  ...,  3.2978,  0.5186,  3.7356],\n",
            "        [12.2409, 25.5183,  4.2075,  ...,  3.2978,  0.5186,  3.7356]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 668, Loss: 63136.632812\n",
            "tensor([[12.2802, 25.6368,  4.2284,  ...,  3.3307,  0.5287,  3.7487],\n",
            "        [12.2802, 25.6368,  4.2284,  ...,  3.3307,  0.5287,  3.7487],\n",
            "        [12.2802, 25.6368,  4.2284,  ...,  3.3307,  0.5287,  3.7487],\n",
            "        ...,\n",
            "        [12.2802, 25.6368,  4.2284,  ...,  3.3307,  0.5287,  3.7487],\n",
            "        [12.2802, 25.6368,  4.2284,  ...,  3.3307,  0.5287,  3.7487],\n",
            "        [12.2802, 25.6368,  4.2284,  ...,  3.3307,  0.5287,  3.7487]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 669, Loss: 63118.199219\n",
            "tensor([[12.3196, 25.7553,  4.2493,  ...,  3.3636,  0.5388,  3.7618],\n",
            "        [12.3196, 25.7553,  4.2493,  ...,  3.3636,  0.5388,  3.7618],\n",
            "        [12.3196, 25.7553,  4.2493,  ...,  3.3636,  0.5388,  3.7618],\n",
            "        ...,\n",
            "        [12.3196, 25.7553,  4.2493,  ...,  3.3636,  0.5388,  3.7618],\n",
            "        [12.3196, 25.7553,  4.2493,  ...,  3.3636,  0.5388,  3.7618],\n",
            "        [12.3196, 25.7553,  4.2493,  ...,  3.3636,  0.5388,  3.7618]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 670, Loss: 63099.781250\n",
            "tensor([[12.3589, 25.8738,  4.2701,  ...,  3.3965,  0.5489,  3.7748],\n",
            "        [12.3589, 25.8738,  4.2701,  ...,  3.3965,  0.5489,  3.7748],\n",
            "        [12.3589, 25.8738,  4.2701,  ...,  3.3965,  0.5489,  3.7748],\n",
            "        ...,\n",
            "        [12.3589, 25.8738,  4.2701,  ...,  3.3965,  0.5489,  3.7748],\n",
            "        [12.3589, 25.8738,  4.2701,  ...,  3.3965,  0.5489,  3.7748],\n",
            "        [12.3589, 25.8738,  4.2701,  ...,  3.3965,  0.5489,  3.7748]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 671, Loss: 63081.355469\n",
            "tensor([[12.3982, 25.9922,  4.2910,  ...,  3.4293,  0.5591,  3.7879],\n",
            "        [12.3982, 25.9922,  4.2910,  ...,  3.4293,  0.5591,  3.7879],\n",
            "        [12.3982, 25.9922,  4.2910,  ...,  3.4293,  0.5591,  3.7879],\n",
            "        ...,\n",
            "        [12.3982, 25.9922,  4.2910,  ...,  3.4293,  0.5591,  3.7879],\n",
            "        [12.3982, 25.9922,  4.2910,  ...,  3.4293,  0.5591,  3.7879],\n",
            "        [12.3982, 25.9922,  4.2910,  ...,  3.4293,  0.5591,  3.7879]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 672, Loss: 63062.953125\n",
            "tensor([[12.4375, 26.1106,  4.3119,  ...,  3.4622,  0.5692,  3.8009],\n",
            "        [12.4375, 26.1106,  4.3119,  ...,  3.4622,  0.5692,  3.8009],\n",
            "        [12.4375, 26.1106,  4.3119,  ...,  3.4622,  0.5692,  3.8009],\n",
            "        ...,\n",
            "        [12.4375, 26.1106,  4.3119,  ...,  3.4622,  0.5692,  3.8009],\n",
            "        [12.4375, 26.1106,  4.3119,  ...,  3.4622,  0.5692,  3.8009],\n",
            "        [12.4375, 26.1106,  4.3119,  ...,  3.4622,  0.5692,  3.8009]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 673, Loss: 63044.542969\n",
            "tensor([[12.4769, 26.2290,  4.3328,  ...,  3.4951,  0.5793,  3.8140],\n",
            "        [12.4769, 26.2290,  4.3328,  ...,  3.4951,  0.5793,  3.8140],\n",
            "        [12.4769, 26.2290,  4.3328,  ...,  3.4951,  0.5793,  3.8140],\n",
            "        ...,\n",
            "        [12.4769, 26.2290,  4.3328,  ...,  3.4951,  0.5793,  3.8140],\n",
            "        [12.4769, 26.2290,  4.3328,  ...,  3.4951,  0.5793,  3.8140],\n",
            "        [12.4769, 26.2290,  4.3328,  ...,  3.4951,  0.5793,  3.8140]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 674, Loss: 63026.152344\n",
            "tensor([[12.5162, 26.3474,  4.3536,  ...,  3.5279,  0.5894,  3.8270],\n",
            "        [12.5162, 26.3474,  4.3536,  ...,  3.5279,  0.5894,  3.8270],\n",
            "        [12.5162, 26.3474,  4.3536,  ...,  3.5279,  0.5894,  3.8270],\n",
            "        ...,\n",
            "        [12.5162, 26.3474,  4.3536,  ...,  3.5279,  0.5894,  3.8270],\n",
            "        [12.5162, 26.3474,  4.3536,  ...,  3.5279,  0.5894,  3.8270],\n",
            "        [12.5162, 26.3474,  4.3536,  ...,  3.5279,  0.5894,  3.8270]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 675, Loss: 63007.757812\n",
            "tensor([[12.5555, 26.4658,  4.3745,  ...,  3.5608,  0.5995,  3.8400],\n",
            "        [12.5555, 26.4658,  4.3745,  ...,  3.5608,  0.5995,  3.8400],\n",
            "        [12.5555, 26.4658,  4.3745,  ...,  3.5608,  0.5995,  3.8400],\n",
            "        ...,\n",
            "        [12.5555, 26.4658,  4.3745,  ...,  3.5608,  0.5995,  3.8400],\n",
            "        [12.5555, 26.4658,  4.3745,  ...,  3.5608,  0.5995,  3.8400],\n",
            "        [12.5555, 26.4658,  4.3745,  ...,  3.5608,  0.5995,  3.8400]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 676, Loss: 62989.375000\n",
            "tensor([[12.5947, 26.5841,  4.3954,  ...,  3.5936,  0.6096,  3.8531],\n",
            "        [12.5947, 26.5841,  4.3954,  ...,  3.5936,  0.6096,  3.8531],\n",
            "        [12.5947, 26.5841,  4.3954,  ...,  3.5936,  0.6096,  3.8531],\n",
            "        ...,\n",
            "        [12.5947, 26.5841,  4.3954,  ...,  3.5936,  0.6096,  3.8531],\n",
            "        [12.5947, 26.5841,  4.3954,  ...,  3.5936,  0.6096,  3.8531],\n",
            "        [12.5947, 26.5841,  4.3954,  ...,  3.5936,  0.6096,  3.8531]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 677, Loss: 62971.011719\n",
            "tensor([[12.6340, 26.7024,  4.4162,  ...,  3.6265,  0.6198,  3.8661],\n",
            "        [12.6340, 26.7024,  4.4162,  ...,  3.6265,  0.6198,  3.8661],\n",
            "        [12.6340, 26.7024,  4.4162,  ...,  3.6265,  0.6198,  3.8661],\n",
            "        ...,\n",
            "        [12.6340, 26.7024,  4.4162,  ...,  3.6265,  0.6198,  3.8661],\n",
            "        [12.6340, 26.7024,  4.4162,  ...,  3.6265,  0.6198,  3.8661],\n",
            "        [12.6340, 26.7024,  4.4162,  ...,  3.6265,  0.6198,  3.8661]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 678, Loss: 62952.640625\n",
            "tensor([[12.6733, 26.8207,  4.4371,  ...,  3.6593,  0.6299,  3.8792],\n",
            "        [12.6733, 26.8207,  4.4371,  ...,  3.6593,  0.6299,  3.8792],\n",
            "        [12.6733, 26.8207,  4.4371,  ...,  3.6593,  0.6299,  3.8792],\n",
            "        ...,\n",
            "        [12.6733, 26.8207,  4.4371,  ...,  3.6593,  0.6299,  3.8792],\n",
            "        [12.6733, 26.8207,  4.4371,  ...,  3.6593,  0.6299,  3.8792],\n",
            "        [12.6733, 26.8207,  4.4371,  ...,  3.6593,  0.6299,  3.8792]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 679, Loss: 62934.277344\n",
            "tensor([[12.7126, 26.9390,  4.4579,  ...,  3.6921,  0.6400,  3.8922],\n",
            "        [12.7126, 26.9390,  4.4579,  ...,  3.6921,  0.6400,  3.8922],\n",
            "        [12.7126, 26.9390,  4.4579,  ...,  3.6921,  0.6400,  3.8922],\n",
            "        ...,\n",
            "        [12.7126, 26.9390,  4.4579,  ...,  3.6921,  0.6400,  3.8922],\n",
            "        [12.7126, 26.9390,  4.4579,  ...,  3.6921,  0.6400,  3.8922],\n",
            "        [12.7126, 26.9390,  4.4579,  ...,  3.6921,  0.6400,  3.8922]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 680, Loss: 62915.929688\n",
            "tensor([[12.7518, 27.0572,  4.4788,  ...,  3.7249,  0.6501,  3.9052],\n",
            "        [12.7518, 27.0572,  4.4788,  ...,  3.7249,  0.6501,  3.9052],\n",
            "        [12.7518, 27.0572,  4.4788,  ...,  3.7249,  0.6501,  3.9052],\n",
            "        ...,\n",
            "        [12.7518, 27.0572,  4.4788,  ...,  3.7249,  0.6501,  3.9052],\n",
            "        [12.7518, 27.0572,  4.4788,  ...,  3.7249,  0.6501,  3.9052],\n",
            "        [12.7518, 27.0572,  4.4788,  ...,  3.7249,  0.6501,  3.9052]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 681, Loss: 62897.585938\n",
            "tensor([[12.7911, 27.1754,  4.4996,  ...,  3.7577,  0.6602,  3.9182],\n",
            "        [12.7911, 27.1754,  4.4996,  ...,  3.7577,  0.6602,  3.9182],\n",
            "        [12.7911, 27.1754,  4.4996,  ...,  3.7577,  0.6602,  3.9182],\n",
            "        ...,\n",
            "        [12.7911, 27.1754,  4.4996,  ...,  3.7577,  0.6602,  3.9182],\n",
            "        [12.7911, 27.1754,  4.4996,  ...,  3.7577,  0.6602,  3.9182],\n",
            "        [12.7911, 27.1754,  4.4996,  ...,  3.7577,  0.6602,  3.9182]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 682, Loss: 62879.246094\n",
            "tensor([[12.8303, 27.2936,  4.5205,  ...,  3.7905,  0.6703,  3.9313],\n",
            "        [12.8303, 27.2936,  4.5205,  ...,  3.7905,  0.6703,  3.9313],\n",
            "        [12.8303, 27.2936,  4.5205,  ...,  3.7905,  0.6703,  3.9313],\n",
            "        ...,\n",
            "        [12.8303, 27.2936,  4.5205,  ...,  3.7905,  0.6703,  3.9313],\n",
            "        [12.8303, 27.2936,  4.5205,  ...,  3.7905,  0.6703,  3.9313],\n",
            "        [12.8303, 27.2936,  4.5205,  ...,  3.7905,  0.6703,  3.9313]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 683, Loss: 62860.910156\n",
            "tensor([[12.8695, 27.4118,  4.5413,  ...,  3.8233,  0.6804,  3.9443],\n",
            "        [12.8695, 27.4118,  4.5413,  ...,  3.8233,  0.6804,  3.9443],\n",
            "        [12.8695, 27.4118,  4.5413,  ...,  3.8233,  0.6804,  3.9443],\n",
            "        ...,\n",
            "        [12.8695, 27.4118,  4.5413,  ...,  3.8233,  0.6804,  3.9443],\n",
            "        [12.8695, 27.4118,  4.5413,  ...,  3.8233,  0.6804,  3.9443],\n",
            "        [12.8695, 27.4118,  4.5413,  ...,  3.8233,  0.6804,  3.9443]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 684, Loss: 62842.589844\n",
            "tensor([[12.9088, 27.5300,  4.5621,  ...,  3.8561,  0.6905,  3.9573],\n",
            "        [12.9088, 27.5300,  4.5621,  ...,  3.8561,  0.6905,  3.9573],\n",
            "        [12.9088, 27.5300,  4.5621,  ...,  3.8561,  0.6905,  3.9573],\n",
            "        ...,\n",
            "        [12.9088, 27.5300,  4.5621,  ...,  3.8561,  0.6905,  3.9573],\n",
            "        [12.9088, 27.5300,  4.5621,  ...,  3.8561,  0.6905,  3.9573],\n",
            "        [12.9088, 27.5300,  4.5621,  ...,  3.8561,  0.6905,  3.9573]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 685, Loss: 62824.273438\n",
            "tensor([[12.9480, 27.6481,  4.5829,  ...,  3.8889,  0.7006,  3.9703],\n",
            "        [12.9480, 27.6481,  4.5829,  ...,  3.8889,  0.7006,  3.9703],\n",
            "        [12.9480, 27.6481,  4.5829,  ...,  3.8889,  0.7006,  3.9703],\n",
            "        ...,\n",
            "        [12.9480, 27.6481,  4.5829,  ...,  3.8889,  0.7006,  3.9703],\n",
            "        [12.9480, 27.6481,  4.5829,  ...,  3.8889,  0.7006,  3.9703],\n",
            "        [12.9480, 27.6481,  4.5829,  ...,  3.8889,  0.7006,  3.9703]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 686, Loss: 62805.968750\n",
            "tensor([[12.9872, 27.7662,  4.6038,  ...,  3.9217,  0.7107,  3.9833],\n",
            "        [12.9872, 27.7662,  4.6038,  ...,  3.9217,  0.7107,  3.9833],\n",
            "        [12.9872, 27.7662,  4.6038,  ...,  3.9217,  0.7107,  3.9833],\n",
            "        ...,\n",
            "        [12.9872, 27.7662,  4.6038,  ...,  3.9217,  0.7107,  3.9833],\n",
            "        [12.9872, 27.7662,  4.6038,  ...,  3.9217,  0.7107,  3.9833],\n",
            "        [12.9872, 27.7662,  4.6038,  ...,  3.9217,  0.7107,  3.9833]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 687, Loss: 62787.664062\n",
            "tensor([[13.0264, 27.8842,  4.6246,  ...,  3.9545,  0.7208,  3.9963],\n",
            "        [13.0264, 27.8842,  4.6246,  ...,  3.9545,  0.7208,  3.9963],\n",
            "        [13.0264, 27.8842,  4.6246,  ...,  3.9545,  0.7208,  3.9963],\n",
            "        ...,\n",
            "        [13.0264, 27.8842,  4.6246,  ...,  3.9545,  0.7208,  3.9963],\n",
            "        [13.0264, 27.8842,  4.6246,  ...,  3.9545,  0.7208,  3.9963],\n",
            "        [13.0264, 27.8842,  4.6246,  ...,  3.9545,  0.7208,  3.9963]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 688, Loss: 62769.359375\n",
            "tensor([[13.0656, 28.0023,  4.6454,  ...,  3.9872,  0.7308,  4.0093],\n",
            "        [13.0656, 28.0023,  4.6454,  ...,  3.9872,  0.7308,  4.0093],\n",
            "        [13.0656, 28.0023,  4.6454,  ...,  3.9872,  0.7308,  4.0093],\n",
            "        ...,\n",
            "        [13.0656, 28.0023,  4.6454,  ...,  3.9872,  0.7308,  4.0093],\n",
            "        [13.0656, 28.0023,  4.6454,  ...,  3.9872,  0.7308,  4.0093],\n",
            "        [13.0656, 28.0023,  4.6454,  ...,  3.9872,  0.7308,  4.0093]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 689, Loss: 62751.082031\n",
            "tensor([[13.1048, 28.1203,  4.6662,  ...,  4.0200,  0.7409,  4.0223],\n",
            "        [13.1048, 28.1203,  4.6662,  ...,  4.0200,  0.7409,  4.0223],\n",
            "        [13.1048, 28.1203,  4.6662,  ...,  4.0200,  0.7409,  4.0223],\n",
            "        ...,\n",
            "        [13.1048, 28.1203,  4.6662,  ...,  4.0200,  0.7409,  4.0223],\n",
            "        [13.1048, 28.1203,  4.6662,  ...,  4.0200,  0.7409,  4.0223],\n",
            "        [13.1048, 28.1203,  4.6662,  ...,  4.0200,  0.7409,  4.0223]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 690, Loss: 62732.804688\n",
            "tensor([[13.1440, 28.2383,  4.6870,  ...,  4.0527,  0.7510,  4.0354],\n",
            "        [13.1440, 28.2383,  4.6870,  ...,  4.0527,  0.7510,  4.0354],\n",
            "        [13.1440, 28.2383,  4.6870,  ...,  4.0527,  0.7510,  4.0354],\n",
            "        ...,\n",
            "        [13.1440, 28.2383,  4.6870,  ...,  4.0527,  0.7510,  4.0354],\n",
            "        [13.1440, 28.2383,  4.6870,  ...,  4.0527,  0.7510,  4.0354],\n",
            "        [13.1440, 28.2383,  4.6870,  ...,  4.0527,  0.7510,  4.0354]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 691, Loss: 62714.539062\n",
            "tensor([[13.1831, 28.3563,  4.7078,  ...,  4.0855,  0.7611,  4.0484],\n",
            "        [13.1831, 28.3563,  4.7078,  ...,  4.0855,  0.7611,  4.0484],\n",
            "        [13.1831, 28.3563,  4.7078,  ...,  4.0855,  0.7611,  4.0484],\n",
            "        ...,\n",
            "        [13.1831, 28.3563,  4.7078,  ...,  4.0855,  0.7611,  4.0484],\n",
            "        [13.1831, 28.3563,  4.7078,  ...,  4.0855,  0.7611,  4.0484],\n",
            "        [13.1831, 28.3563,  4.7078,  ...,  4.0855,  0.7611,  4.0484]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 692, Loss: 62696.269531\n",
            "tensor([[13.2223, 28.4743,  4.7286,  ...,  4.1182,  0.7712,  4.0613],\n",
            "        [13.2223, 28.4743,  4.7286,  ...,  4.1182,  0.7712,  4.0613],\n",
            "        [13.2223, 28.4743,  4.7286,  ...,  4.1182,  0.7712,  4.0613],\n",
            "        ...,\n",
            "        [13.2223, 28.4743,  4.7286,  ...,  4.1182,  0.7712,  4.0613],\n",
            "        [13.2223, 28.4743,  4.7286,  ...,  4.1182,  0.7712,  4.0613],\n",
            "        [13.2223, 28.4743,  4.7286,  ...,  4.1182,  0.7712,  4.0613]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 693, Loss: 62678.019531\n",
            "tensor([[13.2614, 28.5922,  4.7494,  ...,  4.1509,  0.7813,  4.0743],\n",
            "        [13.2614, 28.5922,  4.7494,  ...,  4.1509,  0.7813,  4.0743],\n",
            "        [13.2614, 28.5922,  4.7494,  ...,  4.1509,  0.7813,  4.0743],\n",
            "        ...,\n",
            "        [13.2614, 28.5922,  4.7494,  ...,  4.1509,  0.7813,  4.0743],\n",
            "        [13.2614, 28.5922,  4.7494,  ...,  4.1509,  0.7813,  4.0743],\n",
            "        [13.2614, 28.5922,  4.7494,  ...,  4.1509,  0.7813,  4.0743]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 694, Loss: 62659.765625\n",
            "tensor([[13.3006, 28.7101,  4.7702,  ...,  4.1837,  0.7913,  4.0873],\n",
            "        [13.3006, 28.7101,  4.7702,  ...,  4.1837,  0.7913,  4.0873],\n",
            "        [13.3006, 28.7101,  4.7702,  ...,  4.1837,  0.7913,  4.0873],\n",
            "        ...,\n",
            "        [13.3006, 28.7101,  4.7702,  ...,  4.1837,  0.7913,  4.0873],\n",
            "        [13.3006, 28.7101,  4.7702,  ...,  4.1837,  0.7913,  4.0873],\n",
            "        [13.3006, 28.7101,  4.7702,  ...,  4.1837,  0.7913,  4.0873]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 695, Loss: 62641.523438\n",
            "tensor([[13.3397, 28.8280,  4.7910,  ...,  4.2164,  0.8014,  4.1003],\n",
            "        [13.3397, 28.8280,  4.7910,  ...,  4.2164,  0.8014,  4.1003],\n",
            "        [13.3397, 28.8280,  4.7910,  ...,  4.2164,  0.8014,  4.1003],\n",
            "        ...,\n",
            "        [13.3397, 28.8280,  4.7910,  ...,  4.2164,  0.8014,  4.1003],\n",
            "        [13.3397, 28.8280,  4.7910,  ...,  4.2164,  0.8014,  4.1003],\n",
            "        [13.3397, 28.8280,  4.7910,  ...,  4.2164,  0.8014,  4.1003]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 696, Loss: 62623.292969\n",
            "tensor([[13.3789, 28.9459,  4.8117,  ...,  4.2491,  0.8115,  4.1133],\n",
            "        [13.3789, 28.9459,  4.8117,  ...,  4.2491,  0.8115,  4.1133],\n",
            "        [13.3789, 28.9459,  4.8117,  ...,  4.2491,  0.8115,  4.1133],\n",
            "        ...,\n",
            "        [13.3789, 28.9459,  4.8117,  ...,  4.2491,  0.8115,  4.1133],\n",
            "        [13.3789, 28.9459,  4.8117,  ...,  4.2491,  0.8115,  4.1133],\n",
            "        [13.3789, 28.9459,  4.8117,  ...,  4.2491,  0.8115,  4.1133]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 697, Loss: 62605.058594\n",
            "tensor([[13.4180, 29.0637,  4.8325,  ...,  4.2818,  0.8215,  4.1263],\n",
            "        [13.4180, 29.0637,  4.8325,  ...,  4.2818,  0.8215,  4.1263],\n",
            "        [13.4180, 29.0637,  4.8325,  ...,  4.2818,  0.8215,  4.1263],\n",
            "        ...,\n",
            "        [13.4180, 29.0637,  4.8325,  ...,  4.2818,  0.8215,  4.1263],\n",
            "        [13.4180, 29.0637,  4.8325,  ...,  4.2818,  0.8215,  4.1263],\n",
            "        [13.4180, 29.0637,  4.8325,  ...,  4.2818,  0.8215,  4.1263]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 698, Loss: 62586.835938\n",
            "tensor([[13.4571, 29.1815,  4.8533,  ...,  4.3145,  0.8316,  4.1393],\n",
            "        [13.4571, 29.1815,  4.8533,  ...,  4.3145,  0.8316,  4.1393],\n",
            "        [13.4571, 29.1815,  4.8533,  ...,  4.3145,  0.8316,  4.1393],\n",
            "        ...,\n",
            "        [13.4571, 29.1815,  4.8533,  ...,  4.3145,  0.8316,  4.1393],\n",
            "        [13.4571, 29.1815,  4.8533,  ...,  4.3145,  0.8316,  4.1393],\n",
            "        [13.4571, 29.1815,  4.8533,  ...,  4.3145,  0.8316,  4.1393]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 699, Loss: 62568.625000\n",
            "tensor([[13.4962, 29.2993,  4.8740,  ...,  4.3472,  0.8417,  4.1523],\n",
            "        [13.4962, 29.2993,  4.8740,  ...,  4.3472,  0.8417,  4.1523],\n",
            "        [13.4962, 29.2993,  4.8740,  ...,  4.3472,  0.8417,  4.1523],\n",
            "        ...,\n",
            "        [13.4962, 29.2993,  4.8740,  ...,  4.3472,  0.8417,  4.1523],\n",
            "        [13.4962, 29.2993,  4.8740,  ...,  4.3472,  0.8417,  4.1523],\n",
            "        [13.4962, 29.2993,  4.8740,  ...,  4.3472,  0.8417,  4.1523]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 700, Loss: 62550.425781\n",
            "tensor([[13.5353, 29.4171,  4.8948,  ...,  4.3799,  0.8517,  4.1652],\n",
            "        [13.5353, 29.4171,  4.8948,  ...,  4.3799,  0.8517,  4.1652],\n",
            "        [13.5353, 29.4171,  4.8948,  ...,  4.3799,  0.8517,  4.1652],\n",
            "        ...,\n",
            "        [13.5353, 29.4171,  4.8948,  ...,  4.3799,  0.8517,  4.1652],\n",
            "        [13.5353, 29.4171,  4.8948,  ...,  4.3799,  0.8517,  4.1652],\n",
            "        [13.5353, 29.4171,  4.8948,  ...,  4.3799,  0.8517,  4.1652]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 701, Loss: 62532.222656\n",
            "tensor([[13.5744, 29.5348,  4.9156,  ...,  4.4126,  0.8618,  4.1782],\n",
            "        [13.5744, 29.5348,  4.9156,  ...,  4.4126,  0.8618,  4.1782],\n",
            "        [13.5744, 29.5348,  4.9156,  ...,  4.4126,  0.8618,  4.1782],\n",
            "        ...,\n",
            "        [13.5744, 29.5348,  4.9156,  ...,  4.4126,  0.8618,  4.1782],\n",
            "        [13.5744, 29.5348,  4.9156,  ...,  4.4126,  0.8618,  4.1782],\n",
            "        [13.5744, 29.5348,  4.9156,  ...,  4.4126,  0.8618,  4.1782]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 702, Loss: 62514.027344\n",
            "tensor([[13.6135, 29.6525,  4.9363,  ...,  4.4452,  0.8719,  4.1912],\n",
            "        [13.6135, 29.6525,  4.9363,  ...,  4.4452,  0.8719,  4.1912],\n",
            "        [13.6135, 29.6525,  4.9363,  ...,  4.4452,  0.8719,  4.1912],\n",
            "        ...,\n",
            "        [13.6135, 29.6525,  4.9363,  ...,  4.4452,  0.8719,  4.1912],\n",
            "        [13.6135, 29.6525,  4.9363,  ...,  4.4452,  0.8719,  4.1912],\n",
            "        [13.6135, 29.6525,  4.9363,  ...,  4.4452,  0.8719,  4.1912]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 703, Loss: 62495.843750\n",
            "tensor([[13.6526, 29.7702,  4.9571,  ...,  4.4779,  0.8819,  4.2041],\n",
            "        [13.6526, 29.7702,  4.9571,  ...,  4.4779,  0.8819,  4.2041],\n",
            "        [13.6526, 29.7702,  4.9571,  ...,  4.4779,  0.8819,  4.2041],\n",
            "        ...,\n",
            "        [13.6526, 29.7702,  4.9571,  ...,  4.4779,  0.8819,  4.2041],\n",
            "        [13.6526, 29.7702,  4.9571,  ...,  4.4779,  0.8819,  4.2041],\n",
            "        [13.6526, 29.7702,  4.9571,  ...,  4.4779,  0.8819,  4.2041]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 704, Loss: 62477.667969\n",
            "tensor([[13.6916, 29.8879,  4.9778,  ...,  4.5106,  0.8920,  4.2171],\n",
            "        [13.6916, 29.8879,  4.9778,  ...,  4.5106,  0.8920,  4.2171],\n",
            "        [13.6916, 29.8879,  4.9778,  ...,  4.5106,  0.8920,  4.2171],\n",
            "        ...,\n",
            "        [13.6916, 29.8879,  4.9778,  ...,  4.5106,  0.8920,  4.2171],\n",
            "        [13.6916, 29.8879,  4.9778,  ...,  4.5106,  0.8920,  4.2171],\n",
            "        [13.6916, 29.8879,  4.9778,  ...,  4.5106,  0.8920,  4.2171]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 705, Loss: 62459.496094\n",
            "tensor([[13.7307, 30.0056,  4.9985,  ...,  4.5432,  0.9020,  4.2301],\n",
            "        [13.7307, 30.0056,  4.9985,  ...,  4.5432,  0.9020,  4.2301],\n",
            "        [13.7307, 30.0056,  4.9985,  ...,  4.5432,  0.9020,  4.2301],\n",
            "        ...,\n",
            "        [13.7307, 30.0056,  4.9985,  ...,  4.5432,  0.9020,  4.2301],\n",
            "        [13.7307, 30.0056,  4.9985,  ...,  4.5432,  0.9020,  4.2301],\n",
            "        [13.7307, 30.0056,  4.9985,  ...,  4.5432,  0.9020,  4.2301]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 706, Loss: 62441.335938\n",
            "tensor([[13.7698, 30.1232,  5.0193,  ...,  4.5758,  0.9121,  4.2430],\n",
            "        [13.7698, 30.1232,  5.0193,  ...,  4.5758,  0.9121,  4.2430],\n",
            "        [13.7698, 30.1232,  5.0193,  ...,  4.5758,  0.9121,  4.2430],\n",
            "        ...,\n",
            "        [13.7698, 30.1232,  5.0193,  ...,  4.5758,  0.9121,  4.2430],\n",
            "        [13.7698, 30.1232,  5.0193,  ...,  4.5758,  0.9121,  4.2430],\n",
            "        [13.7698, 30.1232,  5.0193,  ...,  4.5758,  0.9121,  4.2430]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 707, Loss: 62423.187500\n",
            "tensor([[13.8088, 30.2408,  5.0400,  ...,  4.6085,  0.9221,  4.2560],\n",
            "        [13.8088, 30.2408,  5.0400,  ...,  4.6085,  0.9221,  4.2560],\n",
            "        [13.8088, 30.2408,  5.0400,  ...,  4.6085,  0.9221,  4.2560],\n",
            "        ...,\n",
            "        [13.8088, 30.2408,  5.0400,  ...,  4.6085,  0.9221,  4.2560],\n",
            "        [13.8088, 30.2408,  5.0400,  ...,  4.6085,  0.9221,  4.2560],\n",
            "        [13.8088, 30.2408,  5.0400,  ...,  4.6085,  0.9221,  4.2560]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 708, Loss: 62405.031250\n",
            "tensor([[13.8478, 30.3584,  5.0607,  ...,  4.6411,  0.9322,  4.2689],\n",
            "        [13.8478, 30.3584,  5.0607,  ...,  4.6411,  0.9322,  4.2689],\n",
            "        [13.8478, 30.3584,  5.0607,  ...,  4.6411,  0.9322,  4.2689],\n",
            "        ...,\n",
            "        [13.8478, 30.3584,  5.0607,  ...,  4.6411,  0.9322,  4.2689],\n",
            "        [13.8478, 30.3584,  5.0607,  ...,  4.6411,  0.9322,  4.2689],\n",
            "        [13.8478, 30.3584,  5.0607,  ...,  4.6411,  0.9322,  4.2689]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 709, Loss: 62386.894531\n",
            "tensor([[13.8869, 30.4759,  5.0815,  ...,  4.6737,  0.9422,  4.2819],\n",
            "        [13.8869, 30.4759,  5.0815,  ...,  4.6737,  0.9422,  4.2819],\n",
            "        [13.8869, 30.4759,  5.0815,  ...,  4.6737,  0.9422,  4.2819],\n",
            "        ...,\n",
            "        [13.8869, 30.4759,  5.0815,  ...,  4.6737,  0.9422,  4.2819],\n",
            "        [13.8869, 30.4759,  5.0815,  ...,  4.6737,  0.9422,  4.2819],\n",
            "        [13.8869, 30.4759,  5.0815,  ...,  4.6737,  0.9422,  4.2819]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 710, Loss: 62368.757812\n",
            "tensor([[13.9259, 30.5935,  5.1022,  ...,  4.7064,  0.9523,  4.2949],\n",
            "        [13.9259, 30.5935,  5.1022,  ...,  4.7064,  0.9523,  4.2949],\n",
            "        [13.9259, 30.5935,  5.1022,  ...,  4.7064,  0.9523,  4.2949],\n",
            "        ...,\n",
            "        [13.9259, 30.5935,  5.1022,  ...,  4.7064,  0.9523,  4.2949],\n",
            "        [13.9259, 30.5935,  5.1022,  ...,  4.7064,  0.9523,  4.2949],\n",
            "        [13.9259, 30.5935,  5.1022,  ...,  4.7064,  0.9523,  4.2949]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 711, Loss: 62350.632812\n",
            "tensor([[13.9649, 30.7110,  5.1229,  ...,  4.7390,  0.9623,  4.3078],\n",
            "        [13.9649, 30.7110,  5.1229,  ...,  4.7390,  0.9623,  4.3078],\n",
            "        [13.9649, 30.7110,  5.1229,  ...,  4.7390,  0.9623,  4.3078],\n",
            "        ...,\n",
            "        [13.9649, 30.7110,  5.1229,  ...,  4.7390,  0.9623,  4.3078],\n",
            "        [13.9649, 30.7110,  5.1229,  ...,  4.7390,  0.9623,  4.3078],\n",
            "        [13.9649, 30.7110,  5.1229,  ...,  4.7390,  0.9623,  4.3078]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 712, Loss: 62332.523438\n",
            "tensor([[14.0039, 30.8285,  5.1436,  ...,  4.7716,  0.9724,  4.3207],\n",
            "        [14.0039, 30.8285,  5.1436,  ...,  4.7716,  0.9724,  4.3207],\n",
            "        [14.0039, 30.8285,  5.1436,  ...,  4.7716,  0.9724,  4.3207],\n",
            "        ...,\n",
            "        [14.0039, 30.8285,  5.1436,  ...,  4.7716,  0.9724,  4.3207],\n",
            "        [14.0039, 30.8285,  5.1436,  ...,  4.7716,  0.9724,  4.3207],\n",
            "        [14.0039, 30.8285,  5.1436,  ...,  4.7716,  0.9724,  4.3207]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 713, Loss: 62314.402344\n",
            "tensor([[14.0429, 30.9459,  5.1643,  ...,  4.8042,  0.9824,  4.3337],\n",
            "        [14.0429, 30.9459,  5.1643,  ...,  4.8042,  0.9824,  4.3337],\n",
            "        [14.0429, 30.9459,  5.1643,  ...,  4.8042,  0.9824,  4.3337],\n",
            "        ...,\n",
            "        [14.0429, 30.9459,  5.1643,  ...,  4.8042,  0.9824,  4.3337],\n",
            "        [14.0429, 30.9459,  5.1643,  ...,  4.8042,  0.9824,  4.3337],\n",
            "        [14.0429, 30.9459,  5.1643,  ...,  4.8042,  0.9824,  4.3337]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 714, Loss: 62296.304688\n",
            "tensor([[14.0819, 31.0634,  5.1850,  ...,  4.8368,  0.9924,  4.3466],\n",
            "        [14.0819, 31.0634,  5.1850,  ...,  4.8368,  0.9924,  4.3466],\n",
            "        [14.0819, 31.0634,  5.1850,  ...,  4.8368,  0.9924,  4.3466],\n",
            "        ...,\n",
            "        [14.0819, 31.0634,  5.1850,  ...,  4.8368,  0.9924,  4.3466],\n",
            "        [14.0819, 31.0634,  5.1850,  ...,  4.8368,  0.9924,  4.3466],\n",
            "        [14.0819, 31.0634,  5.1850,  ...,  4.8368,  0.9924,  4.3466]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 715, Loss: 62278.203125\n",
            "tensor([[14.1209, 31.1808,  5.2057,  ...,  4.8694,  1.0025,  4.3596],\n",
            "        [14.1209, 31.1808,  5.2057,  ...,  4.8694,  1.0025,  4.3596],\n",
            "        [14.1209, 31.1808,  5.2057,  ...,  4.8694,  1.0025,  4.3596],\n",
            "        ...,\n",
            "        [14.1209, 31.1808,  5.2057,  ...,  4.8694,  1.0025,  4.3596],\n",
            "        [14.1209, 31.1808,  5.2057,  ...,  4.8694,  1.0025,  4.3596],\n",
            "        [14.1209, 31.1808,  5.2057,  ...,  4.8694,  1.0025,  4.3596]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 716, Loss: 62260.109375\n",
            "tensor([[14.1599, 31.2982,  5.2264,  ...,  4.9019,  1.0125,  4.3725],\n",
            "        [14.1599, 31.2982,  5.2264,  ...,  4.9019,  1.0125,  4.3725],\n",
            "        [14.1599, 31.2982,  5.2264,  ...,  4.9019,  1.0125,  4.3725],\n",
            "        ...,\n",
            "        [14.1599, 31.2982,  5.2264,  ...,  4.9019,  1.0125,  4.3725],\n",
            "        [14.1599, 31.2982,  5.2264,  ...,  4.9019,  1.0125,  4.3725],\n",
            "        [14.1599, 31.2982,  5.2264,  ...,  4.9019,  1.0125,  4.3725]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 717, Loss: 62242.023438\n",
            "tensor([[14.1988, 31.4155,  5.2471,  ...,  4.9345,  1.0225,  4.3854],\n",
            "        [14.1988, 31.4155,  5.2471,  ...,  4.9345,  1.0225,  4.3854],\n",
            "        [14.1988, 31.4155,  5.2471,  ...,  4.9345,  1.0225,  4.3854],\n",
            "        ...,\n",
            "        [14.1988, 31.4155,  5.2471,  ...,  4.9345,  1.0225,  4.3854],\n",
            "        [14.1988, 31.4155,  5.2471,  ...,  4.9345,  1.0225,  4.3854],\n",
            "        [14.1988, 31.4155,  5.2471,  ...,  4.9345,  1.0225,  4.3854]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 718, Loss: 62223.957031\n",
            "tensor([[14.2378, 31.5329,  5.2678,  ...,  4.9671,  1.0326,  4.3984],\n",
            "        [14.2378, 31.5329,  5.2678,  ...,  4.9671,  1.0326,  4.3984],\n",
            "        [14.2378, 31.5329,  5.2678,  ...,  4.9671,  1.0326,  4.3984],\n",
            "        ...,\n",
            "        [14.2378, 31.5329,  5.2678,  ...,  4.9671,  1.0326,  4.3984],\n",
            "        [14.2378, 31.5329,  5.2678,  ...,  4.9671,  1.0326,  4.3984],\n",
            "        [14.2378, 31.5329,  5.2678,  ...,  4.9671,  1.0326,  4.3984]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 719, Loss: 62205.886719\n",
            "tensor([[14.2767, 31.6502,  5.2885,  ...,  4.9997,  1.0426,  4.4113],\n",
            "        [14.2767, 31.6502,  5.2885,  ...,  4.9997,  1.0426,  4.4113],\n",
            "        [14.2767, 31.6502,  5.2885,  ...,  4.9997,  1.0426,  4.4113],\n",
            "        ...,\n",
            "        [14.2767, 31.6502,  5.2885,  ...,  4.9997,  1.0426,  4.4113],\n",
            "        [14.2767, 31.6502,  5.2885,  ...,  4.9997,  1.0426,  4.4113],\n",
            "        [14.2767, 31.6502,  5.2885,  ...,  4.9997,  1.0426,  4.4113]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 720, Loss: 62187.828125\n",
            "tensor([[14.3157, 31.7675,  5.3092,  ...,  5.0322,  1.0526,  4.4242],\n",
            "        [14.3157, 31.7675,  5.3092,  ...,  5.0322,  1.0526,  4.4242],\n",
            "        [14.3157, 31.7675,  5.3092,  ...,  5.0322,  1.0526,  4.4242],\n",
            "        ...,\n",
            "        [14.3157, 31.7675,  5.3092,  ...,  5.0322,  1.0526,  4.4242],\n",
            "        [14.3157, 31.7675,  5.3092,  ...,  5.0322,  1.0526,  4.4242],\n",
            "        [14.3157, 31.7675,  5.3092,  ...,  5.0322,  1.0526,  4.4242]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 721, Loss: 62169.777344\n",
            "tensor([[14.3546, 31.8848,  5.3298,  ...,  5.0648,  1.0626,  4.4371],\n",
            "        [14.3546, 31.8848,  5.3298,  ...,  5.0648,  1.0626,  4.4371],\n",
            "        [14.3546, 31.8848,  5.3298,  ...,  5.0648,  1.0626,  4.4371],\n",
            "        ...,\n",
            "        [14.3546, 31.8848,  5.3298,  ...,  5.0648,  1.0626,  4.4371],\n",
            "        [14.3546, 31.8848,  5.3298,  ...,  5.0648,  1.0626,  4.4371],\n",
            "        [14.3546, 31.8848,  5.3298,  ...,  5.0648,  1.0626,  4.4371]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 722, Loss: 62151.730469\n",
            "tensor([[14.3935, 32.0020,  5.3505,  ...,  5.0973,  1.0726,  4.4501],\n",
            "        [14.3935, 32.0020,  5.3505,  ...,  5.0973,  1.0726,  4.4501],\n",
            "        [14.3935, 32.0020,  5.3505,  ...,  5.0973,  1.0726,  4.4501],\n",
            "        ...,\n",
            "        [14.3935, 32.0020,  5.3505,  ...,  5.0973,  1.0726,  4.4501],\n",
            "        [14.3935, 32.0020,  5.3505,  ...,  5.0973,  1.0726,  4.4501],\n",
            "        [14.3935, 32.0020,  5.3505,  ...,  5.0973,  1.0726,  4.4501]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 723, Loss: 62133.691406\n",
            "tensor([[14.4325, 32.1193,  5.3712,  ...,  5.1298,  1.0827,  4.4630],\n",
            "        [14.4325, 32.1193,  5.3712,  ...,  5.1298,  1.0827,  4.4630],\n",
            "        [14.4325, 32.1193,  5.3712,  ...,  5.1298,  1.0827,  4.4630],\n",
            "        ...,\n",
            "        [14.4325, 32.1193,  5.3712,  ...,  5.1298,  1.0827,  4.4630],\n",
            "        [14.4325, 32.1193,  5.3712,  ...,  5.1298,  1.0827,  4.4630],\n",
            "        [14.4325, 32.1193,  5.3712,  ...,  5.1298,  1.0827,  4.4630]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 724, Loss: 62115.656250\n",
            "tensor([[14.4714, 32.2365,  5.3918,  ...,  5.1624,  1.0927,  4.4759],\n",
            "        [14.4714, 32.2365,  5.3918,  ...,  5.1624,  1.0927,  4.4759],\n",
            "        [14.4714, 32.2365,  5.3918,  ...,  5.1624,  1.0927,  4.4759],\n",
            "        ...,\n",
            "        [14.4714, 32.2365,  5.3918,  ...,  5.1624,  1.0927,  4.4759],\n",
            "        [14.4714, 32.2365,  5.3918,  ...,  5.1624,  1.0927,  4.4759],\n",
            "        [14.4714, 32.2365,  5.3918,  ...,  5.1624,  1.0927,  4.4759]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 725, Loss: 62097.636719\n",
            "tensor([[14.5103, 32.3536,  5.4125,  ...,  5.1949,  1.1027,  4.4888],\n",
            "        [14.5103, 32.3536,  5.4125,  ...,  5.1949,  1.1027,  4.4888],\n",
            "        [14.5103, 32.3536,  5.4125,  ...,  5.1949,  1.1027,  4.4888],\n",
            "        ...,\n",
            "        [14.5103, 32.3536,  5.4125,  ...,  5.1949,  1.1027,  4.4888],\n",
            "        [14.5103, 32.3536,  5.4125,  ...,  5.1949,  1.1027,  4.4888],\n",
            "        [14.5103, 32.3536,  5.4125,  ...,  5.1949,  1.1027,  4.4888]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 726, Loss: 62079.613281\n",
            "tensor([[14.5492, 32.4708,  5.4332,  ...,  5.2274,  1.1127,  4.5017],\n",
            "        [14.5492, 32.4708,  5.4332,  ...,  5.2274,  1.1127,  4.5017],\n",
            "        [14.5492, 32.4708,  5.4332,  ...,  5.2274,  1.1127,  4.5017],\n",
            "        ...,\n",
            "        [14.5492, 32.4708,  5.4332,  ...,  5.2274,  1.1127,  4.5017],\n",
            "        [14.5492, 32.4708,  5.4332,  ...,  5.2274,  1.1127,  4.5017],\n",
            "        [14.5492, 32.4708,  5.4332,  ...,  5.2274,  1.1127,  4.5017]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 727, Loss: 62061.605469\n",
            "tensor([[14.5881, 32.5879,  5.4538,  ...,  5.2599,  1.1227,  4.5146],\n",
            "        [14.5881, 32.5879,  5.4538,  ...,  5.2599,  1.1227,  4.5146],\n",
            "        [14.5881, 32.5879,  5.4538,  ...,  5.2599,  1.1227,  4.5146],\n",
            "        ...,\n",
            "        [14.5881, 32.5879,  5.4538,  ...,  5.2599,  1.1227,  4.5146],\n",
            "        [14.5881, 32.5879,  5.4538,  ...,  5.2599,  1.1227,  4.5146],\n",
            "        [14.5881, 32.5879,  5.4538,  ...,  5.2599,  1.1227,  4.5146]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 728, Loss: 62043.597656\n",
            "tensor([[14.6270, 32.7051,  5.4744,  ...,  5.2924,  1.1327,  4.5275],\n",
            "        [14.6270, 32.7051,  5.4744,  ...,  5.2924,  1.1327,  4.5275],\n",
            "        [14.6270, 32.7051,  5.4744,  ...,  5.2924,  1.1327,  4.5275],\n",
            "        ...,\n",
            "        [14.6270, 32.7051,  5.4744,  ...,  5.2924,  1.1327,  4.5275],\n",
            "        [14.6270, 32.7051,  5.4744,  ...,  5.2924,  1.1327,  4.5275],\n",
            "        [14.6270, 32.7051,  5.4744,  ...,  5.2924,  1.1327,  4.5275]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 729, Loss: 62025.597656\n",
            "tensor([[14.6658, 32.8221,  5.4951,  ...,  5.3249,  1.1427,  4.5404],\n",
            "        [14.6658, 32.8221,  5.4951,  ...,  5.3249,  1.1427,  4.5404],\n",
            "        [14.6658, 32.8221,  5.4951,  ...,  5.3249,  1.1427,  4.5404],\n",
            "        ...,\n",
            "        [14.6658, 32.8221,  5.4951,  ...,  5.3249,  1.1427,  4.5404],\n",
            "        [14.6658, 32.8221,  5.4951,  ...,  5.3249,  1.1427,  4.5404],\n",
            "        [14.6658, 32.8221,  5.4951,  ...,  5.3249,  1.1427,  4.5404]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 730, Loss: 62007.617188\n",
            "tensor([[14.7047, 32.9392,  5.5157,  ...,  5.3574,  1.1527,  4.5533],\n",
            "        [14.7047, 32.9392,  5.5157,  ...,  5.3574,  1.1527,  4.5533],\n",
            "        [14.7047, 32.9392,  5.5157,  ...,  5.3574,  1.1527,  4.5533],\n",
            "        ...,\n",
            "        [14.7047, 32.9392,  5.5157,  ...,  5.3574,  1.1527,  4.5533],\n",
            "        [14.7047, 32.9392,  5.5157,  ...,  5.3574,  1.1527,  4.5533],\n",
            "        [14.7047, 32.9392,  5.5157,  ...,  5.3574,  1.1527,  4.5533]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 731, Loss: 61989.632812\n",
            "tensor([[14.7436, 33.0562,  5.5364,  ...,  5.3899,  1.1627,  4.5662],\n",
            "        [14.7436, 33.0562,  5.5364,  ...,  5.3899,  1.1627,  4.5662],\n",
            "        [14.7436, 33.0562,  5.5364,  ...,  5.3899,  1.1627,  4.5662],\n",
            "        ...,\n",
            "        [14.7436, 33.0562,  5.5364,  ...,  5.3899,  1.1627,  4.5662],\n",
            "        [14.7436, 33.0562,  5.5364,  ...,  5.3899,  1.1627,  4.5662],\n",
            "        [14.7436, 33.0562,  5.5364,  ...,  5.3899,  1.1627,  4.5662]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 732, Loss: 61971.656250\n",
            "tensor([[14.7824, 33.1733,  5.5570,  ...,  5.4224,  1.1727,  4.5791],\n",
            "        [14.7824, 33.1733,  5.5570,  ...,  5.4224,  1.1727,  4.5791],\n",
            "        [14.7824, 33.1733,  5.5570,  ...,  5.4224,  1.1727,  4.5791],\n",
            "        ...,\n",
            "        [14.7824, 33.1733,  5.5570,  ...,  5.4224,  1.1727,  4.5791],\n",
            "        [14.7824, 33.1733,  5.5570,  ...,  5.4224,  1.1727,  4.5791],\n",
            "        [14.7824, 33.1733,  5.5570,  ...,  5.4224,  1.1727,  4.5791]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 733, Loss: 61953.687500\n",
            "tensor([[14.8212, 33.2903,  5.5776,  ...,  5.4548,  1.1827,  4.5920],\n",
            "        [14.8212, 33.2903,  5.5776,  ...,  5.4548,  1.1827,  4.5920],\n",
            "        [14.8212, 33.2903,  5.5776,  ...,  5.4548,  1.1827,  4.5920],\n",
            "        ...,\n",
            "        [14.8212, 33.2903,  5.5776,  ...,  5.4548,  1.1827,  4.5920],\n",
            "        [14.8212, 33.2903,  5.5776,  ...,  5.4548,  1.1827,  4.5920],\n",
            "        [14.8212, 33.2903,  5.5776,  ...,  5.4548,  1.1827,  4.5920]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 734, Loss: 61935.734375\n",
            "tensor([[14.8601, 33.4072,  5.5982,  ...,  5.4873,  1.1927,  4.6049],\n",
            "        [14.8601, 33.4072,  5.5982,  ...,  5.4873,  1.1927,  4.6049],\n",
            "        [14.8601, 33.4072,  5.5982,  ...,  5.4873,  1.1927,  4.6049],\n",
            "        ...,\n",
            "        [14.8601, 33.4072,  5.5982,  ...,  5.4873,  1.1927,  4.6049],\n",
            "        [14.8601, 33.4072,  5.5982,  ...,  5.4873,  1.1927,  4.6049],\n",
            "        [14.8601, 33.4072,  5.5982,  ...,  5.4873,  1.1927,  4.6049]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 735, Loss: 61917.781250\n",
            "tensor([[14.8989, 33.5242,  5.6189,  ...,  5.5197,  1.2027,  4.6178],\n",
            "        [14.8989, 33.5242,  5.6189,  ...,  5.5197,  1.2027,  4.6178],\n",
            "        [14.8989, 33.5242,  5.6189,  ...,  5.5197,  1.2027,  4.6178],\n",
            "        ...,\n",
            "        [14.8989, 33.5242,  5.6189,  ...,  5.5197,  1.2027,  4.6178],\n",
            "        [14.8989, 33.5242,  5.6189,  ...,  5.5197,  1.2027,  4.6178],\n",
            "        [14.8989, 33.5242,  5.6189,  ...,  5.5197,  1.2027,  4.6178]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 736, Loss: 61899.824219\n",
            "tensor([[14.9377, 33.6411,  5.6395,  ...,  5.5522,  1.2127,  4.6307],\n",
            "        [14.9377, 33.6411,  5.6395,  ...,  5.5522,  1.2127,  4.6307],\n",
            "        [14.9377, 33.6411,  5.6395,  ...,  5.5522,  1.2127,  4.6307],\n",
            "        ...,\n",
            "        [14.9377, 33.6411,  5.6395,  ...,  5.5522,  1.2127,  4.6307],\n",
            "        [14.9377, 33.6411,  5.6395,  ...,  5.5522,  1.2127,  4.6307],\n",
            "        [14.9377, 33.6411,  5.6395,  ...,  5.5522,  1.2127,  4.6307]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 737, Loss: 61881.890625\n",
            "tensor([[14.9765, 33.7580,  5.6601,  ...,  5.5846,  1.2227,  4.6435],\n",
            "        [14.9765, 33.7580,  5.6601,  ...,  5.5846,  1.2227,  4.6435],\n",
            "        [14.9765, 33.7580,  5.6601,  ...,  5.5846,  1.2227,  4.6435],\n",
            "        ...,\n",
            "        [14.9765, 33.7580,  5.6601,  ...,  5.5846,  1.2227,  4.6435],\n",
            "        [14.9765, 33.7580,  5.6601,  ...,  5.5846,  1.2227,  4.6435],\n",
            "        [14.9765, 33.7580,  5.6601,  ...,  5.5846,  1.2227,  4.6435]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 738, Loss: 61863.968750\n",
            "tensor([[15.0153, 33.8749,  5.6807,  ...,  5.6171,  1.2327,  4.6564],\n",
            "        [15.0153, 33.8749,  5.6807,  ...,  5.6171,  1.2327,  4.6564],\n",
            "        [15.0153, 33.8749,  5.6807,  ...,  5.6171,  1.2327,  4.6564],\n",
            "        ...,\n",
            "        [15.0153, 33.8749,  5.6807,  ...,  5.6171,  1.2327,  4.6564],\n",
            "        [15.0153, 33.8749,  5.6807,  ...,  5.6171,  1.2327,  4.6564],\n",
            "        [15.0153, 33.8749,  5.6807,  ...,  5.6171,  1.2327,  4.6564]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 739, Loss: 61846.042969\n",
            "tensor([[15.0541, 33.9917,  5.7013,  ...,  5.6495,  1.2427,  4.6693],\n",
            "        [15.0541, 33.9917,  5.7013,  ...,  5.6495,  1.2427,  4.6693],\n",
            "        [15.0541, 33.9917,  5.7013,  ...,  5.6495,  1.2427,  4.6693],\n",
            "        ...,\n",
            "        [15.0541, 33.9917,  5.7013,  ...,  5.6495,  1.2427,  4.6693],\n",
            "        [15.0541, 33.9917,  5.7013,  ...,  5.6495,  1.2427,  4.6693],\n",
            "        [15.0541, 33.9917,  5.7013,  ...,  5.6495,  1.2427,  4.6693]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 740, Loss: 61828.125000\n",
            "tensor([[15.0929, 34.1086,  5.7219,  ...,  5.6819,  1.2527,  4.6822],\n",
            "        [15.0929, 34.1086,  5.7219,  ...,  5.6819,  1.2527,  4.6822],\n",
            "        [15.0929, 34.1086,  5.7219,  ...,  5.6819,  1.2527,  4.6822],\n",
            "        ...,\n",
            "        [15.0929, 34.1086,  5.7219,  ...,  5.6819,  1.2527,  4.6822],\n",
            "        [15.0929, 34.1086,  5.7219,  ...,  5.6819,  1.2527,  4.6822],\n",
            "        [15.0929, 34.1086,  5.7219,  ...,  5.6819,  1.2527,  4.6822]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 741, Loss: 61810.218750\n",
            "tensor([[15.1317, 34.2254,  5.7425,  ...,  5.7144,  1.2626,  4.6950],\n",
            "        [15.1317, 34.2254,  5.7425,  ...,  5.7144,  1.2626,  4.6950],\n",
            "        [15.1317, 34.2254,  5.7425,  ...,  5.7144,  1.2626,  4.6950],\n",
            "        ...,\n",
            "        [15.1317, 34.2254,  5.7425,  ...,  5.7144,  1.2626,  4.6950],\n",
            "        [15.1317, 34.2254,  5.7425,  ...,  5.7144,  1.2626,  4.6950],\n",
            "        [15.1317, 34.2254,  5.7425,  ...,  5.7144,  1.2626,  4.6950]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 742, Loss: 61792.312500\n",
            "tensor([[15.1705, 34.3421,  5.7631,  ...,  5.7468,  1.2726,  4.7079],\n",
            "        [15.1705, 34.3421,  5.7631,  ...,  5.7468,  1.2726,  4.7079],\n",
            "        [15.1705, 34.3421,  5.7631,  ...,  5.7468,  1.2726,  4.7079],\n",
            "        ...,\n",
            "        [15.1705, 34.3421,  5.7631,  ...,  5.7468,  1.2726,  4.7079],\n",
            "        [15.1705, 34.3421,  5.7631,  ...,  5.7468,  1.2726,  4.7079],\n",
            "        [15.1705, 34.3421,  5.7631,  ...,  5.7468,  1.2726,  4.7079]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 743, Loss: 61774.414062\n",
            "tensor([[15.2093, 34.4589,  5.7836,  ...,  5.7792,  1.2826,  4.7208],\n",
            "        [15.2093, 34.4589,  5.7836,  ...,  5.7792,  1.2826,  4.7208],\n",
            "        [15.2093, 34.4589,  5.7836,  ...,  5.7792,  1.2826,  4.7208],\n",
            "        ...,\n",
            "        [15.2093, 34.4589,  5.7836,  ...,  5.7792,  1.2826,  4.7208],\n",
            "        [15.2093, 34.4589,  5.7836,  ...,  5.7792,  1.2826,  4.7208],\n",
            "        [15.2093, 34.4589,  5.7836,  ...,  5.7792,  1.2826,  4.7208]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 744, Loss: 61756.535156\n",
            "tensor([[15.2480, 34.5756,  5.8042,  ...,  5.8116,  1.2926,  4.7336],\n",
            "        [15.2480, 34.5756,  5.8042,  ...,  5.8116,  1.2926,  4.7336],\n",
            "        [15.2480, 34.5756,  5.8042,  ...,  5.8116,  1.2926,  4.7336],\n",
            "        ...,\n",
            "        [15.2480, 34.5756,  5.8042,  ...,  5.8116,  1.2926,  4.7336],\n",
            "        [15.2480, 34.5756,  5.8042,  ...,  5.8116,  1.2926,  4.7336],\n",
            "        [15.2480, 34.5756,  5.8042,  ...,  5.8116,  1.2926,  4.7336]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 745, Loss: 61738.644531\n",
            "tensor([[15.2868, 34.6924,  5.8248,  ...,  5.8440,  1.3025,  4.7465],\n",
            "        [15.2868, 34.6924,  5.8248,  ...,  5.8440,  1.3025,  4.7465],\n",
            "        [15.2868, 34.6924,  5.8248,  ...,  5.8440,  1.3025,  4.7465],\n",
            "        ...,\n",
            "        [15.2868, 34.6924,  5.8248,  ...,  5.8440,  1.3025,  4.7465],\n",
            "        [15.2868, 34.6924,  5.8248,  ...,  5.8440,  1.3025,  4.7465],\n",
            "        [15.2868, 34.6924,  5.8248,  ...,  5.8440,  1.3025,  4.7465]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 746, Loss: 61720.773438\n",
            "tensor([[15.3255, 34.8090,  5.8454,  ...,  5.8763,  1.3125,  4.7593],\n",
            "        [15.3255, 34.8090,  5.8454,  ...,  5.8763,  1.3125,  4.7593],\n",
            "        [15.3255, 34.8090,  5.8454,  ...,  5.8763,  1.3125,  4.7593],\n",
            "        ...,\n",
            "        [15.3255, 34.8090,  5.8454,  ...,  5.8763,  1.3125,  4.7593],\n",
            "        [15.3255, 34.8090,  5.8454,  ...,  5.8763,  1.3125,  4.7593],\n",
            "        [15.3255, 34.8090,  5.8454,  ...,  5.8763,  1.3125,  4.7593]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 747, Loss: 61702.906250\n",
            "tensor([[15.3642, 34.9257,  5.8659,  ...,  5.9087,  1.3225,  4.7722],\n",
            "        [15.3642, 34.9257,  5.8659,  ...,  5.9087,  1.3225,  4.7722],\n",
            "        [15.3642, 34.9257,  5.8659,  ...,  5.9087,  1.3225,  4.7722],\n",
            "        ...,\n",
            "        [15.3642, 34.9257,  5.8659,  ...,  5.9087,  1.3225,  4.7722],\n",
            "        [15.3642, 34.9257,  5.8659,  ...,  5.9087,  1.3225,  4.7722],\n",
            "        [15.3642, 34.9257,  5.8659,  ...,  5.9087,  1.3225,  4.7722]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 748, Loss: 61685.054688\n",
            "tensor([[15.4030, 35.0424,  5.8865,  ...,  5.9411,  1.3325,  4.7850],\n",
            "        [15.4030, 35.0424,  5.8865,  ...,  5.9411,  1.3325,  4.7850],\n",
            "        [15.4030, 35.0424,  5.8865,  ...,  5.9411,  1.3325,  4.7850],\n",
            "        ...,\n",
            "        [15.4030, 35.0424,  5.8865,  ...,  5.9411,  1.3325,  4.7850],\n",
            "        [15.4030, 35.0424,  5.8865,  ...,  5.9411,  1.3325,  4.7850],\n",
            "        [15.4030, 35.0424,  5.8865,  ...,  5.9411,  1.3325,  4.7850]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 749, Loss: 61667.199219\n",
            "tensor([[15.4417, 35.1590,  5.9071,  ...,  5.9735,  1.3424,  4.7979],\n",
            "        [15.4417, 35.1590,  5.9071,  ...,  5.9735,  1.3424,  4.7979],\n",
            "        [15.4417, 35.1590,  5.9071,  ...,  5.9735,  1.3424,  4.7979],\n",
            "        ...,\n",
            "        [15.4417, 35.1590,  5.9071,  ...,  5.9735,  1.3424,  4.7979],\n",
            "        [15.4417, 35.1590,  5.9071,  ...,  5.9735,  1.3424,  4.7979],\n",
            "        [15.4417, 35.1590,  5.9071,  ...,  5.9735,  1.3424,  4.7979]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 750, Loss: 61649.347656\n",
            "tensor([[15.4804, 35.2756,  5.9276,  ...,  6.0058,  1.3524,  4.8107],\n",
            "        [15.4804, 35.2756,  5.9276,  ...,  6.0058,  1.3524,  4.8107],\n",
            "        [15.4804, 35.2756,  5.9276,  ...,  6.0058,  1.3524,  4.8107],\n",
            "        ...,\n",
            "        [15.4804, 35.2756,  5.9276,  ...,  6.0058,  1.3524,  4.8107],\n",
            "        [15.4804, 35.2756,  5.9276,  ...,  6.0058,  1.3524,  4.8107],\n",
            "        [15.4804, 35.2756,  5.9276,  ...,  6.0058,  1.3524,  4.8107]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 751, Loss: 61631.511719\n",
            "tensor([[15.5191, 35.3921,  5.9482,  ...,  6.0382,  1.3624,  4.8236],\n",
            "        [15.5191, 35.3921,  5.9482,  ...,  6.0382,  1.3624,  4.8236],\n",
            "        [15.5191, 35.3921,  5.9482,  ...,  6.0382,  1.3624,  4.8236],\n",
            "        ...,\n",
            "        [15.5191, 35.3921,  5.9482,  ...,  6.0382,  1.3624,  4.8236],\n",
            "        [15.5191, 35.3921,  5.9482,  ...,  6.0382,  1.3624,  4.8236],\n",
            "        [15.5191, 35.3921,  5.9482,  ...,  6.0382,  1.3624,  4.8236]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 752, Loss: 61613.687500\n",
            "tensor([[15.5578, 35.5087,  5.9687,  ...,  6.0705,  1.3723,  4.8364],\n",
            "        [15.5578, 35.5087,  5.9687,  ...,  6.0705,  1.3723,  4.8364],\n",
            "        [15.5578, 35.5087,  5.9687,  ...,  6.0705,  1.3723,  4.8364],\n",
            "        ...,\n",
            "        [15.5578, 35.5087,  5.9687,  ...,  6.0705,  1.3723,  4.8364],\n",
            "        [15.5578, 35.5087,  5.9687,  ...,  6.0705,  1.3723,  4.8364],\n",
            "        [15.5578, 35.5087,  5.9687,  ...,  6.0705,  1.3723,  4.8364]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 753, Loss: 61595.859375\n",
            "tensor([[15.5965, 35.6252,  5.9893,  ...,  6.1029,  1.3823,  4.8493],\n",
            "        [15.5965, 35.6252,  5.9893,  ...,  6.1029,  1.3823,  4.8493],\n",
            "        [15.5965, 35.6252,  5.9893,  ...,  6.1029,  1.3823,  4.8493],\n",
            "        ...,\n",
            "        [15.5965, 35.6252,  5.9893,  ...,  6.1029,  1.3823,  4.8493],\n",
            "        [15.5965, 35.6252,  5.9893,  ...,  6.1029,  1.3823,  4.8493],\n",
            "        [15.5965, 35.6252,  5.9893,  ...,  6.1029,  1.3823,  4.8493]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 754, Loss: 61578.039062\n",
            "tensor([[15.6352, 35.7417,  6.0098,  ...,  6.1352,  1.3922,  4.8621],\n",
            "        [15.6352, 35.7417,  6.0098,  ...,  6.1352,  1.3922,  4.8621],\n",
            "        [15.6352, 35.7417,  6.0098,  ...,  6.1352,  1.3922,  4.8621],\n",
            "        ...,\n",
            "        [15.6352, 35.7417,  6.0098,  ...,  6.1352,  1.3922,  4.8621],\n",
            "        [15.6352, 35.7417,  6.0098,  ...,  6.1352,  1.3922,  4.8621],\n",
            "        [15.6352, 35.7417,  6.0098,  ...,  6.1352,  1.3922,  4.8621]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 755, Loss: 61560.226562\n",
            "tensor([[15.6738, 35.8582,  6.0303,  ...,  6.1675,  1.4022,  4.8749],\n",
            "        [15.6738, 35.8582,  6.0303,  ...,  6.1675,  1.4022,  4.8749],\n",
            "        [15.6738, 35.8582,  6.0303,  ...,  6.1675,  1.4022,  4.8749],\n",
            "        ...,\n",
            "        [15.6738, 35.8582,  6.0303,  ...,  6.1675,  1.4022,  4.8749],\n",
            "        [15.6738, 35.8582,  6.0303,  ...,  6.1675,  1.4022,  4.8749],\n",
            "        [15.6738, 35.8582,  6.0303,  ...,  6.1675,  1.4022,  4.8749]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 756, Loss: 61542.429688\n",
            "tensor([[15.7125, 35.9747,  6.0509,  ...,  6.1998,  1.4121,  4.8878],\n",
            "        [15.7125, 35.9747,  6.0509,  ...,  6.1998,  1.4121,  4.8878],\n",
            "        [15.7125, 35.9747,  6.0509,  ...,  6.1998,  1.4121,  4.8878],\n",
            "        ...,\n",
            "        [15.7125, 35.9747,  6.0509,  ...,  6.1998,  1.4121,  4.8878],\n",
            "        [15.7125, 35.9747,  6.0509,  ...,  6.1998,  1.4121,  4.8878],\n",
            "        [15.7125, 35.9747,  6.0509,  ...,  6.1998,  1.4121,  4.8878]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 757, Loss: 61524.636719\n",
            "tensor([[15.7512, 36.0911,  6.0714,  ...,  6.2322,  1.4221,  4.9006],\n",
            "        [15.7512, 36.0911,  6.0714,  ...,  6.2322,  1.4221,  4.9006],\n",
            "        [15.7512, 36.0911,  6.0714,  ...,  6.2322,  1.4221,  4.9006],\n",
            "        ...,\n",
            "        [15.7512, 36.0911,  6.0714,  ...,  6.2322,  1.4221,  4.9006],\n",
            "        [15.7512, 36.0911,  6.0714,  ...,  6.2322,  1.4221,  4.9006],\n",
            "        [15.7512, 36.0911,  6.0714,  ...,  6.2322,  1.4221,  4.9006]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 758, Loss: 61506.843750\n",
            "tensor([[15.7898, 36.2075,  6.0919,  ...,  6.2645,  1.4320,  4.9134],\n",
            "        [15.7898, 36.2075,  6.0919,  ...,  6.2645,  1.4320,  4.9134],\n",
            "        [15.7898, 36.2075,  6.0919,  ...,  6.2645,  1.4320,  4.9134],\n",
            "        ...,\n",
            "        [15.7898, 36.2075,  6.0919,  ...,  6.2645,  1.4320,  4.9134],\n",
            "        [15.7898, 36.2075,  6.0919,  ...,  6.2645,  1.4320,  4.9134],\n",
            "        [15.7898, 36.2075,  6.0919,  ...,  6.2645,  1.4320,  4.9134]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 759, Loss: 61489.062500\n",
            "tensor([[15.8284, 36.3239,  6.1124,  ...,  6.2968,  1.4420,  4.9263],\n",
            "        [15.8284, 36.3239,  6.1124,  ...,  6.2968,  1.4420,  4.9263],\n",
            "        [15.8284, 36.3239,  6.1124,  ...,  6.2968,  1.4420,  4.9263],\n",
            "        ...,\n",
            "        [15.8284, 36.3239,  6.1124,  ...,  6.2968,  1.4420,  4.9263],\n",
            "        [15.8284, 36.3239,  6.1124,  ...,  6.2968,  1.4420,  4.9263],\n",
            "        [15.8284, 36.3239,  6.1124,  ...,  6.2968,  1.4420,  4.9263]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 760, Loss: 61471.292969\n",
            "tensor([[15.8671, 36.4403,  6.1329,  ...,  6.3291,  1.4519,  4.9391],\n",
            "        [15.8671, 36.4403,  6.1329,  ...,  6.3291,  1.4519,  4.9391],\n",
            "        [15.8671, 36.4403,  6.1329,  ...,  6.3291,  1.4519,  4.9391],\n",
            "        ...,\n",
            "        [15.8671, 36.4403,  6.1329,  ...,  6.3291,  1.4519,  4.9391],\n",
            "        [15.8671, 36.4403,  6.1329,  ...,  6.3291,  1.4519,  4.9391],\n",
            "        [15.8671, 36.4403,  6.1329,  ...,  6.3291,  1.4519,  4.9391]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 761, Loss: 61453.515625\n",
            "tensor([[15.9057, 36.5566,  6.1534,  ...,  6.3614,  1.4619,  4.9519],\n",
            "        [15.9057, 36.5566,  6.1534,  ...,  6.3614,  1.4619,  4.9519],\n",
            "        [15.9057, 36.5566,  6.1534,  ...,  6.3614,  1.4619,  4.9519],\n",
            "        ...,\n",
            "        [15.9057, 36.5566,  6.1534,  ...,  6.3614,  1.4619,  4.9519],\n",
            "        [15.9057, 36.5566,  6.1534,  ...,  6.3614,  1.4619,  4.9519],\n",
            "        [15.9057, 36.5566,  6.1534,  ...,  6.3614,  1.4619,  4.9519]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 762, Loss: 61435.761719\n",
            "tensor([[15.9443, 36.6729,  6.1740,  ...,  6.3936,  1.4718,  4.9647],\n",
            "        [15.9443, 36.6729,  6.1740,  ...,  6.3936,  1.4718,  4.9647],\n",
            "        [15.9443, 36.6729,  6.1740,  ...,  6.3936,  1.4718,  4.9647],\n",
            "        ...,\n",
            "        [15.9443, 36.6729,  6.1740,  ...,  6.3936,  1.4718,  4.9647],\n",
            "        [15.9443, 36.6729,  6.1740,  ...,  6.3936,  1.4718,  4.9647],\n",
            "        [15.9443, 36.6729,  6.1740,  ...,  6.3936,  1.4718,  4.9647]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 763, Loss: 61418.007812\n",
            "tensor([[15.9829, 36.7892,  6.1945,  ...,  6.4259,  1.4817,  4.9775],\n",
            "        [15.9829, 36.7892,  6.1945,  ...,  6.4259,  1.4817,  4.9775],\n",
            "        [15.9829, 36.7892,  6.1945,  ...,  6.4259,  1.4817,  4.9775],\n",
            "        ...,\n",
            "        [15.9829, 36.7892,  6.1945,  ...,  6.4259,  1.4817,  4.9775],\n",
            "        [15.9829, 36.7892,  6.1945,  ...,  6.4259,  1.4817,  4.9775],\n",
            "        [15.9829, 36.7892,  6.1945,  ...,  6.4259,  1.4817,  4.9775]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 764, Loss: 61400.261719\n",
            "tensor([[16.0215, 36.9055,  6.2150,  ...,  6.4582,  1.4917,  4.9903],\n",
            "        [16.0215, 36.9055,  6.2150,  ...,  6.4582,  1.4917,  4.9903],\n",
            "        [16.0215, 36.9055,  6.2150,  ...,  6.4582,  1.4917,  4.9903],\n",
            "        ...,\n",
            "        [16.0215, 36.9055,  6.2150,  ...,  6.4582,  1.4917,  4.9903],\n",
            "        [16.0215, 36.9055,  6.2150,  ...,  6.4582,  1.4917,  4.9903],\n",
            "        [16.0215, 36.9055,  6.2150,  ...,  6.4582,  1.4917,  4.9903]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 765, Loss: 61382.519531\n",
            "tensor([[16.0601, 37.0217,  6.2354,  ...,  6.4904,  1.5016,  5.0031],\n",
            "        [16.0601, 37.0217,  6.2354,  ...,  6.4904,  1.5016,  5.0031],\n",
            "        [16.0601, 37.0217,  6.2354,  ...,  6.4904,  1.5016,  5.0031],\n",
            "        ...,\n",
            "        [16.0601, 37.0217,  6.2354,  ...,  6.4904,  1.5016,  5.0031],\n",
            "        [16.0601, 37.0217,  6.2354,  ...,  6.4904,  1.5016,  5.0031],\n",
            "        [16.0601, 37.0217,  6.2354,  ...,  6.4904,  1.5016,  5.0031]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 766, Loss: 61364.785156\n",
            "tensor([[16.0987, 37.1379,  6.2559,  ...,  6.5227,  1.5115,  5.0160],\n",
            "        [16.0987, 37.1379,  6.2559,  ...,  6.5227,  1.5115,  5.0160],\n",
            "        [16.0987, 37.1379,  6.2559,  ...,  6.5227,  1.5115,  5.0160],\n",
            "        ...,\n",
            "        [16.0987, 37.1379,  6.2559,  ...,  6.5227,  1.5115,  5.0160],\n",
            "        [16.0987, 37.1379,  6.2559,  ...,  6.5227,  1.5115,  5.0160],\n",
            "        [16.0987, 37.1379,  6.2559,  ...,  6.5227,  1.5115,  5.0160]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 767, Loss: 61347.066406\n",
            "tensor([[16.1373, 37.2541,  6.2764,  ...,  6.5550,  1.5215,  5.0288],\n",
            "        [16.1373, 37.2541,  6.2764,  ...,  6.5550,  1.5215,  5.0288],\n",
            "        [16.1373, 37.2541,  6.2764,  ...,  6.5550,  1.5215,  5.0288],\n",
            "        ...,\n",
            "        [16.1373, 37.2541,  6.2764,  ...,  6.5550,  1.5215,  5.0288],\n",
            "        [16.1373, 37.2541,  6.2764,  ...,  6.5550,  1.5215,  5.0288],\n",
            "        [16.1373, 37.2541,  6.2764,  ...,  6.5550,  1.5215,  5.0288]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 768, Loss: 61329.351562\n",
            "tensor([[16.1759, 37.3703,  6.2969,  ...,  6.5872,  1.5314,  5.0416],\n",
            "        [16.1759, 37.3703,  6.2969,  ...,  6.5872,  1.5314,  5.0416],\n",
            "        [16.1759, 37.3703,  6.2969,  ...,  6.5872,  1.5314,  5.0416],\n",
            "        ...,\n",
            "        [16.1759, 37.3703,  6.2969,  ...,  6.5872,  1.5314,  5.0416],\n",
            "        [16.1759, 37.3703,  6.2969,  ...,  6.5872,  1.5314,  5.0416],\n",
            "        [16.1759, 37.3703,  6.2969,  ...,  6.5872,  1.5314,  5.0416]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 769, Loss: 61311.640625\n",
            "tensor([[16.2144, 37.4865,  6.3174,  ...,  6.6194,  1.5413,  5.0544],\n",
            "        [16.2144, 37.4865,  6.3174,  ...,  6.6194,  1.5413,  5.0544],\n",
            "        [16.2144, 37.4865,  6.3174,  ...,  6.6194,  1.5413,  5.0544],\n",
            "        ...,\n",
            "        [16.2144, 37.4865,  6.3174,  ...,  6.6194,  1.5413,  5.0544],\n",
            "        [16.2144, 37.4865,  6.3174,  ...,  6.6194,  1.5413,  5.0544],\n",
            "        [16.2144, 37.4865,  6.3174,  ...,  6.6194,  1.5413,  5.0544]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 770, Loss: 61293.941406\n",
            "tensor([[16.2530, 37.6026,  6.3379,  ...,  6.6517,  1.5512,  5.0672],\n",
            "        [16.2530, 37.6026,  6.3379,  ...,  6.6517,  1.5512,  5.0672],\n",
            "        [16.2530, 37.6026,  6.3379,  ...,  6.6517,  1.5512,  5.0672],\n",
            "        ...,\n",
            "        [16.2530, 37.6026,  6.3379,  ...,  6.6517,  1.5512,  5.0672],\n",
            "        [16.2530, 37.6026,  6.3379,  ...,  6.6517,  1.5512,  5.0672],\n",
            "        [16.2530, 37.6026,  6.3379,  ...,  6.6517,  1.5512,  5.0672]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 771, Loss: 61276.242188\n",
            "tensor([[16.2915, 37.7187,  6.3583,  ...,  6.6839,  1.5612,  5.0799],\n",
            "        [16.2915, 37.7187,  6.3583,  ...,  6.6839,  1.5612,  5.0799],\n",
            "        [16.2915, 37.7187,  6.3583,  ...,  6.6839,  1.5612,  5.0799],\n",
            "        ...,\n",
            "        [16.2915, 37.7187,  6.3583,  ...,  6.6839,  1.5612,  5.0799],\n",
            "        [16.2915, 37.7187,  6.3583,  ...,  6.6839,  1.5612,  5.0799],\n",
            "        [16.2915, 37.7187,  6.3583,  ...,  6.6839,  1.5612,  5.0799]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 772, Loss: 61258.550781\n",
            "tensor([[16.3301, 37.8348,  6.3788,  ...,  6.7161,  1.5711,  5.0927],\n",
            "        [16.3301, 37.8348,  6.3788,  ...,  6.7161,  1.5711,  5.0927],\n",
            "        [16.3301, 37.8348,  6.3788,  ...,  6.7161,  1.5711,  5.0927],\n",
            "        ...,\n",
            "        [16.3301, 37.8348,  6.3788,  ...,  6.7161,  1.5711,  5.0927],\n",
            "        [16.3301, 37.8348,  6.3788,  ...,  6.7161,  1.5711,  5.0927],\n",
            "        [16.3301, 37.8348,  6.3788,  ...,  6.7161,  1.5711,  5.0927]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 773, Loss: 61240.867188\n",
            "tensor([[16.3686, 37.9509,  6.3992,  ...,  6.7483,  1.5810,  5.1055],\n",
            "        [16.3686, 37.9509,  6.3992,  ...,  6.7483,  1.5810,  5.1055],\n",
            "        [16.3686, 37.9509,  6.3992,  ...,  6.7483,  1.5810,  5.1055],\n",
            "        ...,\n",
            "        [16.3686, 37.9509,  6.3992,  ...,  6.7483,  1.5810,  5.1055],\n",
            "        [16.3686, 37.9509,  6.3992,  ...,  6.7483,  1.5810,  5.1055],\n",
            "        [16.3686, 37.9509,  6.3992,  ...,  6.7483,  1.5810,  5.1055]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 774, Loss: 61223.199219\n",
            "tensor([[16.4071, 38.0669,  6.4197,  ...,  6.7805,  1.5909,  5.1183],\n",
            "        [16.4071, 38.0669,  6.4197,  ...,  6.7805,  1.5909,  5.1183],\n",
            "        [16.4071, 38.0669,  6.4197,  ...,  6.7805,  1.5909,  5.1183],\n",
            "        ...,\n",
            "        [16.4071, 38.0669,  6.4197,  ...,  6.7805,  1.5909,  5.1183],\n",
            "        [16.4071, 38.0669,  6.4197,  ...,  6.7805,  1.5909,  5.1183],\n",
            "        [16.4071, 38.0669,  6.4197,  ...,  6.7805,  1.5909,  5.1183]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 775, Loss: 61205.531250\n",
            "tensor([[16.4457, 38.1829,  6.4402,  ...,  6.8127,  1.6008,  5.1311],\n",
            "        [16.4457, 38.1829,  6.4402,  ...,  6.8127,  1.6008,  5.1311],\n",
            "        [16.4457, 38.1829,  6.4402,  ...,  6.8127,  1.6008,  5.1311],\n",
            "        ...,\n",
            "        [16.4457, 38.1829,  6.4402,  ...,  6.8127,  1.6008,  5.1311],\n",
            "        [16.4457, 38.1829,  6.4402,  ...,  6.8127,  1.6008,  5.1311],\n",
            "        [16.4457, 38.1829,  6.4402,  ...,  6.8127,  1.6008,  5.1311]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 776, Loss: 61187.871094\n",
            "tensor([[16.4842, 38.2989,  6.4606,  ...,  6.8449,  1.6108,  5.1439],\n",
            "        [16.4842, 38.2989,  6.4606,  ...,  6.8449,  1.6108,  5.1439],\n",
            "        [16.4842, 38.2989,  6.4606,  ...,  6.8449,  1.6108,  5.1439],\n",
            "        ...,\n",
            "        [16.4842, 38.2989,  6.4606,  ...,  6.8449,  1.6108,  5.1439],\n",
            "        [16.4842, 38.2989,  6.4606,  ...,  6.8449,  1.6108,  5.1439],\n",
            "        [16.4842, 38.2989,  6.4606,  ...,  6.8449,  1.6108,  5.1439]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 777, Loss: 61170.210938\n",
            "tensor([[16.5227, 38.4149,  6.4811,  ...,  6.8771,  1.6207,  5.1567],\n",
            "        [16.5227, 38.4149,  6.4811,  ...,  6.8771,  1.6207,  5.1567],\n",
            "        [16.5227, 38.4149,  6.4811,  ...,  6.8771,  1.6207,  5.1567],\n",
            "        ...,\n",
            "        [16.5227, 38.4149,  6.4811,  ...,  6.8771,  1.6207,  5.1567],\n",
            "        [16.5227, 38.4149,  6.4811,  ...,  6.8771,  1.6207,  5.1567],\n",
            "        [16.5227, 38.4149,  6.4811,  ...,  6.8771,  1.6207,  5.1567]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 778, Loss: 61152.562500\n",
            "tensor([[16.5612, 38.5308,  6.5015,  ...,  6.9093,  1.6306,  5.1694],\n",
            "        [16.5612, 38.5308,  6.5015,  ...,  6.9093,  1.6306,  5.1694],\n",
            "        [16.5612, 38.5308,  6.5015,  ...,  6.9093,  1.6306,  5.1694],\n",
            "        ...,\n",
            "        [16.5612, 38.5308,  6.5015,  ...,  6.9093,  1.6306,  5.1694],\n",
            "        [16.5612, 38.5308,  6.5015,  ...,  6.9093,  1.6306,  5.1694],\n",
            "        [16.5612, 38.5308,  6.5015,  ...,  6.9093,  1.6306,  5.1694]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 779, Loss: 61134.925781\n",
            "tensor([[16.5997, 38.6467,  6.5219,  ...,  6.9414,  1.6405,  5.1822],\n",
            "        [16.5997, 38.6467,  6.5219,  ...,  6.9414,  1.6405,  5.1822],\n",
            "        [16.5997, 38.6467,  6.5219,  ...,  6.9414,  1.6405,  5.1822],\n",
            "        ...,\n",
            "        [16.5997, 38.6467,  6.5219,  ...,  6.9414,  1.6405,  5.1822],\n",
            "        [16.5997, 38.6467,  6.5219,  ...,  6.9414,  1.6405,  5.1822],\n",
            "        [16.5997, 38.6467,  6.5219,  ...,  6.9414,  1.6405,  5.1822]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 780, Loss: 61117.296875\n",
            "tensor([[16.6381, 38.7626,  6.5424,  ...,  6.9736,  1.6504,  5.1950],\n",
            "        [16.6381, 38.7626,  6.5424,  ...,  6.9736,  1.6504,  5.1950],\n",
            "        [16.6381, 38.7626,  6.5424,  ...,  6.9736,  1.6504,  5.1950],\n",
            "        ...,\n",
            "        [16.6381, 38.7626,  6.5424,  ...,  6.9736,  1.6504,  5.1950],\n",
            "        [16.6381, 38.7626,  6.5424,  ...,  6.9736,  1.6504,  5.1950],\n",
            "        [16.6381, 38.7626,  6.5424,  ...,  6.9736,  1.6504,  5.1950]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 781, Loss: 61099.664062\n",
            "tensor([[16.6766, 38.8785,  6.5628,  ...,  7.0058,  1.6603,  5.2077],\n",
            "        [16.6766, 38.8785,  6.5628,  ...,  7.0058,  1.6603,  5.2077],\n",
            "        [16.6766, 38.8785,  6.5628,  ...,  7.0058,  1.6603,  5.2077],\n",
            "        ...,\n",
            "        [16.6766, 38.8785,  6.5628,  ...,  7.0058,  1.6603,  5.2077],\n",
            "        [16.6766, 38.8785,  6.5628,  ...,  7.0058,  1.6603,  5.2077],\n",
            "        [16.6766, 38.8785,  6.5628,  ...,  7.0058,  1.6603,  5.2077]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 782, Loss: 61082.046875\n",
            "tensor([[16.7151, 38.9944,  6.5832,  ...,  7.0379,  1.6702,  5.2205],\n",
            "        [16.7151, 38.9944,  6.5832,  ...,  7.0379,  1.6702,  5.2205],\n",
            "        [16.7151, 38.9944,  6.5832,  ...,  7.0379,  1.6702,  5.2205],\n",
            "        ...,\n",
            "        [16.7151, 38.9944,  6.5832,  ...,  7.0379,  1.6702,  5.2205],\n",
            "        [16.7151, 38.9944,  6.5832,  ...,  7.0379,  1.6702,  5.2205],\n",
            "        [16.7151, 38.9944,  6.5832,  ...,  7.0379,  1.6702,  5.2205]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 783, Loss: 61064.441406\n",
            "tensor([[16.7535, 39.1102,  6.6036,  ...,  7.0701,  1.6801,  5.2333],\n",
            "        [16.7535, 39.1102,  6.6036,  ...,  7.0701,  1.6801,  5.2333],\n",
            "        [16.7535, 39.1102,  6.6036,  ...,  7.0701,  1.6801,  5.2333],\n",
            "        ...,\n",
            "        [16.7535, 39.1102,  6.6036,  ...,  7.0701,  1.6801,  5.2333],\n",
            "        [16.7535, 39.1102,  6.6036,  ...,  7.0701,  1.6801,  5.2333],\n",
            "        [16.7535, 39.1102,  6.6036,  ...,  7.0701,  1.6801,  5.2333]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 784, Loss: 61046.832031\n",
            "tensor([[16.7920, 39.2260,  6.6240,  ...,  7.1022,  1.6900,  5.2460],\n",
            "        [16.7920, 39.2260,  6.6240,  ...,  7.1022,  1.6900,  5.2460],\n",
            "        [16.7920, 39.2260,  6.6240,  ...,  7.1022,  1.6900,  5.2460],\n",
            "        ...,\n",
            "        [16.7920, 39.2260,  6.6240,  ...,  7.1022,  1.6900,  5.2460],\n",
            "        [16.7920, 39.2260,  6.6240,  ...,  7.1022,  1.6900,  5.2460],\n",
            "        [16.7920, 39.2260,  6.6240,  ...,  7.1022,  1.6900,  5.2460]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 785, Loss: 61029.238281\n",
            "tensor([[16.8304, 39.3418,  6.6445,  ...,  7.1343,  1.6999,  5.2588],\n",
            "        [16.8304, 39.3418,  6.6445,  ...,  7.1343,  1.6999,  5.2588],\n",
            "        [16.8304, 39.3418,  6.6445,  ...,  7.1343,  1.6999,  5.2588],\n",
            "        ...,\n",
            "        [16.8304, 39.3418,  6.6445,  ...,  7.1343,  1.6999,  5.2588],\n",
            "        [16.8304, 39.3418,  6.6445,  ...,  7.1343,  1.6999,  5.2588],\n",
            "        [16.8304, 39.3418,  6.6445,  ...,  7.1343,  1.6999,  5.2588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 786, Loss: 61011.644531\n",
            "tensor([[16.8689, 39.4576,  6.6649,  ...,  7.1665,  1.7098,  5.2715],\n",
            "        [16.8689, 39.4576,  6.6649,  ...,  7.1665,  1.7098,  5.2715],\n",
            "        [16.8689, 39.4576,  6.6649,  ...,  7.1665,  1.7098,  5.2715],\n",
            "        ...,\n",
            "        [16.8689, 39.4576,  6.6649,  ...,  7.1665,  1.7098,  5.2715],\n",
            "        [16.8689, 39.4576,  6.6649,  ...,  7.1665,  1.7098,  5.2715],\n",
            "        [16.8689, 39.4576,  6.6649,  ...,  7.1665,  1.7098,  5.2715]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 787, Loss: 60994.062500\n",
            "tensor([[16.9073, 39.5733,  6.6853,  ...,  7.1986,  1.7197,  5.2843],\n",
            "        [16.9073, 39.5733,  6.6853,  ...,  7.1986,  1.7197,  5.2843],\n",
            "        [16.9073, 39.5733,  6.6853,  ...,  7.1986,  1.7197,  5.2843],\n",
            "        ...,\n",
            "        [16.9073, 39.5733,  6.6853,  ...,  7.1986,  1.7197,  5.2843],\n",
            "        [16.9073, 39.5733,  6.6853,  ...,  7.1986,  1.7197,  5.2843],\n",
            "        [16.9073, 39.5733,  6.6853,  ...,  7.1986,  1.7197,  5.2843]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 788, Loss: 60976.492188\n",
            "tensor([[16.9457, 39.6890,  6.7057,  ...,  7.2307,  1.7295,  5.2970],\n",
            "        [16.9457, 39.6890,  6.7057,  ...,  7.2307,  1.7295,  5.2970],\n",
            "        [16.9457, 39.6890,  6.7057,  ...,  7.2307,  1.7295,  5.2970],\n",
            "        ...,\n",
            "        [16.9457, 39.6890,  6.7057,  ...,  7.2307,  1.7295,  5.2970],\n",
            "        [16.9457, 39.6890,  6.7057,  ...,  7.2307,  1.7295,  5.2970],\n",
            "        [16.9457, 39.6890,  6.7057,  ...,  7.2307,  1.7295,  5.2970]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 789, Loss: 60958.921875\n",
            "tensor([[16.9841, 39.8047,  6.7261,  ...,  7.2628,  1.7394,  5.3098],\n",
            "        [16.9841, 39.8047,  6.7261,  ...,  7.2628,  1.7394,  5.3098],\n",
            "        [16.9841, 39.8047,  6.7261,  ...,  7.2628,  1.7394,  5.3098],\n",
            "        ...,\n",
            "        [16.9841, 39.8047,  6.7261,  ...,  7.2628,  1.7394,  5.3098],\n",
            "        [16.9841, 39.8047,  6.7261,  ...,  7.2628,  1.7394,  5.3098],\n",
            "        [16.9841, 39.8047,  6.7261,  ...,  7.2628,  1.7394,  5.3098]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 790, Loss: 60941.355469\n",
            "tensor([[17.0225, 39.9204,  6.7465,  ...,  7.2949,  1.7493,  5.3225],\n",
            "        [17.0225, 39.9204,  6.7465,  ...,  7.2949,  1.7493,  5.3225],\n",
            "        [17.0225, 39.9204,  6.7465,  ...,  7.2949,  1.7493,  5.3225],\n",
            "        ...,\n",
            "        [17.0225, 39.9204,  6.7465,  ...,  7.2949,  1.7493,  5.3225],\n",
            "        [17.0225, 39.9204,  6.7465,  ...,  7.2949,  1.7493,  5.3225],\n",
            "        [17.0225, 39.9204,  6.7465,  ...,  7.2949,  1.7493,  5.3225]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 791, Loss: 60923.796875\n",
            "tensor([[17.0609, 40.0360,  6.7668,  ...,  7.3270,  1.7592,  5.3353],\n",
            "        [17.0609, 40.0360,  6.7668,  ...,  7.3270,  1.7592,  5.3353],\n",
            "        [17.0609, 40.0360,  6.7668,  ...,  7.3270,  1.7592,  5.3353],\n",
            "        ...,\n",
            "        [17.0609, 40.0360,  6.7668,  ...,  7.3270,  1.7592,  5.3353],\n",
            "        [17.0609, 40.0360,  6.7668,  ...,  7.3270,  1.7592,  5.3353],\n",
            "        [17.0609, 40.0360,  6.7668,  ...,  7.3270,  1.7592,  5.3353]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 792, Loss: 60906.257812\n",
            "tensor([[17.0993, 40.1516,  6.7872,  ...,  7.3591,  1.7691,  5.3480],\n",
            "        [17.0993, 40.1516,  6.7872,  ...,  7.3591,  1.7691,  5.3480],\n",
            "        [17.0993, 40.1516,  6.7872,  ...,  7.3591,  1.7691,  5.3480],\n",
            "        ...,\n",
            "        [17.0993, 40.1516,  6.7872,  ...,  7.3591,  1.7691,  5.3480],\n",
            "        [17.0993, 40.1516,  6.7872,  ...,  7.3591,  1.7691,  5.3480],\n",
            "        [17.0993, 40.1516,  6.7872,  ...,  7.3591,  1.7691,  5.3480]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 793, Loss: 60888.722656\n",
            "tensor([[17.1377, 40.2672,  6.8076,  ...,  7.3912,  1.7790,  5.3608],\n",
            "        [17.1377, 40.2672,  6.8076,  ...,  7.3912,  1.7790,  5.3608],\n",
            "        [17.1377, 40.2672,  6.8076,  ...,  7.3912,  1.7790,  5.3608],\n",
            "        ...,\n",
            "        [17.1377, 40.2672,  6.8076,  ...,  7.3912,  1.7790,  5.3608],\n",
            "        [17.1377, 40.2672,  6.8076,  ...,  7.3912,  1.7790,  5.3608],\n",
            "        [17.1377, 40.2672,  6.8076,  ...,  7.3912,  1.7790,  5.3608]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 794, Loss: 60871.179688\n",
            "tensor([[17.1760, 40.3828,  6.8280,  ...,  7.4233,  1.7888,  5.3735],\n",
            "        [17.1760, 40.3828,  6.8280,  ...,  7.4233,  1.7888,  5.3735],\n",
            "        [17.1760, 40.3828,  6.8280,  ...,  7.4233,  1.7888,  5.3735],\n",
            "        ...,\n",
            "        [17.1760, 40.3828,  6.8280,  ...,  7.4233,  1.7888,  5.3735],\n",
            "        [17.1760, 40.3828,  6.8280,  ...,  7.4233,  1.7888,  5.3735],\n",
            "        [17.1760, 40.3828,  6.8280,  ...,  7.4233,  1.7888,  5.3735]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 795, Loss: 60853.656250\n",
            "tensor([[17.2144, 40.4983,  6.8484,  ...,  7.4553,  1.7987,  5.3862],\n",
            "        [17.2144, 40.4983,  6.8484,  ...,  7.4553,  1.7987,  5.3862],\n",
            "        [17.2144, 40.4983,  6.8484,  ...,  7.4553,  1.7987,  5.3862],\n",
            "        ...,\n",
            "        [17.2144, 40.4983,  6.8484,  ...,  7.4553,  1.7987,  5.3862],\n",
            "        [17.2144, 40.4983,  6.8484,  ...,  7.4553,  1.7987,  5.3862],\n",
            "        [17.2144, 40.4983,  6.8484,  ...,  7.4553,  1.7987,  5.3862]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 796, Loss: 60836.128906\n",
            "tensor([[17.2528, 40.6139,  6.8687,  ...,  7.4874,  1.8086,  5.3989],\n",
            "        [17.2528, 40.6139,  6.8687,  ...,  7.4874,  1.8086,  5.3989],\n",
            "        [17.2528, 40.6139,  6.8687,  ...,  7.4874,  1.8086,  5.3989],\n",
            "        ...,\n",
            "        [17.2528, 40.6139,  6.8687,  ...,  7.4874,  1.8086,  5.3989],\n",
            "        [17.2528, 40.6139,  6.8687,  ...,  7.4874,  1.8086,  5.3989],\n",
            "        [17.2528, 40.6139,  6.8687,  ...,  7.4874,  1.8086,  5.3989]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 797, Loss: 60818.617188\n",
            "tensor([[17.2911, 40.7294,  6.8891,  ...,  7.5195,  1.8185,  5.4117],\n",
            "        [17.2911, 40.7294,  6.8891,  ...,  7.5195,  1.8185,  5.4117],\n",
            "        [17.2911, 40.7294,  6.8891,  ...,  7.5195,  1.8185,  5.4117],\n",
            "        ...,\n",
            "        [17.2911, 40.7294,  6.8891,  ...,  7.5195,  1.8185,  5.4117],\n",
            "        [17.2911, 40.7294,  6.8891,  ...,  7.5195,  1.8185,  5.4117],\n",
            "        [17.2911, 40.7294,  6.8891,  ...,  7.5195,  1.8185,  5.4117]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 798, Loss: 60801.117188\n",
            "tensor([[17.3295, 40.8449,  6.9094,  ...,  7.5515,  1.8283,  5.4244],\n",
            "        [17.3295, 40.8449,  6.9094,  ...,  7.5515,  1.8283,  5.4244],\n",
            "        [17.3295, 40.8449,  6.9094,  ...,  7.5515,  1.8283,  5.4244],\n",
            "        ...,\n",
            "        [17.3295, 40.8449,  6.9094,  ...,  7.5515,  1.8283,  5.4244],\n",
            "        [17.3295, 40.8449,  6.9094,  ...,  7.5515,  1.8283,  5.4244],\n",
            "        [17.3295, 40.8449,  6.9094,  ...,  7.5515,  1.8283,  5.4244]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 799, Loss: 60783.621094\n",
            "tensor([[17.3678, 40.9603,  6.9298,  ...,  7.5835,  1.8382,  5.4371],\n",
            "        [17.3678, 40.9603,  6.9298,  ...,  7.5835,  1.8382,  5.4371],\n",
            "        [17.3678, 40.9603,  6.9298,  ...,  7.5835,  1.8382,  5.4371],\n",
            "        ...,\n",
            "        [17.3678, 40.9603,  6.9298,  ...,  7.5835,  1.8382,  5.4371],\n",
            "        [17.3678, 40.9603,  6.9298,  ...,  7.5835,  1.8382,  5.4371],\n",
            "        [17.3678, 40.9603,  6.9298,  ...,  7.5835,  1.8382,  5.4371]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 800, Loss: 60766.121094\n",
            "tensor([[17.4061, 41.0758,  6.9501,  ...,  7.6156,  1.8481,  5.4498],\n",
            "        [17.4061, 41.0758,  6.9501,  ...,  7.6156,  1.8481,  5.4498],\n",
            "        [17.4061, 41.0758,  6.9501,  ...,  7.6156,  1.8481,  5.4498],\n",
            "        ...,\n",
            "        [17.4061, 41.0758,  6.9501,  ...,  7.6156,  1.8481,  5.4498],\n",
            "        [17.4061, 41.0758,  6.9501,  ...,  7.6156,  1.8481,  5.4498],\n",
            "        [17.4061, 41.0758,  6.9501,  ...,  7.6156,  1.8481,  5.4498]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 801, Loss: 60748.636719\n",
            "tensor([[17.4444, 41.1912,  6.9705,  ...,  7.6476,  1.8579,  5.4626],\n",
            "        [17.4444, 41.1912,  6.9705,  ...,  7.6476,  1.8579,  5.4626],\n",
            "        [17.4444, 41.1912,  6.9705,  ...,  7.6476,  1.8579,  5.4626],\n",
            "        ...,\n",
            "        [17.4444, 41.1912,  6.9705,  ...,  7.6476,  1.8579,  5.4626],\n",
            "        [17.4444, 41.1912,  6.9705,  ...,  7.6476,  1.8579,  5.4626],\n",
            "        [17.4444, 41.1912,  6.9705,  ...,  7.6476,  1.8579,  5.4626]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 802, Loss: 60731.164062\n",
            "tensor([[17.4827, 41.3066,  6.9908,  ...,  7.6796,  1.8678,  5.4753],\n",
            "        [17.4827, 41.3066,  6.9908,  ...,  7.6796,  1.8678,  5.4753],\n",
            "        [17.4827, 41.3066,  6.9908,  ...,  7.6796,  1.8678,  5.4753],\n",
            "        ...,\n",
            "        [17.4827, 41.3066,  6.9908,  ...,  7.6796,  1.8678,  5.4753],\n",
            "        [17.4827, 41.3066,  6.9908,  ...,  7.6796,  1.8678,  5.4753],\n",
            "        [17.4827, 41.3066,  6.9908,  ...,  7.6796,  1.8678,  5.4753]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 803, Loss: 60713.687500\n",
            "tensor([[17.5211, 41.4219,  7.0112,  ...,  7.7117,  1.8776,  5.4880],\n",
            "        [17.5211, 41.4219,  7.0112,  ...,  7.7117,  1.8776,  5.4880],\n",
            "        [17.5211, 41.4219,  7.0112,  ...,  7.7117,  1.8776,  5.4880],\n",
            "        ...,\n",
            "        [17.5211, 41.4219,  7.0112,  ...,  7.7117,  1.8776,  5.4880],\n",
            "        [17.5211, 41.4219,  7.0112,  ...,  7.7117,  1.8776,  5.4880],\n",
            "        [17.5211, 41.4219,  7.0112,  ...,  7.7117,  1.8776,  5.4880]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 804, Loss: 60696.226562\n",
            "tensor([[17.5593, 41.5373,  7.0315,  ...,  7.7437,  1.8875,  5.5007],\n",
            "        [17.5593, 41.5373,  7.0315,  ...,  7.7437,  1.8875,  5.5007],\n",
            "        [17.5593, 41.5373,  7.0315,  ...,  7.7437,  1.8875,  5.5007],\n",
            "        ...,\n",
            "        [17.5593, 41.5373,  7.0315,  ...,  7.7437,  1.8875,  5.5007],\n",
            "        [17.5593, 41.5373,  7.0315,  ...,  7.7437,  1.8875,  5.5007],\n",
            "        [17.5593, 41.5373,  7.0315,  ...,  7.7437,  1.8875,  5.5007]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 805, Loss: 60678.769531\n",
            "tensor([[17.5976, 41.6526,  7.0518,  ...,  7.7757,  1.8973,  5.5134],\n",
            "        [17.5976, 41.6526,  7.0518,  ...,  7.7757,  1.8973,  5.5134],\n",
            "        [17.5976, 41.6526,  7.0518,  ...,  7.7757,  1.8973,  5.5134],\n",
            "        ...,\n",
            "        [17.5976, 41.6526,  7.0518,  ...,  7.7757,  1.8973,  5.5134],\n",
            "        [17.5976, 41.6526,  7.0518,  ...,  7.7757,  1.8973,  5.5134],\n",
            "        [17.5976, 41.6526,  7.0518,  ...,  7.7757,  1.8973,  5.5134]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 806, Loss: 60661.320312\n",
            "tensor([[17.6359, 41.7679,  7.0722,  ...,  7.8077,  1.9072,  5.5261],\n",
            "        [17.6359, 41.7679,  7.0722,  ...,  7.8077,  1.9072,  5.5261],\n",
            "        [17.6359, 41.7679,  7.0722,  ...,  7.8077,  1.9072,  5.5261],\n",
            "        ...,\n",
            "        [17.6359, 41.7679,  7.0722,  ...,  7.8077,  1.9072,  5.5261],\n",
            "        [17.6359, 41.7679,  7.0722,  ...,  7.8077,  1.9072,  5.5261],\n",
            "        [17.6359, 41.7679,  7.0722,  ...,  7.8077,  1.9072,  5.5261]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 807, Loss: 60643.875000\n",
            "tensor([[17.6742, 41.8832,  7.0925,  ...,  7.8397,  1.9170,  5.5388],\n",
            "        [17.6742, 41.8832,  7.0925,  ...,  7.8397,  1.9170,  5.5388],\n",
            "        [17.6742, 41.8832,  7.0925,  ...,  7.8397,  1.9170,  5.5388],\n",
            "        ...,\n",
            "        [17.6742, 41.8832,  7.0925,  ...,  7.8397,  1.9170,  5.5388],\n",
            "        [17.6742, 41.8832,  7.0925,  ...,  7.8397,  1.9170,  5.5388],\n",
            "        [17.6742, 41.8832,  7.0925,  ...,  7.8397,  1.9170,  5.5388]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 808, Loss: 60626.441406\n",
            "tensor([[17.7125, 41.9984,  7.1128,  ...,  7.8717,  1.9269,  5.5515],\n",
            "        [17.7125, 41.9984,  7.1128,  ...,  7.8717,  1.9269,  5.5515],\n",
            "        [17.7125, 41.9984,  7.1128,  ...,  7.8717,  1.9269,  5.5515],\n",
            "        ...,\n",
            "        [17.7125, 41.9984,  7.1128,  ...,  7.8717,  1.9269,  5.5515],\n",
            "        [17.7125, 41.9984,  7.1128,  ...,  7.8717,  1.9269,  5.5515],\n",
            "        [17.7125, 41.9984,  7.1128,  ...,  7.8717,  1.9269,  5.5515]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 809, Loss: 60609.007812\n",
            "tensor([[17.7507, 42.1137,  7.1331,  ...,  7.9036,  1.9367,  5.5642],\n",
            "        [17.7507, 42.1137,  7.1331,  ...,  7.9036,  1.9367,  5.5642],\n",
            "        [17.7507, 42.1137,  7.1331,  ...,  7.9036,  1.9367,  5.5642],\n",
            "        ...,\n",
            "        [17.7507, 42.1137,  7.1331,  ...,  7.9036,  1.9367,  5.5642],\n",
            "        [17.7507, 42.1137,  7.1331,  ...,  7.9036,  1.9367,  5.5642],\n",
            "        [17.7507, 42.1137,  7.1331,  ...,  7.9036,  1.9367,  5.5642]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 810, Loss: 60591.593750\n",
            "tensor([[17.7890, 42.2289,  7.1534,  ...,  7.9356,  1.9466,  5.5769],\n",
            "        [17.7890, 42.2289,  7.1534,  ...,  7.9356,  1.9466,  5.5769],\n",
            "        [17.7890, 42.2289,  7.1534,  ...,  7.9356,  1.9466,  5.5769],\n",
            "        ...,\n",
            "        [17.7890, 42.2289,  7.1534,  ...,  7.9356,  1.9466,  5.5769],\n",
            "        [17.7890, 42.2289,  7.1534,  ...,  7.9356,  1.9466,  5.5769],\n",
            "        [17.7890, 42.2289,  7.1534,  ...,  7.9356,  1.9466,  5.5769]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 811, Loss: 60574.167969\n",
            "tensor([[17.8272, 42.3440,  7.1737,  ...,  7.9676,  1.9564,  5.5896],\n",
            "        [17.8272, 42.3440,  7.1737,  ...,  7.9676,  1.9564,  5.5896],\n",
            "        [17.8272, 42.3440,  7.1737,  ...,  7.9676,  1.9564,  5.5896],\n",
            "        ...,\n",
            "        [17.8272, 42.3440,  7.1737,  ...,  7.9676,  1.9564,  5.5896],\n",
            "        [17.8272, 42.3440,  7.1737,  ...,  7.9676,  1.9564,  5.5896],\n",
            "        [17.8272, 42.3440,  7.1737,  ...,  7.9676,  1.9564,  5.5896]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 812, Loss: 60556.757812\n",
            "tensor([[17.8654, 42.4592,  7.1940,  ...,  7.9995,  1.9663,  5.6023],\n",
            "        [17.8654, 42.4592,  7.1940,  ...,  7.9995,  1.9663,  5.6023],\n",
            "        [17.8654, 42.4592,  7.1940,  ...,  7.9995,  1.9663,  5.6023],\n",
            "        ...,\n",
            "        [17.8654, 42.4592,  7.1940,  ...,  7.9995,  1.9663,  5.6023],\n",
            "        [17.8654, 42.4592,  7.1940,  ...,  7.9995,  1.9663,  5.6023],\n",
            "        [17.8654, 42.4592,  7.1940,  ...,  7.9995,  1.9663,  5.6023]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 813, Loss: 60539.367188\n",
            "tensor([[17.9037, 42.5743,  7.2143,  ...,  8.0315,  1.9761,  5.6150],\n",
            "        [17.9037, 42.5743,  7.2143,  ...,  8.0315,  1.9761,  5.6150],\n",
            "        [17.9037, 42.5743,  7.2143,  ...,  8.0315,  1.9761,  5.6150],\n",
            "        ...,\n",
            "        [17.9037, 42.5743,  7.2143,  ...,  8.0315,  1.9761,  5.6150],\n",
            "        [17.9037, 42.5743,  7.2143,  ...,  8.0315,  1.9761,  5.6150],\n",
            "        [17.9037, 42.5743,  7.2143,  ...,  8.0315,  1.9761,  5.6150]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 814, Loss: 60521.972656\n",
            "tensor([[17.9419, 42.6894,  7.2346,  ...,  8.0634,  1.9860,  5.6276],\n",
            "        [17.9419, 42.6894,  7.2346,  ...,  8.0634,  1.9860,  5.6276],\n",
            "        [17.9419, 42.6894,  7.2346,  ...,  8.0634,  1.9860,  5.6276],\n",
            "        ...,\n",
            "        [17.9419, 42.6894,  7.2346,  ...,  8.0634,  1.9860,  5.6276],\n",
            "        [17.9419, 42.6894,  7.2346,  ...,  8.0634,  1.9860,  5.6276],\n",
            "        [17.9419, 42.6894,  7.2346,  ...,  8.0634,  1.9860,  5.6276]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 815, Loss: 60504.578125\n",
            "tensor([[17.9801, 42.8045,  7.2549,  ...,  8.0954,  1.9958,  5.6403],\n",
            "        [17.9801, 42.8045,  7.2549,  ...,  8.0954,  1.9958,  5.6403],\n",
            "        [17.9801, 42.8045,  7.2549,  ...,  8.0954,  1.9958,  5.6403],\n",
            "        ...,\n",
            "        [17.9801, 42.8045,  7.2549,  ...,  8.0954,  1.9958,  5.6403],\n",
            "        [17.9801, 42.8045,  7.2549,  ...,  8.0954,  1.9958,  5.6403],\n",
            "        [17.9801, 42.8045,  7.2549,  ...,  8.0954,  1.9958,  5.6403]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 816, Loss: 60487.199219\n",
            "tensor([[18.0183, 42.9196,  7.2752,  ...,  8.1273,  2.0056,  5.6530],\n",
            "        [18.0183, 42.9196,  7.2752,  ...,  8.1273,  2.0056,  5.6530],\n",
            "        [18.0183, 42.9196,  7.2752,  ...,  8.1273,  2.0056,  5.6530],\n",
            "        ...,\n",
            "        [18.0183, 42.9196,  7.2752,  ...,  8.1273,  2.0056,  5.6530],\n",
            "        [18.0183, 42.9196,  7.2752,  ...,  8.1273,  2.0056,  5.6530],\n",
            "        [18.0183, 42.9196,  7.2752,  ...,  8.1273,  2.0056,  5.6530]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 817, Loss: 60469.820312\n",
            "tensor([[18.0565, 43.0346,  7.2955,  ...,  8.1593,  2.0155,  5.6657],\n",
            "        [18.0565, 43.0346,  7.2955,  ...,  8.1593,  2.0155,  5.6657],\n",
            "        [18.0565, 43.0346,  7.2955,  ...,  8.1593,  2.0155,  5.6657],\n",
            "        ...,\n",
            "        [18.0565, 43.0346,  7.2955,  ...,  8.1593,  2.0155,  5.6657],\n",
            "        [18.0565, 43.0346,  7.2955,  ...,  8.1593,  2.0155,  5.6657],\n",
            "        [18.0565, 43.0346,  7.2955,  ...,  8.1593,  2.0155,  5.6657]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 818, Loss: 60452.464844\n",
            "tensor([[18.0947, 43.1497,  7.3158,  ...,  8.1912,  2.0253,  5.6784],\n",
            "        [18.0947, 43.1497,  7.3158,  ...,  8.1912,  2.0253,  5.6784],\n",
            "        [18.0947, 43.1497,  7.3158,  ...,  8.1912,  2.0253,  5.6784],\n",
            "        ...,\n",
            "        [18.0947, 43.1497,  7.3158,  ...,  8.1912,  2.0253,  5.6784],\n",
            "        [18.0947, 43.1497,  7.3158,  ...,  8.1912,  2.0253,  5.6784],\n",
            "        [18.0947, 43.1497,  7.3158,  ...,  8.1912,  2.0253,  5.6784]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 819, Loss: 60435.105469\n",
            "tensor([[18.1329, 43.2647,  7.3360,  ...,  8.2231,  2.0351,  5.6910],\n",
            "        [18.1329, 43.2647,  7.3360,  ...,  8.2231,  2.0351,  5.6910],\n",
            "        [18.1329, 43.2647,  7.3360,  ...,  8.2231,  2.0351,  5.6910],\n",
            "        ...,\n",
            "        [18.1329, 43.2647,  7.3360,  ...,  8.2231,  2.0351,  5.6910],\n",
            "        [18.1329, 43.2647,  7.3360,  ...,  8.2231,  2.0351,  5.6910],\n",
            "        [18.1329, 43.2647,  7.3360,  ...,  8.2231,  2.0351,  5.6910]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 820, Loss: 60417.753906\n",
            "tensor([[18.1710, 43.3796,  7.3563,  ...,  8.2550,  2.0449,  5.7037],\n",
            "        [18.1710, 43.3796,  7.3563,  ...,  8.2550,  2.0449,  5.7037],\n",
            "        [18.1710, 43.3796,  7.3563,  ...,  8.2550,  2.0449,  5.7037],\n",
            "        ...,\n",
            "        [18.1710, 43.3796,  7.3563,  ...,  8.2550,  2.0449,  5.7037],\n",
            "        [18.1710, 43.3796,  7.3563,  ...,  8.2550,  2.0449,  5.7037],\n",
            "        [18.1710, 43.3796,  7.3563,  ...,  8.2550,  2.0449,  5.7037]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 821, Loss: 60400.398438\n",
            "tensor([[18.2092, 43.4946,  7.3766,  ...,  8.2869,  2.0548,  5.7164],\n",
            "        [18.2092, 43.4946,  7.3766,  ...,  8.2869,  2.0548,  5.7164],\n",
            "        [18.2092, 43.4946,  7.3766,  ...,  8.2869,  2.0548,  5.7164],\n",
            "        ...,\n",
            "        [18.2092, 43.4946,  7.3766,  ...,  8.2869,  2.0548,  5.7164],\n",
            "        [18.2092, 43.4946,  7.3766,  ...,  8.2869,  2.0548,  5.7164],\n",
            "        [18.2092, 43.4946,  7.3766,  ...,  8.2869,  2.0548,  5.7164]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 822, Loss: 60383.062500\n",
            "tensor([[18.2474, 43.6095,  7.3968,  ...,  8.3188,  2.0646,  5.7290],\n",
            "        [18.2474, 43.6095,  7.3968,  ...,  8.3188,  2.0646,  5.7290],\n",
            "        [18.2474, 43.6095,  7.3968,  ...,  8.3188,  2.0646,  5.7290],\n",
            "        ...,\n",
            "        [18.2474, 43.6095,  7.3968,  ...,  8.3188,  2.0646,  5.7290],\n",
            "        [18.2474, 43.6095,  7.3968,  ...,  8.3188,  2.0646,  5.7290],\n",
            "        [18.2474, 43.6095,  7.3968,  ...,  8.3188,  2.0646,  5.7290]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 823, Loss: 60365.734375\n",
            "tensor([[18.2855, 43.7244,  7.4171,  ...,  8.3507,  2.0744,  5.7417],\n",
            "        [18.2855, 43.7244,  7.4171,  ...,  8.3507,  2.0744,  5.7417],\n",
            "        [18.2855, 43.7244,  7.4171,  ...,  8.3507,  2.0744,  5.7417],\n",
            "        ...,\n",
            "        [18.2855, 43.7244,  7.4171,  ...,  8.3507,  2.0744,  5.7417],\n",
            "        [18.2855, 43.7244,  7.4171,  ...,  8.3507,  2.0744,  5.7417],\n",
            "        [18.2855, 43.7244,  7.4171,  ...,  8.3507,  2.0744,  5.7417]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 824, Loss: 60348.406250\n",
            "tensor([[18.3237, 43.8393,  7.4373,  ...,  8.3826,  2.0842,  5.7543],\n",
            "        [18.3237, 43.8393,  7.4373,  ...,  8.3826,  2.0842,  5.7543],\n",
            "        [18.3237, 43.8393,  7.4373,  ...,  8.3826,  2.0842,  5.7543],\n",
            "        ...,\n",
            "        [18.3237, 43.8393,  7.4373,  ...,  8.3826,  2.0842,  5.7543],\n",
            "        [18.3237, 43.8393,  7.4373,  ...,  8.3826,  2.0842,  5.7543],\n",
            "        [18.3237, 43.8393,  7.4373,  ...,  8.3826,  2.0842,  5.7543]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 825, Loss: 60331.085938\n",
            "tensor([[18.3618, 43.9542,  7.4576,  ...,  8.4145,  2.0940,  5.7670],\n",
            "        [18.3618, 43.9542,  7.4576,  ...,  8.4145,  2.0940,  5.7670],\n",
            "        [18.3618, 43.9542,  7.4576,  ...,  8.4145,  2.0940,  5.7670],\n",
            "        ...,\n",
            "        [18.3618, 43.9542,  7.4576,  ...,  8.4145,  2.0940,  5.7670],\n",
            "        [18.3618, 43.9542,  7.4576,  ...,  8.4145,  2.0940,  5.7670],\n",
            "        [18.3618, 43.9542,  7.4576,  ...,  8.4145,  2.0940,  5.7670]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 826, Loss: 60313.777344\n",
            "tensor([[18.3999, 44.0690,  7.4778,  ...,  8.4463,  2.1038,  5.7796],\n",
            "        [18.3999, 44.0690,  7.4778,  ...,  8.4463,  2.1038,  5.7796],\n",
            "        [18.3999, 44.0690,  7.4778,  ...,  8.4463,  2.1038,  5.7796],\n",
            "        ...,\n",
            "        [18.3999, 44.0690,  7.4778,  ...,  8.4463,  2.1038,  5.7796],\n",
            "        [18.3999, 44.0690,  7.4778,  ...,  8.4463,  2.1038,  5.7796],\n",
            "        [18.3999, 44.0690,  7.4778,  ...,  8.4463,  2.1038,  5.7796]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 827, Loss: 60296.476562\n",
            "tensor([[18.4380, 44.1838,  7.4981,  ...,  8.4782,  2.1137,  5.7923],\n",
            "        [18.4380, 44.1838,  7.4981,  ...,  8.4782,  2.1137,  5.7923],\n",
            "        [18.4380, 44.1838,  7.4981,  ...,  8.4782,  2.1137,  5.7923],\n",
            "        ...,\n",
            "        [18.4380, 44.1838,  7.4981,  ...,  8.4782,  2.1137,  5.7923],\n",
            "        [18.4380, 44.1838,  7.4981,  ...,  8.4782,  2.1137,  5.7923],\n",
            "        [18.4380, 44.1838,  7.4981,  ...,  8.4782,  2.1137,  5.7923]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 828, Loss: 60279.179688\n",
            "tensor([[18.4762, 44.2986,  7.5183,  ...,  8.5100,  2.1235,  5.8049],\n",
            "        [18.4762, 44.2986,  7.5183,  ...,  8.5100,  2.1235,  5.8049],\n",
            "        [18.4762, 44.2986,  7.5183,  ...,  8.5100,  2.1235,  5.8049],\n",
            "        ...,\n",
            "        [18.4762, 44.2986,  7.5183,  ...,  8.5100,  2.1235,  5.8049],\n",
            "        [18.4762, 44.2986,  7.5183,  ...,  8.5100,  2.1235,  5.8049],\n",
            "        [18.4762, 44.2986,  7.5183,  ...,  8.5100,  2.1235,  5.8049]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 829, Loss: 60261.890625\n",
            "tensor([[18.5143, 44.4134,  7.5385,  ...,  8.5419,  2.1333,  5.8176],\n",
            "        [18.5143, 44.4134,  7.5385,  ...,  8.5419,  2.1333,  5.8176],\n",
            "        [18.5143, 44.4134,  7.5385,  ...,  8.5419,  2.1333,  5.8176],\n",
            "        ...,\n",
            "        [18.5143, 44.4134,  7.5385,  ...,  8.5419,  2.1333,  5.8176],\n",
            "        [18.5143, 44.4134,  7.5385,  ...,  8.5419,  2.1333,  5.8176],\n",
            "        [18.5143, 44.4134,  7.5385,  ...,  8.5419,  2.1333,  5.8176]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 830, Loss: 60244.605469\n",
            "tensor([[18.5524, 44.5281,  7.5588,  ...,  8.5737,  2.1431,  5.8302],\n",
            "        [18.5524, 44.5281,  7.5588,  ...,  8.5737,  2.1431,  5.8302],\n",
            "        [18.5524, 44.5281,  7.5588,  ...,  8.5737,  2.1431,  5.8302],\n",
            "        ...,\n",
            "        [18.5524, 44.5281,  7.5588,  ...,  8.5737,  2.1431,  5.8302],\n",
            "        [18.5524, 44.5281,  7.5588,  ...,  8.5737,  2.1431,  5.8302],\n",
            "        [18.5524, 44.5281,  7.5588,  ...,  8.5737,  2.1431,  5.8302]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 831, Loss: 60227.328125\n",
            "tensor([[18.5904, 44.6428,  7.5790,  ...,  8.6056,  2.1529,  5.8429],\n",
            "        [18.5904, 44.6428,  7.5790,  ...,  8.6056,  2.1529,  5.8429],\n",
            "        [18.5904, 44.6428,  7.5790,  ...,  8.6056,  2.1529,  5.8429],\n",
            "        ...,\n",
            "        [18.5904, 44.6428,  7.5790,  ...,  8.6056,  2.1529,  5.8429],\n",
            "        [18.5904, 44.6428,  7.5790,  ...,  8.6056,  2.1529,  5.8429],\n",
            "        [18.5904, 44.6428,  7.5790,  ...,  8.6056,  2.1529,  5.8429]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 832, Loss: 60210.062500\n",
            "tensor([[18.6285, 44.7575,  7.5992,  ...,  8.6374,  2.1627,  5.8555],\n",
            "        [18.6285, 44.7575,  7.5992,  ...,  8.6374,  2.1627,  5.8555],\n",
            "        [18.6285, 44.7575,  7.5992,  ...,  8.6374,  2.1627,  5.8555],\n",
            "        ...,\n",
            "        [18.6285, 44.7575,  7.5992,  ...,  8.6374,  2.1627,  5.8555],\n",
            "        [18.6285, 44.7575,  7.5992,  ...,  8.6374,  2.1627,  5.8555],\n",
            "        [18.6285, 44.7575,  7.5992,  ...,  8.6374,  2.1627,  5.8555]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 833, Loss: 60192.796875\n",
            "tensor([[18.6666, 44.8722,  7.6194,  ...,  8.6692,  2.1725,  5.8682],\n",
            "        [18.6666, 44.8722,  7.6194,  ...,  8.6692,  2.1725,  5.8682],\n",
            "        [18.6666, 44.8722,  7.6194,  ...,  8.6692,  2.1725,  5.8682],\n",
            "        ...,\n",
            "        [18.6666, 44.8722,  7.6194,  ...,  8.6692,  2.1725,  5.8682],\n",
            "        [18.6666, 44.8722,  7.6194,  ...,  8.6692,  2.1725,  5.8682],\n",
            "        [18.6666, 44.8722,  7.6194,  ...,  8.6692,  2.1725,  5.8682]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 834, Loss: 60175.542969\n",
            "tensor([[18.7047, 44.9869,  7.6397,  ...,  8.7011,  2.1823,  5.8808],\n",
            "        [18.7047, 44.9869,  7.6397,  ...,  8.7011,  2.1823,  5.8808],\n",
            "        [18.7047, 44.9869,  7.6397,  ...,  8.7011,  2.1823,  5.8808],\n",
            "        ...,\n",
            "        [18.7047, 44.9869,  7.6397,  ...,  8.7011,  2.1823,  5.8808],\n",
            "        [18.7047, 44.9869,  7.6397,  ...,  8.7011,  2.1823,  5.8808],\n",
            "        [18.7047, 44.9869,  7.6397,  ...,  8.7011,  2.1823,  5.8808]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 835, Loss: 60158.289062\n",
            "tensor([[18.7427, 45.1015,  7.6599,  ...,  8.7329,  2.1921,  5.8934],\n",
            "        [18.7427, 45.1015,  7.6599,  ...,  8.7329,  2.1921,  5.8934],\n",
            "        [18.7427, 45.1015,  7.6599,  ...,  8.7329,  2.1921,  5.8934],\n",
            "        ...,\n",
            "        [18.7427, 45.1015,  7.6599,  ...,  8.7329,  2.1921,  5.8934],\n",
            "        [18.7427, 45.1015,  7.6599,  ...,  8.7329,  2.1921,  5.8934],\n",
            "        [18.7427, 45.1015,  7.6599,  ...,  8.7329,  2.1921,  5.8934]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 836, Loss: 60141.046875\n",
            "tensor([[18.7808, 45.2161,  7.6801,  ...,  8.7647,  2.2019,  5.9060],\n",
            "        [18.7808, 45.2161,  7.6801,  ...,  8.7647,  2.2019,  5.9060],\n",
            "        [18.7808, 45.2161,  7.6801,  ...,  8.7647,  2.2019,  5.9060],\n",
            "        ...,\n",
            "        [18.7808, 45.2161,  7.6801,  ...,  8.7647,  2.2019,  5.9060],\n",
            "        [18.7808, 45.2161,  7.6801,  ...,  8.7647,  2.2019,  5.9060],\n",
            "        [18.7808, 45.2161,  7.6801,  ...,  8.7647,  2.2019,  5.9060]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 837, Loss: 60123.820312\n",
            "tensor([[18.8188, 45.3307,  7.7003,  ...,  8.7965,  2.2117,  5.9187],\n",
            "        [18.8188, 45.3307,  7.7003,  ...,  8.7965,  2.2117,  5.9187],\n",
            "        [18.8188, 45.3307,  7.7003,  ...,  8.7965,  2.2117,  5.9187],\n",
            "        ...,\n",
            "        [18.8188, 45.3307,  7.7003,  ...,  8.7965,  2.2117,  5.9187],\n",
            "        [18.8188, 45.3307,  7.7003,  ...,  8.7965,  2.2117,  5.9187],\n",
            "        [18.8188, 45.3307,  7.7003,  ...,  8.7965,  2.2117,  5.9187]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 838, Loss: 60106.585938\n",
            "tensor([[18.8569, 45.4453,  7.7205,  ...,  8.8283,  2.2215,  5.9313],\n",
            "        [18.8569, 45.4453,  7.7205,  ...,  8.8283,  2.2215,  5.9313],\n",
            "        [18.8569, 45.4453,  7.7205,  ...,  8.8283,  2.2215,  5.9313],\n",
            "        ...,\n",
            "        [18.8569, 45.4453,  7.7205,  ...,  8.8283,  2.2215,  5.9313],\n",
            "        [18.8569, 45.4453,  7.7205,  ...,  8.8283,  2.2215,  5.9313],\n",
            "        [18.8569, 45.4453,  7.7205,  ...,  8.8283,  2.2215,  5.9313]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 839, Loss: 60089.359375\n",
            "tensor([[18.8949, 45.5598,  7.7407,  ...,  8.8601,  2.2312,  5.9439],\n",
            "        [18.8949, 45.5598,  7.7407,  ...,  8.8601,  2.2312,  5.9439],\n",
            "        [18.8949, 45.5598,  7.7407,  ...,  8.8601,  2.2312,  5.9439],\n",
            "        ...,\n",
            "        [18.8949, 45.5598,  7.7407,  ...,  8.8601,  2.2312,  5.9439],\n",
            "        [18.8949, 45.5598,  7.7407,  ...,  8.8601,  2.2312,  5.9439],\n",
            "        [18.8949, 45.5598,  7.7407,  ...,  8.8601,  2.2312,  5.9439]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 840, Loss: 60072.152344\n",
            "tensor([[18.9329, 45.6743,  7.7608,  ...,  8.8919,  2.2410,  5.9565],\n",
            "        [18.9329, 45.6743,  7.7608,  ...,  8.8919,  2.2410,  5.9565],\n",
            "        [18.9329, 45.6743,  7.7608,  ...,  8.8919,  2.2410,  5.9565],\n",
            "        ...,\n",
            "        [18.9329, 45.6743,  7.7608,  ...,  8.8919,  2.2410,  5.9565],\n",
            "        [18.9329, 45.6743,  7.7608,  ...,  8.8919,  2.2410,  5.9565],\n",
            "        [18.9329, 45.6743,  7.7608,  ...,  8.8919,  2.2410,  5.9565]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 841, Loss: 60054.941406\n",
            "tensor([[18.9709, 45.7888,  7.7810,  ...,  8.9236,  2.2508,  5.9691],\n",
            "        [18.9709, 45.7888,  7.7810,  ...,  8.9236,  2.2508,  5.9691],\n",
            "        [18.9709, 45.7888,  7.7810,  ...,  8.9236,  2.2508,  5.9691],\n",
            "        ...,\n",
            "        [18.9709, 45.7888,  7.7810,  ...,  8.9236,  2.2508,  5.9691],\n",
            "        [18.9709, 45.7888,  7.7810,  ...,  8.9236,  2.2508,  5.9691],\n",
            "        [18.9709, 45.7888,  7.7810,  ...,  8.9236,  2.2508,  5.9691]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 842, Loss: 60037.742188\n",
            "tensor([[19.0089, 45.9033,  7.8012,  ...,  8.9554,  2.2606,  5.9818],\n",
            "        [19.0089, 45.9033,  7.8012,  ...,  8.9554,  2.2606,  5.9818],\n",
            "        [19.0089, 45.9033,  7.8012,  ...,  8.9554,  2.2606,  5.9818],\n",
            "        ...,\n",
            "        [19.0089, 45.9033,  7.8012,  ...,  8.9554,  2.2606,  5.9818],\n",
            "        [19.0089, 45.9033,  7.8012,  ...,  8.9554,  2.2606,  5.9818],\n",
            "        [19.0089, 45.9033,  7.8012,  ...,  8.9554,  2.2606,  5.9818]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 843, Loss: 60020.546875\n",
            "tensor([[19.0469, 46.0177,  7.8214,  ...,  8.9872,  2.2704,  5.9944],\n",
            "        [19.0469, 46.0177,  7.8214,  ...,  8.9872,  2.2704,  5.9944],\n",
            "        [19.0469, 46.0177,  7.8214,  ...,  8.9872,  2.2704,  5.9944],\n",
            "        ...,\n",
            "        [19.0469, 46.0177,  7.8214,  ...,  8.9872,  2.2704,  5.9944],\n",
            "        [19.0469, 46.0177,  7.8214,  ...,  8.9872,  2.2704,  5.9944],\n",
            "        [19.0469, 46.0177,  7.8214,  ...,  8.9872,  2.2704,  5.9944]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 844, Loss: 60003.367188\n",
            "tensor([[19.0849, 46.1322,  7.8416,  ...,  9.0189,  2.2802,  6.0070],\n",
            "        [19.0849, 46.1322,  7.8416,  ...,  9.0189,  2.2802,  6.0070],\n",
            "        [19.0849, 46.1322,  7.8416,  ...,  9.0189,  2.2802,  6.0070],\n",
            "        ...,\n",
            "        [19.0849, 46.1322,  7.8416,  ...,  9.0189,  2.2802,  6.0070],\n",
            "        [19.0849, 46.1322,  7.8416,  ...,  9.0189,  2.2802,  6.0070],\n",
            "        [19.0849, 46.1322,  7.8416,  ...,  9.0189,  2.2802,  6.0070]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 845, Loss: 59986.175781\n",
            "tensor([[19.1229, 46.2466,  7.8617,  ...,  9.0507,  2.2899,  6.0196],\n",
            "        [19.1229, 46.2466,  7.8617,  ...,  9.0507,  2.2899,  6.0196],\n",
            "        [19.1229, 46.2466,  7.8617,  ...,  9.0507,  2.2899,  6.0196],\n",
            "        ...,\n",
            "        [19.1229, 46.2466,  7.8617,  ...,  9.0507,  2.2899,  6.0196],\n",
            "        [19.1229, 46.2466,  7.8617,  ...,  9.0507,  2.2899,  6.0196],\n",
            "        [19.1229, 46.2466,  7.8617,  ...,  9.0507,  2.2899,  6.0196]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 846, Loss: 59969.011719\n",
            "tensor([[19.1609, 46.3610,  7.8819,  ...,  9.0824,  2.2997,  6.0322],\n",
            "        [19.1609, 46.3610,  7.8819,  ...,  9.0824,  2.2997,  6.0322],\n",
            "        [19.1609, 46.3610,  7.8819,  ...,  9.0824,  2.2997,  6.0322],\n",
            "        ...,\n",
            "        [19.1609, 46.3610,  7.8819,  ...,  9.0824,  2.2997,  6.0322],\n",
            "        [19.1609, 46.3610,  7.8819,  ...,  9.0824,  2.2997,  6.0322],\n",
            "        [19.1609, 46.3610,  7.8819,  ...,  9.0824,  2.2997,  6.0322]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 847, Loss: 59951.835938\n",
            "tensor([[19.1988, 46.4753,  7.9020,  ...,  9.1142,  2.3095,  6.0448],\n",
            "        [19.1988, 46.4753,  7.9020,  ...,  9.1142,  2.3095,  6.0448],\n",
            "        [19.1988, 46.4753,  7.9020,  ...,  9.1142,  2.3095,  6.0448],\n",
            "        ...,\n",
            "        [19.1988, 46.4753,  7.9020,  ...,  9.1142,  2.3095,  6.0448],\n",
            "        [19.1988, 46.4753,  7.9020,  ...,  9.1142,  2.3095,  6.0448],\n",
            "        [19.1988, 46.4753,  7.9020,  ...,  9.1142,  2.3095,  6.0448]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 848, Loss: 59934.691406\n",
            "tensor([[19.2368, 46.5896,  7.9222,  ...,  9.1459,  2.3192,  6.0574],\n",
            "        [19.2368, 46.5896,  7.9222,  ...,  9.1459,  2.3192,  6.0574],\n",
            "        [19.2368, 46.5896,  7.9222,  ...,  9.1459,  2.3192,  6.0574],\n",
            "        ...,\n",
            "        [19.2368, 46.5896,  7.9222,  ...,  9.1459,  2.3192,  6.0574],\n",
            "        [19.2368, 46.5896,  7.9222,  ...,  9.1459,  2.3192,  6.0574],\n",
            "        [19.2368, 46.5896,  7.9222,  ...,  9.1459,  2.3192,  6.0574]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 849, Loss: 59917.535156\n",
            "tensor([[19.2748, 46.7040,  7.9424,  ...,  9.1776,  2.3290,  6.0700],\n",
            "        [19.2748, 46.7040,  7.9424,  ...,  9.1776,  2.3290,  6.0700],\n",
            "        [19.2748, 46.7040,  7.9424,  ...,  9.1776,  2.3290,  6.0700],\n",
            "        ...,\n",
            "        [19.2748, 46.7040,  7.9424,  ...,  9.1776,  2.3290,  6.0700],\n",
            "        [19.2748, 46.7040,  7.9424,  ...,  9.1776,  2.3290,  6.0700],\n",
            "        [19.2748, 46.7040,  7.9424,  ...,  9.1776,  2.3290,  6.0700]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 850, Loss: 59900.382812\n",
            "tensor([[19.3127, 46.8182,  7.9625,  ...,  9.2093,  2.3388,  6.0826],\n",
            "        [19.3127, 46.8182,  7.9625,  ...,  9.2093,  2.3388,  6.0826],\n",
            "        [19.3127, 46.8182,  7.9625,  ...,  9.2093,  2.3388,  6.0826],\n",
            "        ...,\n",
            "        [19.3127, 46.8182,  7.9625,  ...,  9.2093,  2.3388,  6.0826],\n",
            "        [19.3127, 46.8182,  7.9625,  ...,  9.2093,  2.3388,  6.0826],\n",
            "        [19.3127, 46.8182,  7.9625,  ...,  9.2093,  2.3388,  6.0826]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 851, Loss: 59883.242188\n",
            "tensor([[19.3506, 46.9325,  7.9826,  ...,  9.2410,  2.3485,  6.0952],\n",
            "        [19.3506, 46.9325,  7.9826,  ...,  9.2410,  2.3485,  6.0952],\n",
            "        [19.3506, 46.9325,  7.9826,  ...,  9.2410,  2.3485,  6.0952],\n",
            "        ...,\n",
            "        [19.3506, 46.9325,  7.9826,  ...,  9.2410,  2.3485,  6.0952],\n",
            "        [19.3506, 46.9325,  7.9826,  ...,  9.2410,  2.3485,  6.0952],\n",
            "        [19.3506, 46.9325,  7.9826,  ...,  9.2410,  2.3485,  6.0952]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 852, Loss: 59866.113281\n",
            "tensor([[19.3886, 47.0467,  8.0028,  ...,  9.2728,  2.3583,  6.1077],\n",
            "        [19.3886, 47.0467,  8.0028,  ...,  9.2728,  2.3583,  6.1077],\n",
            "        [19.3886, 47.0467,  8.0028,  ...,  9.2728,  2.3583,  6.1077],\n",
            "        ...,\n",
            "        [19.3886, 47.0467,  8.0028,  ...,  9.2728,  2.3583,  6.1077],\n",
            "        [19.3886, 47.0467,  8.0028,  ...,  9.2728,  2.3583,  6.1077],\n",
            "        [19.3886, 47.0467,  8.0028,  ...,  9.2728,  2.3583,  6.1077]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 853, Loss: 59848.988281\n",
            "tensor([[19.4265, 47.1610,  8.0229,  ...,  9.3045,  2.3681,  6.1203],\n",
            "        [19.4265, 47.1610,  8.0229,  ...,  9.3045,  2.3681,  6.1203],\n",
            "        [19.4265, 47.1610,  8.0229,  ...,  9.3045,  2.3681,  6.1203],\n",
            "        ...,\n",
            "        [19.4265, 47.1610,  8.0229,  ...,  9.3045,  2.3681,  6.1203],\n",
            "        [19.4265, 47.1610,  8.0229,  ...,  9.3045,  2.3681,  6.1203],\n",
            "        [19.4265, 47.1610,  8.0229,  ...,  9.3045,  2.3681,  6.1203]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 854, Loss: 59831.863281\n",
            "tensor([[19.4644, 47.2752,  8.0431,  ...,  9.3361,  2.3778,  6.1329],\n",
            "        [19.4644, 47.2752,  8.0431,  ...,  9.3361,  2.3778,  6.1329],\n",
            "        [19.4644, 47.2752,  8.0431,  ...,  9.3361,  2.3778,  6.1329],\n",
            "        ...,\n",
            "        [19.4644, 47.2752,  8.0431,  ...,  9.3361,  2.3778,  6.1329],\n",
            "        [19.4644, 47.2752,  8.0431,  ...,  9.3361,  2.3778,  6.1329],\n",
            "        [19.4644, 47.2752,  8.0431,  ...,  9.3361,  2.3778,  6.1329]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 855, Loss: 59814.761719\n",
            "tensor([[19.5023, 47.3893,  8.0632,  ...,  9.3678,  2.3876,  6.1455],\n",
            "        [19.5023, 47.3893,  8.0632,  ...,  9.3678,  2.3876,  6.1455],\n",
            "        [19.5023, 47.3893,  8.0632,  ...,  9.3678,  2.3876,  6.1455],\n",
            "        ...,\n",
            "        [19.5023, 47.3893,  8.0632,  ...,  9.3678,  2.3876,  6.1455],\n",
            "        [19.5023, 47.3893,  8.0632,  ...,  9.3678,  2.3876,  6.1455],\n",
            "        [19.5023, 47.3893,  8.0632,  ...,  9.3678,  2.3876,  6.1455]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 856, Loss: 59797.652344\n",
            "tensor([[19.5402, 47.5035,  8.0833,  ...,  9.3995,  2.3973,  6.1581],\n",
            "        [19.5402, 47.5035,  8.0833,  ...,  9.3995,  2.3973,  6.1581],\n",
            "        [19.5402, 47.5035,  8.0833,  ...,  9.3995,  2.3973,  6.1581],\n",
            "        ...,\n",
            "        [19.5402, 47.5035,  8.0833,  ...,  9.3995,  2.3973,  6.1581],\n",
            "        [19.5402, 47.5035,  8.0833,  ...,  9.3995,  2.3973,  6.1581],\n",
            "        [19.5402, 47.5035,  8.0833,  ...,  9.3995,  2.3973,  6.1581]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 857, Loss: 59780.562500\n",
            "tensor([[19.5781, 47.6176,  8.1034,  ...,  9.4312,  2.4071,  6.1706],\n",
            "        [19.5781, 47.6176,  8.1034,  ...,  9.4312,  2.4071,  6.1706],\n",
            "        [19.5781, 47.6176,  8.1034,  ...,  9.4312,  2.4071,  6.1706],\n",
            "        ...,\n",
            "        [19.5781, 47.6176,  8.1034,  ...,  9.4312,  2.4071,  6.1706],\n",
            "        [19.5781, 47.6176,  8.1034,  ...,  9.4312,  2.4071,  6.1706],\n",
            "        [19.5781, 47.6176,  8.1034,  ...,  9.4312,  2.4071,  6.1706]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 858, Loss: 59763.460938\n",
            "tensor([[19.6160, 47.7317,  8.1235,  ...,  9.4629,  2.4168,  6.1832],\n",
            "        [19.6160, 47.7317,  8.1235,  ...,  9.4629,  2.4168,  6.1832],\n",
            "        [19.6160, 47.7317,  8.1235,  ...,  9.4629,  2.4168,  6.1832],\n",
            "        ...,\n",
            "        [19.6160, 47.7317,  8.1235,  ...,  9.4629,  2.4168,  6.1832],\n",
            "        [19.6160, 47.7317,  8.1235,  ...,  9.4629,  2.4168,  6.1832],\n",
            "        [19.6160, 47.7317,  8.1235,  ...,  9.4629,  2.4168,  6.1832]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 859, Loss: 59746.386719\n",
            "tensor([[19.6539, 47.8458,  8.1437,  ...,  9.4945,  2.4266,  6.1958],\n",
            "        [19.6539, 47.8458,  8.1437,  ...,  9.4945,  2.4266,  6.1958],\n",
            "        [19.6539, 47.8458,  8.1437,  ...,  9.4945,  2.4266,  6.1958],\n",
            "        ...,\n",
            "        [19.6539, 47.8458,  8.1437,  ...,  9.4945,  2.4266,  6.1958],\n",
            "        [19.6539, 47.8458,  8.1437,  ...,  9.4945,  2.4266,  6.1958],\n",
            "        [19.6539, 47.8458,  8.1437,  ...,  9.4945,  2.4266,  6.1958]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 860, Loss: 59729.300781\n",
            "tensor([[19.6917, 47.9599,  8.1638,  ...,  9.5262,  2.4363,  6.2084],\n",
            "        [19.6917, 47.9599,  8.1638,  ...,  9.5262,  2.4363,  6.2084],\n",
            "        [19.6917, 47.9599,  8.1638,  ...,  9.5262,  2.4363,  6.2084],\n",
            "        ...,\n",
            "        [19.6917, 47.9599,  8.1638,  ...,  9.5262,  2.4363,  6.2084],\n",
            "        [19.6917, 47.9599,  8.1638,  ...,  9.5262,  2.4363,  6.2084],\n",
            "        [19.6917, 47.9599,  8.1638,  ...,  9.5262,  2.4363,  6.2084]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 861, Loss: 59712.238281\n",
            "tensor([[19.7296, 48.0739,  8.1839,  ...,  9.5578,  2.4461,  6.2209],\n",
            "        [19.7296, 48.0739,  8.1839,  ...,  9.5578,  2.4461,  6.2209],\n",
            "        [19.7296, 48.0739,  8.1839,  ...,  9.5578,  2.4461,  6.2209],\n",
            "        ...,\n",
            "        [19.7296, 48.0739,  8.1839,  ...,  9.5578,  2.4461,  6.2209],\n",
            "        [19.7296, 48.0739,  8.1839,  ...,  9.5578,  2.4461,  6.2209],\n",
            "        [19.7296, 48.0739,  8.1839,  ...,  9.5578,  2.4461,  6.2209]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 862, Loss: 59695.175781\n",
            "tensor([[19.7674, 48.1879,  8.2040,  ...,  9.5895,  2.4558,  6.2335],\n",
            "        [19.7674, 48.1879,  8.2040,  ...,  9.5895,  2.4558,  6.2335],\n",
            "        [19.7674, 48.1879,  8.2040,  ...,  9.5895,  2.4558,  6.2335],\n",
            "        ...,\n",
            "        [19.7674, 48.1879,  8.2040,  ...,  9.5895,  2.4558,  6.2335],\n",
            "        [19.7674, 48.1879,  8.2040,  ...,  9.5895,  2.4558,  6.2335],\n",
            "        [19.7674, 48.1879,  8.2040,  ...,  9.5895,  2.4558,  6.2335]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 863, Loss: 59678.121094\n",
            "tensor([[19.8053, 48.3019,  8.2241,  ...,  9.6211,  2.4656,  6.2460],\n",
            "        [19.8053, 48.3019,  8.2241,  ...,  9.6211,  2.4656,  6.2460],\n",
            "        [19.8053, 48.3019,  8.2241,  ...,  9.6211,  2.4656,  6.2460],\n",
            "        ...,\n",
            "        [19.8053, 48.3019,  8.2241,  ...,  9.6211,  2.4656,  6.2460],\n",
            "        [19.8053, 48.3019,  8.2241,  ...,  9.6211,  2.4656,  6.2460],\n",
            "        [19.8053, 48.3019,  8.2241,  ...,  9.6211,  2.4656,  6.2460]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 864, Loss: 59661.058594\n",
            "tensor([[19.8431, 48.4159,  8.2442,  ...,  9.6527,  2.4753,  6.2586],\n",
            "        [19.8431, 48.4159,  8.2442,  ...,  9.6527,  2.4753,  6.2586],\n",
            "        [19.8431, 48.4159,  8.2442,  ...,  9.6527,  2.4753,  6.2586],\n",
            "        ...,\n",
            "        [19.8431, 48.4159,  8.2442,  ...,  9.6527,  2.4753,  6.2586],\n",
            "        [19.8431, 48.4159,  8.2442,  ...,  9.6527,  2.4753,  6.2586],\n",
            "        [19.8431, 48.4159,  8.2442,  ...,  9.6527,  2.4753,  6.2586]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 865, Loss: 59644.015625\n",
            "tensor([[19.8810, 48.5298,  8.2642,  ...,  9.6844,  2.4850,  6.2712],\n",
            "        [19.8810, 48.5298,  8.2642,  ...,  9.6844,  2.4850,  6.2712],\n",
            "        [19.8810, 48.5298,  8.2642,  ...,  9.6844,  2.4850,  6.2712],\n",
            "        ...,\n",
            "        [19.8810, 48.5298,  8.2642,  ...,  9.6844,  2.4850,  6.2712],\n",
            "        [19.8810, 48.5298,  8.2642,  ...,  9.6844,  2.4850,  6.2712],\n",
            "        [19.8810, 48.5298,  8.2642,  ...,  9.6844,  2.4850,  6.2712]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 866, Loss: 59626.984375\n",
            "tensor([[19.9188, 48.6437,  8.2843,  ...,  9.7160,  2.4948,  6.2837],\n",
            "        [19.9188, 48.6437,  8.2843,  ...,  9.7160,  2.4948,  6.2837],\n",
            "        [19.9188, 48.6437,  8.2843,  ...,  9.7160,  2.4948,  6.2837],\n",
            "        ...,\n",
            "        [19.9188, 48.6437,  8.2843,  ...,  9.7160,  2.4948,  6.2837],\n",
            "        [19.9188, 48.6437,  8.2843,  ...,  9.7160,  2.4948,  6.2837],\n",
            "        [19.9188, 48.6437,  8.2843,  ...,  9.7160,  2.4948,  6.2837]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 867, Loss: 59609.945312\n",
            "tensor([[19.9566, 48.7576,  8.3044,  ...,  9.7476,  2.5045,  6.2963],\n",
            "        [19.9566, 48.7576,  8.3044,  ...,  9.7476,  2.5045,  6.2963],\n",
            "        [19.9566, 48.7576,  8.3044,  ...,  9.7476,  2.5045,  6.2963],\n",
            "        ...,\n",
            "        [19.9566, 48.7576,  8.3044,  ...,  9.7476,  2.5045,  6.2963],\n",
            "        [19.9566, 48.7576,  8.3044,  ...,  9.7476,  2.5045,  6.2963],\n",
            "        [19.9566, 48.7576,  8.3044,  ...,  9.7476,  2.5045,  6.2963]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 868, Loss: 59592.929688\n",
            "tensor([[19.9944, 48.8715,  8.3245,  ...,  9.7792,  2.5142,  6.3088],\n",
            "        [19.9944, 48.8715,  8.3245,  ...,  9.7792,  2.5142,  6.3088],\n",
            "        [19.9944, 48.8715,  8.3245,  ...,  9.7792,  2.5142,  6.3088],\n",
            "        ...,\n",
            "        [19.9944, 48.8715,  8.3245,  ...,  9.7792,  2.5142,  6.3088],\n",
            "        [19.9944, 48.8715,  8.3245,  ...,  9.7792,  2.5142,  6.3088],\n",
            "        [19.9944, 48.8715,  8.3245,  ...,  9.7792,  2.5142,  6.3088]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 869, Loss: 59575.921875\n",
            "tensor([[20.0322, 48.9854,  8.3446,  ...,  9.8108,  2.5240,  6.3214],\n",
            "        [20.0322, 48.9854,  8.3446,  ...,  9.8108,  2.5240,  6.3214],\n",
            "        [20.0322, 48.9854,  8.3446,  ...,  9.8108,  2.5240,  6.3214],\n",
            "        ...,\n",
            "        [20.0322, 48.9854,  8.3446,  ...,  9.8108,  2.5240,  6.3214],\n",
            "        [20.0322, 48.9854,  8.3446,  ...,  9.8108,  2.5240,  6.3214],\n",
            "        [20.0322, 48.9854,  8.3446,  ...,  9.8108,  2.5240,  6.3214]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 870, Loss: 59558.906250\n",
            "tensor([[20.0700, 49.0992,  8.3646,  ...,  9.8424,  2.5337,  6.3339],\n",
            "        [20.0700, 49.0992,  8.3646,  ...,  9.8424,  2.5337,  6.3339],\n",
            "        [20.0700, 49.0992,  8.3646,  ...,  9.8424,  2.5337,  6.3339],\n",
            "        ...,\n",
            "        [20.0700, 49.0992,  8.3646,  ...,  9.8424,  2.5337,  6.3339],\n",
            "        [20.0700, 49.0992,  8.3646,  ...,  9.8424,  2.5337,  6.3339],\n",
            "        [20.0700, 49.0992,  8.3646,  ...,  9.8424,  2.5337,  6.3339]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 871, Loss: 59541.906250\n",
            "tensor([[20.1078, 49.2130,  8.3847,  ...,  9.8740,  2.5434,  6.3464],\n",
            "        [20.1078, 49.2130,  8.3847,  ...,  9.8740,  2.5434,  6.3464],\n",
            "        [20.1078, 49.2130,  8.3847,  ...,  9.8740,  2.5434,  6.3464],\n",
            "        ...,\n",
            "        [20.1078, 49.2130,  8.3847,  ...,  9.8740,  2.5434,  6.3464],\n",
            "        [20.1078, 49.2130,  8.3847,  ...,  9.8740,  2.5434,  6.3464],\n",
            "        [20.1078, 49.2130,  8.3847,  ...,  9.8740,  2.5434,  6.3464]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 872, Loss: 59524.917969\n",
            "tensor([[20.1456, 49.3268,  8.4047,  ...,  9.9055,  2.5532,  6.3590],\n",
            "        [20.1456, 49.3268,  8.4047,  ...,  9.9055,  2.5532,  6.3590],\n",
            "        [20.1456, 49.3268,  8.4047,  ...,  9.9055,  2.5532,  6.3590],\n",
            "        ...,\n",
            "        [20.1456, 49.3268,  8.4047,  ...,  9.9055,  2.5532,  6.3590],\n",
            "        [20.1456, 49.3268,  8.4047,  ...,  9.9055,  2.5532,  6.3590],\n",
            "        [20.1456, 49.3268,  8.4047,  ...,  9.9055,  2.5532,  6.3590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 873, Loss: 59507.925781\n",
            "tensor([[20.1833, 49.4406,  8.4248,  ...,  9.9371,  2.5629,  6.3715],\n",
            "        [20.1833, 49.4406,  8.4248,  ...,  9.9371,  2.5629,  6.3715],\n",
            "        [20.1833, 49.4406,  8.4248,  ...,  9.9371,  2.5629,  6.3715],\n",
            "        ...,\n",
            "        [20.1833, 49.4406,  8.4248,  ...,  9.9371,  2.5629,  6.3715],\n",
            "        [20.1833, 49.4406,  8.4248,  ...,  9.9371,  2.5629,  6.3715],\n",
            "        [20.1833, 49.4406,  8.4248,  ...,  9.9371,  2.5629,  6.3715]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 874, Loss: 59490.945312\n",
            "tensor([[20.2211, 49.5543,  8.4449,  ...,  9.9687,  2.5726,  6.3840],\n",
            "        [20.2211, 49.5543,  8.4449,  ...,  9.9687,  2.5726,  6.3840],\n",
            "        [20.2211, 49.5543,  8.4449,  ...,  9.9687,  2.5726,  6.3840],\n",
            "        ...,\n",
            "        [20.2211, 49.5543,  8.4449,  ...,  9.9687,  2.5726,  6.3840],\n",
            "        [20.2211, 49.5543,  8.4449,  ...,  9.9687,  2.5726,  6.3840],\n",
            "        [20.2211, 49.5543,  8.4449,  ...,  9.9687,  2.5726,  6.3840]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 875, Loss: 59473.960938\n",
            "tensor([[20.2589, 49.6680,  8.4649,  ..., 10.0002,  2.5823,  6.3966],\n",
            "        [20.2589, 49.6680,  8.4649,  ..., 10.0002,  2.5823,  6.3966],\n",
            "        [20.2589, 49.6680,  8.4649,  ..., 10.0002,  2.5823,  6.3966],\n",
            "        ...,\n",
            "        [20.2589, 49.6680,  8.4649,  ..., 10.0002,  2.5823,  6.3966],\n",
            "        [20.2589, 49.6680,  8.4649,  ..., 10.0002,  2.5823,  6.3966],\n",
            "        [20.2589, 49.6680,  8.4649,  ..., 10.0002,  2.5823,  6.3966]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 876, Loss: 59457.000000\n",
            "tensor([[20.2966, 49.7817,  8.4849,  ..., 10.0318,  2.5920,  6.4091],\n",
            "        [20.2966, 49.7817,  8.4849,  ..., 10.0318,  2.5920,  6.4091],\n",
            "        [20.2966, 49.7817,  8.4849,  ..., 10.0318,  2.5920,  6.4091],\n",
            "        ...,\n",
            "        [20.2966, 49.7817,  8.4849,  ..., 10.0318,  2.5920,  6.4091],\n",
            "        [20.2966, 49.7817,  8.4849,  ..., 10.0318,  2.5920,  6.4091],\n",
            "        [20.2966, 49.7817,  8.4849,  ..., 10.0318,  2.5920,  6.4091]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 877, Loss: 59440.039062\n",
            "tensor([[20.3343, 49.8954,  8.5050,  ..., 10.0634,  2.6017,  6.4216],\n",
            "        [20.3343, 49.8954,  8.5050,  ..., 10.0634,  2.6017,  6.4216],\n",
            "        [20.3343, 49.8954,  8.5050,  ..., 10.0634,  2.6017,  6.4216],\n",
            "        ...,\n",
            "        [20.3343, 49.8954,  8.5050,  ..., 10.0634,  2.6017,  6.4216],\n",
            "        [20.3343, 49.8954,  8.5050,  ..., 10.0634,  2.6017,  6.4216],\n",
            "        [20.3343, 49.8954,  8.5050,  ..., 10.0634,  2.6017,  6.4216]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 878, Loss: 59423.082031\n",
            "tensor([[20.3721, 50.0090,  8.5250,  ..., 10.0949,  2.6115,  6.4341],\n",
            "        [20.3721, 50.0090,  8.5250,  ..., 10.0949,  2.6115,  6.4341],\n",
            "        [20.3721, 50.0090,  8.5250,  ..., 10.0949,  2.6115,  6.4341],\n",
            "        ...,\n",
            "        [20.3721, 50.0090,  8.5250,  ..., 10.0949,  2.6115,  6.4341],\n",
            "        [20.3721, 50.0090,  8.5250,  ..., 10.0949,  2.6115,  6.4341],\n",
            "        [20.3721, 50.0090,  8.5250,  ..., 10.0949,  2.6115,  6.4341]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 879, Loss: 59406.136719\n",
            "tensor([[20.4098, 50.1226,  8.5451,  ..., 10.1264,  2.6212,  6.4467],\n",
            "        [20.4098, 50.1226,  8.5451,  ..., 10.1264,  2.6212,  6.4467],\n",
            "        [20.4098, 50.1226,  8.5451,  ..., 10.1264,  2.6212,  6.4467],\n",
            "        ...,\n",
            "        [20.4098, 50.1226,  8.5451,  ..., 10.1264,  2.6212,  6.4467],\n",
            "        [20.4098, 50.1226,  8.5451,  ..., 10.1264,  2.6212,  6.4467],\n",
            "        [20.4098, 50.1226,  8.5451,  ..., 10.1264,  2.6212,  6.4467]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 880, Loss: 59389.195312\n",
            "tensor([[20.4475, 50.2363,  8.5651,  ..., 10.1580,  2.6309,  6.4592],\n",
            "        [20.4475, 50.2363,  8.5651,  ..., 10.1580,  2.6309,  6.4592],\n",
            "        [20.4475, 50.2363,  8.5651,  ..., 10.1580,  2.6309,  6.4592],\n",
            "        ...,\n",
            "        [20.4475, 50.2363,  8.5651,  ..., 10.1580,  2.6309,  6.4592],\n",
            "        [20.4475, 50.2363,  8.5651,  ..., 10.1580,  2.6309,  6.4592],\n",
            "        [20.4475, 50.2363,  8.5651,  ..., 10.1580,  2.6309,  6.4592]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 881, Loss: 59372.257812\n",
            "tensor([[20.4852, 50.3498,  8.5851,  ..., 10.1895,  2.6406,  6.4717],\n",
            "        [20.4852, 50.3498,  8.5851,  ..., 10.1895,  2.6406,  6.4717],\n",
            "        [20.4852, 50.3498,  8.5851,  ..., 10.1895,  2.6406,  6.4717],\n",
            "        ...,\n",
            "        [20.4852, 50.3498,  8.5851,  ..., 10.1895,  2.6406,  6.4717],\n",
            "        [20.4852, 50.3498,  8.5851,  ..., 10.1895,  2.6406,  6.4717],\n",
            "        [20.4852, 50.3498,  8.5851,  ..., 10.1895,  2.6406,  6.4717]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 882, Loss: 59355.332031\n",
            "tensor([[20.5229, 50.4634,  8.6051,  ..., 10.2210,  2.6503,  6.4842],\n",
            "        [20.5229, 50.4634,  8.6051,  ..., 10.2210,  2.6503,  6.4842],\n",
            "        [20.5229, 50.4634,  8.6051,  ..., 10.2210,  2.6503,  6.4842],\n",
            "        ...,\n",
            "        [20.5229, 50.4634,  8.6051,  ..., 10.2210,  2.6503,  6.4842],\n",
            "        [20.5229, 50.4634,  8.6051,  ..., 10.2210,  2.6503,  6.4842],\n",
            "        [20.5229, 50.4634,  8.6051,  ..., 10.2210,  2.6503,  6.4842]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 883, Loss: 59338.410156\n",
            "tensor([[20.5606, 50.5769,  8.6251,  ..., 10.2525,  2.6600,  6.4967],\n",
            "        [20.5606, 50.5769,  8.6251,  ..., 10.2525,  2.6600,  6.4967],\n",
            "        [20.5606, 50.5769,  8.6251,  ..., 10.2525,  2.6600,  6.4967],\n",
            "        ...,\n",
            "        [20.5606, 50.5769,  8.6251,  ..., 10.2525,  2.6600,  6.4967],\n",
            "        [20.5606, 50.5769,  8.6251,  ..., 10.2525,  2.6600,  6.4967],\n",
            "        [20.5606, 50.5769,  8.6251,  ..., 10.2525,  2.6600,  6.4967]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 884, Loss: 59321.500000\n",
            "tensor([[20.5983, 50.6904,  8.6451,  ..., 10.2840,  2.6697,  6.5092],\n",
            "        [20.5983, 50.6904,  8.6451,  ..., 10.2840,  2.6697,  6.5092],\n",
            "        [20.5983, 50.6904,  8.6451,  ..., 10.2840,  2.6697,  6.5092],\n",
            "        ...,\n",
            "        [20.5983, 50.6904,  8.6451,  ..., 10.2840,  2.6697,  6.5092],\n",
            "        [20.5983, 50.6904,  8.6451,  ..., 10.2840,  2.6697,  6.5092],\n",
            "        [20.5983, 50.6904,  8.6451,  ..., 10.2840,  2.6697,  6.5092]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 885, Loss: 59304.593750\n",
            "tensor([[20.6360, 50.8039,  8.6652,  ..., 10.3155,  2.6794,  6.5217],\n",
            "        [20.6360, 50.8039,  8.6652,  ..., 10.3155,  2.6794,  6.5217],\n",
            "        [20.6360, 50.8039,  8.6652,  ..., 10.3155,  2.6794,  6.5217],\n",
            "        ...,\n",
            "        [20.6360, 50.8039,  8.6652,  ..., 10.3155,  2.6794,  6.5217],\n",
            "        [20.6360, 50.8039,  8.6652,  ..., 10.3155,  2.6794,  6.5217],\n",
            "        [20.6360, 50.8039,  8.6652,  ..., 10.3155,  2.6794,  6.5217]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 886, Loss: 59287.687500\n",
            "tensor([[20.6737, 50.9174,  8.6852,  ..., 10.3470,  2.6891,  6.5342],\n",
            "        [20.6737, 50.9174,  8.6852,  ..., 10.3470,  2.6891,  6.5342],\n",
            "        [20.6737, 50.9174,  8.6852,  ..., 10.3470,  2.6891,  6.5342],\n",
            "        ...,\n",
            "        [20.6737, 50.9174,  8.6852,  ..., 10.3470,  2.6891,  6.5342],\n",
            "        [20.6737, 50.9174,  8.6852,  ..., 10.3470,  2.6891,  6.5342],\n",
            "        [20.6737, 50.9174,  8.6852,  ..., 10.3470,  2.6891,  6.5342]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 887, Loss: 59270.792969\n",
            "tensor([[20.7113, 51.0308,  8.7052,  ..., 10.3785,  2.6988,  6.5467],\n",
            "        [20.7113, 51.0308,  8.7052,  ..., 10.3785,  2.6988,  6.5467],\n",
            "        [20.7113, 51.0308,  8.7052,  ..., 10.3785,  2.6988,  6.5467],\n",
            "        ...,\n",
            "        [20.7113, 51.0308,  8.7052,  ..., 10.3785,  2.6988,  6.5467],\n",
            "        [20.7113, 51.0308,  8.7052,  ..., 10.3785,  2.6988,  6.5467],\n",
            "        [20.7113, 51.0308,  8.7052,  ..., 10.3785,  2.6988,  6.5467]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 888, Loss: 59253.910156\n",
            "tensor([[20.7490, 51.1443,  8.7252,  ..., 10.4100,  2.7085,  6.5592],\n",
            "        [20.7490, 51.1443,  8.7252,  ..., 10.4100,  2.7085,  6.5592],\n",
            "        [20.7490, 51.1443,  8.7252,  ..., 10.4100,  2.7085,  6.5592],\n",
            "        ...,\n",
            "        [20.7490, 51.1443,  8.7252,  ..., 10.4100,  2.7085,  6.5592],\n",
            "        [20.7490, 51.1443,  8.7252,  ..., 10.4100,  2.7085,  6.5592],\n",
            "        [20.7490, 51.1443,  8.7252,  ..., 10.4100,  2.7085,  6.5592]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 889, Loss: 59237.027344\n",
            "tensor([[20.7866, 51.2577,  8.7451,  ..., 10.4414,  2.7182,  6.5717],\n",
            "        [20.7866, 51.2577,  8.7451,  ..., 10.4414,  2.7182,  6.5717],\n",
            "        [20.7866, 51.2577,  8.7451,  ..., 10.4414,  2.7182,  6.5717],\n",
            "        ...,\n",
            "        [20.7866, 51.2577,  8.7451,  ..., 10.4414,  2.7182,  6.5717],\n",
            "        [20.7866, 51.2577,  8.7451,  ..., 10.4414,  2.7182,  6.5717],\n",
            "        [20.7866, 51.2577,  8.7451,  ..., 10.4414,  2.7182,  6.5717]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 890, Loss: 59220.152344\n",
            "tensor([[20.8243, 51.3710,  8.7651,  ..., 10.4729,  2.7278,  6.5842],\n",
            "        [20.8243, 51.3710,  8.7651,  ..., 10.4729,  2.7278,  6.5842],\n",
            "        [20.8243, 51.3710,  8.7651,  ..., 10.4729,  2.7278,  6.5842],\n",
            "        ...,\n",
            "        [20.8243, 51.3710,  8.7651,  ..., 10.4729,  2.7278,  6.5842],\n",
            "        [20.8243, 51.3710,  8.7651,  ..., 10.4729,  2.7278,  6.5842],\n",
            "        [20.8243, 51.3710,  8.7651,  ..., 10.4729,  2.7278,  6.5842]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 891, Loss: 59203.289062\n",
            "tensor([[20.8619, 51.4844,  8.7851,  ..., 10.5044,  2.7375,  6.5967],\n",
            "        [20.8619, 51.4844,  8.7851,  ..., 10.5044,  2.7375,  6.5967],\n",
            "        [20.8619, 51.4844,  8.7851,  ..., 10.5044,  2.7375,  6.5967],\n",
            "        ...,\n",
            "        [20.8619, 51.4844,  8.7851,  ..., 10.5044,  2.7375,  6.5967],\n",
            "        [20.8619, 51.4844,  8.7851,  ..., 10.5044,  2.7375,  6.5967],\n",
            "        [20.8619, 51.4844,  8.7851,  ..., 10.5044,  2.7375,  6.5967]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 892, Loss: 59186.433594\n",
            "tensor([[20.8995, 51.5977,  8.8051,  ..., 10.5358,  2.7472,  6.6092],\n",
            "        [20.8995, 51.5977,  8.8051,  ..., 10.5358,  2.7472,  6.6092],\n",
            "        [20.8995, 51.5977,  8.8051,  ..., 10.5358,  2.7472,  6.6092],\n",
            "        ...,\n",
            "        [20.8995, 51.5977,  8.8051,  ..., 10.5358,  2.7472,  6.6092],\n",
            "        [20.8995, 51.5977,  8.8051,  ..., 10.5358,  2.7472,  6.6092],\n",
            "        [20.8995, 51.5977,  8.8051,  ..., 10.5358,  2.7472,  6.6092]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 893, Loss: 59169.574219\n",
            "tensor([[20.9372, 51.7110,  8.8251,  ..., 10.5673,  2.7569,  6.6217],\n",
            "        [20.9372, 51.7110,  8.8251,  ..., 10.5673,  2.7569,  6.6217],\n",
            "        [20.9372, 51.7110,  8.8251,  ..., 10.5673,  2.7569,  6.6217],\n",
            "        ...,\n",
            "        [20.9372, 51.7110,  8.8251,  ..., 10.5673,  2.7569,  6.6217],\n",
            "        [20.9372, 51.7110,  8.8251,  ..., 10.5673,  2.7569,  6.6217],\n",
            "        [20.9372, 51.7110,  8.8251,  ..., 10.5673,  2.7569,  6.6217]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 894, Loss: 59152.734375\n",
            "tensor([[20.9748, 51.8243,  8.8450,  ..., 10.5987,  2.7666,  6.6342],\n",
            "        [20.9748, 51.8243,  8.8450,  ..., 10.5987,  2.7666,  6.6342],\n",
            "        [20.9748, 51.8243,  8.8450,  ..., 10.5987,  2.7666,  6.6342],\n",
            "        ...,\n",
            "        [20.9748, 51.8243,  8.8450,  ..., 10.5987,  2.7666,  6.6342],\n",
            "        [20.9748, 51.8243,  8.8450,  ..., 10.5987,  2.7666,  6.6342],\n",
            "        [20.9748, 51.8243,  8.8450,  ..., 10.5987,  2.7666,  6.6342]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 895, Loss: 59135.886719\n",
            "tensor([[21.0124, 51.9376,  8.8650,  ..., 10.6301,  2.7763,  6.6466],\n",
            "        [21.0124, 51.9376,  8.8650,  ..., 10.6301,  2.7763,  6.6466],\n",
            "        [21.0124, 51.9376,  8.8650,  ..., 10.6301,  2.7763,  6.6466],\n",
            "        ...,\n",
            "        [21.0124, 51.9376,  8.8650,  ..., 10.6301,  2.7763,  6.6466],\n",
            "        [21.0124, 51.9376,  8.8650,  ..., 10.6301,  2.7763,  6.6466],\n",
            "        [21.0124, 51.9376,  8.8650,  ..., 10.6301,  2.7763,  6.6466]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 896, Loss: 59119.058594\n",
            "tensor([[21.0500, 52.0508,  8.8850,  ..., 10.6616,  2.7859,  6.6591],\n",
            "        [21.0500, 52.0508,  8.8850,  ..., 10.6616,  2.7859,  6.6591],\n",
            "        [21.0500, 52.0508,  8.8850,  ..., 10.6616,  2.7859,  6.6591],\n",
            "        ...,\n",
            "        [21.0500, 52.0508,  8.8850,  ..., 10.6616,  2.7859,  6.6591],\n",
            "        [21.0500, 52.0508,  8.8850,  ..., 10.6616,  2.7859,  6.6591],\n",
            "        [21.0500, 52.0508,  8.8850,  ..., 10.6616,  2.7859,  6.6591]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 897, Loss: 59102.230469\n",
            "tensor([[21.0876, 52.1640,  8.9049,  ..., 10.6930,  2.7956,  6.6716],\n",
            "        [21.0876, 52.1640,  8.9049,  ..., 10.6930,  2.7956,  6.6716],\n",
            "        [21.0876, 52.1640,  8.9049,  ..., 10.6930,  2.7956,  6.6716],\n",
            "        ...,\n",
            "        [21.0876, 52.1640,  8.9049,  ..., 10.6930,  2.7956,  6.6716],\n",
            "        [21.0876, 52.1640,  8.9049,  ..., 10.6930,  2.7956,  6.6716],\n",
            "        [21.0876, 52.1640,  8.9049,  ..., 10.6930,  2.7956,  6.6716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 898, Loss: 59085.414062\n",
            "tensor([[21.1252, 52.2772,  8.9249,  ..., 10.7244,  2.8053,  6.6841],\n",
            "        [21.1252, 52.2772,  8.9249,  ..., 10.7244,  2.8053,  6.6841],\n",
            "        [21.1252, 52.2772,  8.9249,  ..., 10.7244,  2.8053,  6.6841],\n",
            "        ...,\n",
            "        [21.1252, 52.2772,  8.9249,  ..., 10.7244,  2.8053,  6.6841],\n",
            "        [21.1252, 52.2772,  8.9249,  ..., 10.7244,  2.8053,  6.6841],\n",
            "        [21.1252, 52.2772,  8.9249,  ..., 10.7244,  2.8053,  6.6841]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 899, Loss: 59068.601562\n",
            "tensor([[21.1627, 52.3904,  8.9448,  ..., 10.7558,  2.8150,  6.6965],\n",
            "        [21.1627, 52.3904,  8.9448,  ..., 10.7558,  2.8150,  6.6965],\n",
            "        [21.1627, 52.3904,  8.9448,  ..., 10.7558,  2.8150,  6.6965],\n",
            "        ...,\n",
            "        [21.1627, 52.3904,  8.9448,  ..., 10.7558,  2.8150,  6.6965],\n",
            "        [21.1627, 52.3904,  8.9448,  ..., 10.7558,  2.8150,  6.6965],\n",
            "        [21.1627, 52.3904,  8.9448,  ..., 10.7558,  2.8150,  6.6965]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 900, Loss: 59051.792969\n",
            "tensor([[21.2003, 52.5036,  8.9648,  ..., 10.7872,  2.8246,  6.7090],\n",
            "        [21.2003, 52.5036,  8.9648,  ..., 10.7872,  2.8246,  6.7090],\n",
            "        [21.2003, 52.5036,  8.9648,  ..., 10.7872,  2.8246,  6.7090],\n",
            "        ...,\n",
            "        [21.2003, 52.5036,  8.9648,  ..., 10.7872,  2.8246,  6.7090],\n",
            "        [21.2003, 52.5036,  8.9648,  ..., 10.7872,  2.8246,  6.7090],\n",
            "        [21.2003, 52.5036,  8.9648,  ..., 10.7872,  2.8246,  6.7090]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 901, Loss: 59034.992188\n",
            "tensor([[21.2379, 52.6167,  8.9847,  ..., 10.8186,  2.8343,  6.7215],\n",
            "        [21.2379, 52.6167,  8.9847,  ..., 10.8186,  2.8343,  6.7215],\n",
            "        [21.2379, 52.6167,  8.9847,  ..., 10.8186,  2.8343,  6.7215],\n",
            "        ...,\n",
            "        [21.2379, 52.6167,  8.9847,  ..., 10.8186,  2.8343,  6.7215],\n",
            "        [21.2379, 52.6167,  8.9847,  ..., 10.8186,  2.8343,  6.7215],\n",
            "        [21.2379, 52.6167,  8.9847,  ..., 10.8186,  2.8343,  6.7215]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 902, Loss: 59018.203125\n",
            "tensor([[21.2754, 52.7298,  9.0047,  ..., 10.8500,  2.8440,  6.7339],\n",
            "        [21.2754, 52.7298,  9.0047,  ..., 10.8500,  2.8440,  6.7339],\n",
            "        [21.2754, 52.7298,  9.0047,  ..., 10.8500,  2.8440,  6.7339],\n",
            "        ...,\n",
            "        [21.2754, 52.7298,  9.0047,  ..., 10.8500,  2.8440,  6.7339],\n",
            "        [21.2754, 52.7298,  9.0047,  ..., 10.8500,  2.8440,  6.7339],\n",
            "        [21.2754, 52.7298,  9.0047,  ..., 10.8500,  2.8440,  6.7339]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 903, Loss: 59001.410156\n",
            "tensor([[21.3129, 52.8429,  9.0246,  ..., 10.8814,  2.8536,  6.7464],\n",
            "        [21.3129, 52.8429,  9.0246,  ..., 10.8814,  2.8536,  6.7464],\n",
            "        [21.3129, 52.8429,  9.0246,  ..., 10.8814,  2.8536,  6.7464],\n",
            "        ...,\n",
            "        [21.3129, 52.8429,  9.0246,  ..., 10.8814,  2.8536,  6.7464],\n",
            "        [21.3129, 52.8429,  9.0246,  ..., 10.8814,  2.8536,  6.7464],\n",
            "        [21.3129, 52.8429,  9.0246,  ..., 10.8814,  2.8536,  6.7464]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 904, Loss: 58984.640625\n",
            "tensor([[21.3505, 52.9559,  9.0445,  ..., 10.9128,  2.8633,  6.7589],\n",
            "        [21.3505, 52.9559,  9.0445,  ..., 10.9128,  2.8633,  6.7589],\n",
            "        [21.3505, 52.9559,  9.0445,  ..., 10.9128,  2.8633,  6.7589],\n",
            "        ...,\n",
            "        [21.3505, 52.9559,  9.0445,  ..., 10.9128,  2.8633,  6.7589],\n",
            "        [21.3505, 52.9559,  9.0445,  ..., 10.9128,  2.8633,  6.7589],\n",
            "        [21.3505, 52.9559,  9.0445,  ..., 10.9128,  2.8633,  6.7589]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 905, Loss: 58967.863281\n",
            "tensor([[21.3880, 53.0690,  9.0645,  ..., 10.9441,  2.8729,  6.7713],\n",
            "        [21.3880, 53.0690,  9.0645,  ..., 10.9441,  2.8729,  6.7713],\n",
            "        [21.3880, 53.0690,  9.0645,  ..., 10.9441,  2.8729,  6.7713],\n",
            "        ...,\n",
            "        [21.3880, 53.0690,  9.0645,  ..., 10.9441,  2.8729,  6.7713],\n",
            "        [21.3880, 53.0690,  9.0645,  ..., 10.9441,  2.8729,  6.7713],\n",
            "        [21.3880, 53.0690,  9.0645,  ..., 10.9441,  2.8729,  6.7713]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 906, Loss: 58951.105469\n",
            "tensor([[21.4255, 53.1820,  9.0844,  ..., 10.9755,  2.8826,  6.7838],\n",
            "        [21.4255, 53.1820,  9.0844,  ..., 10.9755,  2.8826,  6.7838],\n",
            "        [21.4255, 53.1820,  9.0844,  ..., 10.9755,  2.8826,  6.7838],\n",
            "        ...,\n",
            "        [21.4255, 53.1820,  9.0844,  ..., 10.9755,  2.8826,  6.7838],\n",
            "        [21.4255, 53.1820,  9.0844,  ..., 10.9755,  2.8826,  6.7838],\n",
            "        [21.4255, 53.1820,  9.0844,  ..., 10.9755,  2.8826,  6.7838]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 907, Loss: 58934.339844\n",
            "tensor([[21.4630, 53.2950,  9.1043,  ..., 11.0069,  2.8923,  6.7962],\n",
            "        [21.4630, 53.2950,  9.1043,  ..., 11.0069,  2.8923,  6.7962],\n",
            "        [21.4630, 53.2950,  9.1043,  ..., 11.0069,  2.8923,  6.7962],\n",
            "        ...,\n",
            "        [21.4630, 53.2950,  9.1043,  ..., 11.0069,  2.8923,  6.7962],\n",
            "        [21.4630, 53.2950,  9.1043,  ..., 11.0069,  2.8923,  6.7962],\n",
            "        [21.4630, 53.2950,  9.1043,  ..., 11.0069,  2.8923,  6.7962]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 908, Loss: 58917.582031\n",
            "tensor([[21.5006, 53.4080,  9.1242,  ..., 11.0382,  2.9019,  6.8087],\n",
            "        [21.5006, 53.4080,  9.1242,  ..., 11.0382,  2.9019,  6.8087],\n",
            "        [21.5006, 53.4080,  9.1242,  ..., 11.0382,  2.9019,  6.8087],\n",
            "        ...,\n",
            "        [21.5006, 53.4080,  9.1242,  ..., 11.0382,  2.9019,  6.8087],\n",
            "        [21.5006, 53.4080,  9.1242,  ..., 11.0382,  2.9019,  6.8087],\n",
            "        [21.5006, 53.4080,  9.1242,  ..., 11.0382,  2.9019,  6.8087]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 909, Loss: 58900.843750\n",
            "tensor([[21.5381, 53.5209,  9.1441,  ..., 11.0696,  2.9116,  6.8211],\n",
            "        [21.5381, 53.5209,  9.1441,  ..., 11.0696,  2.9116,  6.8211],\n",
            "        [21.5381, 53.5209,  9.1441,  ..., 11.0696,  2.9116,  6.8211],\n",
            "        ...,\n",
            "        [21.5381, 53.5209,  9.1441,  ..., 11.0696,  2.9116,  6.8211],\n",
            "        [21.5381, 53.5209,  9.1441,  ..., 11.0696,  2.9116,  6.8211],\n",
            "        [21.5381, 53.5209,  9.1441,  ..., 11.0696,  2.9116,  6.8211]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 910, Loss: 58884.105469\n",
            "tensor([[21.5755, 53.6338,  9.1640,  ..., 11.1009,  2.9212,  6.8335],\n",
            "        [21.5755, 53.6338,  9.1640,  ..., 11.1009,  2.9212,  6.8335],\n",
            "        [21.5755, 53.6338,  9.1640,  ..., 11.1009,  2.9212,  6.8335],\n",
            "        ...,\n",
            "        [21.5755, 53.6338,  9.1640,  ..., 11.1009,  2.9212,  6.8335],\n",
            "        [21.5755, 53.6338,  9.1640,  ..., 11.1009,  2.9212,  6.8335],\n",
            "        [21.5755, 53.6338,  9.1640,  ..., 11.1009,  2.9212,  6.8335]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 911, Loss: 58867.367188\n",
            "tensor([[21.6130, 53.7467,  9.1840,  ..., 11.1322,  2.9309,  6.8460],\n",
            "        [21.6130, 53.7467,  9.1840,  ..., 11.1322,  2.9309,  6.8460],\n",
            "        [21.6130, 53.7467,  9.1840,  ..., 11.1322,  2.9309,  6.8460],\n",
            "        ...,\n",
            "        [21.6130, 53.7467,  9.1840,  ..., 11.1322,  2.9309,  6.8460],\n",
            "        [21.6130, 53.7467,  9.1840,  ..., 11.1322,  2.9309,  6.8460],\n",
            "        [21.6130, 53.7467,  9.1840,  ..., 11.1322,  2.9309,  6.8460]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 912, Loss: 58850.648438\n",
            "tensor([[21.6505, 53.8596,  9.2038,  ..., 11.1636,  2.9405,  6.8584],\n",
            "        [21.6505, 53.8596,  9.2038,  ..., 11.1636,  2.9405,  6.8584],\n",
            "        [21.6505, 53.8596,  9.2038,  ..., 11.1636,  2.9405,  6.8584],\n",
            "        ...,\n",
            "        [21.6505, 53.8596,  9.2038,  ..., 11.1636,  2.9405,  6.8584],\n",
            "        [21.6505, 53.8596,  9.2038,  ..., 11.1636,  2.9405,  6.8584],\n",
            "        [21.6505, 53.8596,  9.2038,  ..., 11.1636,  2.9405,  6.8584]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 913, Loss: 58833.921875\n",
            "tensor([[21.6880, 53.9725,  9.2237,  ..., 11.1949,  2.9502,  6.8709],\n",
            "        [21.6880, 53.9725,  9.2237,  ..., 11.1949,  2.9502,  6.8709],\n",
            "        [21.6880, 53.9725,  9.2237,  ..., 11.1949,  2.9502,  6.8709],\n",
            "        ...,\n",
            "        [21.6880, 53.9725,  9.2237,  ..., 11.1949,  2.9502,  6.8709],\n",
            "        [21.6880, 53.9725,  9.2237,  ..., 11.1949,  2.9502,  6.8709],\n",
            "        [21.6880, 53.9725,  9.2237,  ..., 11.1949,  2.9502,  6.8709]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 914, Loss: 58817.218750\n",
            "tensor([[21.7254, 54.0853,  9.2436,  ..., 11.2262,  2.9598,  6.8833],\n",
            "        [21.7254, 54.0853,  9.2436,  ..., 11.2262,  2.9598,  6.8833],\n",
            "        [21.7254, 54.0853,  9.2436,  ..., 11.2262,  2.9598,  6.8833],\n",
            "        ...,\n",
            "        [21.7254, 54.0853,  9.2436,  ..., 11.2262,  2.9598,  6.8833],\n",
            "        [21.7254, 54.0853,  9.2436,  ..., 11.2262,  2.9598,  6.8833],\n",
            "        [21.7254, 54.0853,  9.2436,  ..., 11.2262,  2.9598,  6.8833]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 915, Loss: 58800.507812\n",
            "tensor([[21.7629, 54.1981,  9.2635,  ..., 11.2575,  2.9694,  6.8957],\n",
            "        [21.7629, 54.1981,  9.2635,  ..., 11.2575,  2.9694,  6.8957],\n",
            "        [21.7629, 54.1981,  9.2635,  ..., 11.2575,  2.9694,  6.8957],\n",
            "        ...,\n",
            "        [21.7629, 54.1981,  9.2635,  ..., 11.2575,  2.9694,  6.8957],\n",
            "        [21.7629, 54.1981,  9.2635,  ..., 11.2575,  2.9694,  6.8957],\n",
            "        [21.7629, 54.1981,  9.2635,  ..., 11.2575,  2.9694,  6.8957]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 916, Loss: 58783.808594\n",
            "tensor([[21.8003, 54.3109,  9.2834,  ..., 11.2888,  2.9791,  6.9081],\n",
            "        [21.8003, 54.3109,  9.2834,  ..., 11.2888,  2.9791,  6.9081],\n",
            "        [21.8003, 54.3109,  9.2834,  ..., 11.2888,  2.9791,  6.9081],\n",
            "        ...,\n",
            "        [21.8003, 54.3109,  9.2834,  ..., 11.2888,  2.9791,  6.9081],\n",
            "        [21.8003, 54.3109,  9.2834,  ..., 11.2888,  2.9791,  6.9081],\n",
            "        [21.8003, 54.3109,  9.2834,  ..., 11.2888,  2.9791,  6.9081]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 917, Loss: 58767.117188\n",
            "tensor([[21.8378, 54.4237,  9.3033,  ..., 11.3201,  2.9887,  6.9206],\n",
            "        [21.8378, 54.4237,  9.3033,  ..., 11.3201,  2.9887,  6.9206],\n",
            "        [21.8378, 54.4237,  9.3033,  ..., 11.3201,  2.9887,  6.9206],\n",
            "        ...,\n",
            "        [21.8378, 54.4237,  9.3033,  ..., 11.3201,  2.9887,  6.9206],\n",
            "        [21.8378, 54.4237,  9.3033,  ..., 11.3201,  2.9887,  6.9206],\n",
            "        [21.8378, 54.4237,  9.3033,  ..., 11.3201,  2.9887,  6.9206]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 918, Loss: 58750.433594\n",
            "tensor([[21.8752, 54.5364,  9.3232,  ..., 11.3514,  2.9983,  6.9330],\n",
            "        [21.8752, 54.5364,  9.3232,  ..., 11.3514,  2.9983,  6.9330],\n",
            "        [21.8752, 54.5364,  9.3232,  ..., 11.3514,  2.9983,  6.9330],\n",
            "        ...,\n",
            "        [21.8752, 54.5364,  9.3232,  ..., 11.3514,  2.9983,  6.9330],\n",
            "        [21.8752, 54.5364,  9.3232,  ..., 11.3514,  2.9983,  6.9330],\n",
            "        [21.8752, 54.5364,  9.3232,  ..., 11.3514,  2.9983,  6.9330]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 919, Loss: 58733.753906\n",
            "tensor([[21.9126, 54.6491,  9.3430,  ..., 11.3827,  3.0080,  6.9454],\n",
            "        [21.9126, 54.6491,  9.3430,  ..., 11.3827,  3.0080,  6.9454],\n",
            "        [21.9126, 54.6491,  9.3430,  ..., 11.3827,  3.0080,  6.9454],\n",
            "        ...,\n",
            "        [21.9126, 54.6491,  9.3430,  ..., 11.3827,  3.0080,  6.9454],\n",
            "        [21.9126, 54.6491,  9.3430,  ..., 11.3827,  3.0080,  6.9454],\n",
            "        [21.9126, 54.6491,  9.3430,  ..., 11.3827,  3.0080,  6.9454]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 920, Loss: 58717.070312\n",
            "tensor([[21.9501, 54.7618,  9.3629,  ..., 11.4140,  3.0176,  6.9578],\n",
            "        [21.9501, 54.7618,  9.3629,  ..., 11.4140,  3.0176,  6.9578],\n",
            "        [21.9501, 54.7618,  9.3629,  ..., 11.4140,  3.0176,  6.9578],\n",
            "        ...,\n",
            "        [21.9501, 54.7618,  9.3629,  ..., 11.4140,  3.0176,  6.9578],\n",
            "        [21.9501, 54.7618,  9.3629,  ..., 11.4140,  3.0176,  6.9578],\n",
            "        [21.9501, 54.7618,  9.3629,  ..., 11.4140,  3.0176,  6.9578]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 921, Loss: 58700.414062\n",
            "tensor([[21.9875, 54.8745,  9.3828,  ..., 11.4452,  3.0272,  6.9702],\n",
            "        [21.9875, 54.8745,  9.3828,  ..., 11.4452,  3.0272,  6.9702],\n",
            "        [21.9875, 54.8745,  9.3828,  ..., 11.4452,  3.0272,  6.9702],\n",
            "        ...,\n",
            "        [21.9875, 54.8745,  9.3828,  ..., 11.4452,  3.0272,  6.9702],\n",
            "        [21.9875, 54.8745,  9.3828,  ..., 11.4452,  3.0272,  6.9702],\n",
            "        [21.9875, 54.8745,  9.3828,  ..., 11.4452,  3.0272,  6.9702]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 922, Loss: 58683.757812\n",
            "tensor([[22.0249, 54.9872,  9.4026,  ..., 11.4765,  3.0369,  6.9827],\n",
            "        [22.0249, 54.9872,  9.4026,  ..., 11.4765,  3.0369,  6.9827],\n",
            "        [22.0249, 54.9872,  9.4026,  ..., 11.4765,  3.0369,  6.9827],\n",
            "        ...,\n",
            "        [22.0249, 54.9872,  9.4026,  ..., 11.4765,  3.0369,  6.9827],\n",
            "        [22.0249, 54.9872,  9.4026,  ..., 11.4765,  3.0369,  6.9827],\n",
            "        [22.0249, 54.9872,  9.4026,  ..., 11.4765,  3.0369,  6.9827]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 923, Loss: 58667.105469\n",
            "tensor([[22.0623, 55.0998,  9.4225,  ..., 11.5078,  3.0465,  6.9951],\n",
            "        [22.0623, 55.0998,  9.4225,  ..., 11.5078,  3.0465,  6.9951],\n",
            "        [22.0623, 55.0998,  9.4225,  ..., 11.5078,  3.0465,  6.9951],\n",
            "        ...,\n",
            "        [22.0623, 55.0998,  9.4225,  ..., 11.5078,  3.0465,  6.9951],\n",
            "        [22.0623, 55.0998,  9.4225,  ..., 11.5078,  3.0465,  6.9951],\n",
            "        [22.0623, 55.0998,  9.4225,  ..., 11.5078,  3.0465,  6.9951]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 924, Loss: 58650.464844\n",
            "tensor([[22.0996, 55.2124,  9.4423,  ..., 11.5390,  3.0561,  7.0075],\n",
            "        [22.0996, 55.2124,  9.4423,  ..., 11.5390,  3.0561,  7.0075],\n",
            "        [22.0996, 55.2124,  9.4423,  ..., 11.5390,  3.0561,  7.0075],\n",
            "        ...,\n",
            "        [22.0996, 55.2124,  9.4423,  ..., 11.5390,  3.0561,  7.0075],\n",
            "        [22.0996, 55.2124,  9.4423,  ..., 11.5390,  3.0561,  7.0075],\n",
            "        [22.0996, 55.2124,  9.4423,  ..., 11.5390,  3.0561,  7.0075]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 925, Loss: 58633.816406\n",
            "tensor([[22.1370, 55.3250,  9.4622,  ..., 11.5703,  3.0657,  7.0199],\n",
            "        [22.1370, 55.3250,  9.4622,  ..., 11.5703,  3.0657,  7.0199],\n",
            "        [22.1370, 55.3250,  9.4622,  ..., 11.5703,  3.0657,  7.0199],\n",
            "        ...,\n",
            "        [22.1370, 55.3250,  9.4622,  ..., 11.5703,  3.0657,  7.0199],\n",
            "        [22.1370, 55.3250,  9.4622,  ..., 11.5703,  3.0657,  7.0199],\n",
            "        [22.1370, 55.3250,  9.4622,  ..., 11.5703,  3.0657,  7.0199]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 926, Loss: 58617.191406\n",
            "tensor([[22.1744, 55.4375,  9.4820,  ..., 11.6015,  3.0754,  7.0323],\n",
            "        [22.1744, 55.4375,  9.4820,  ..., 11.6015,  3.0754,  7.0323],\n",
            "        [22.1744, 55.4375,  9.4820,  ..., 11.6015,  3.0754,  7.0323],\n",
            "        ...,\n",
            "        [22.1744, 55.4375,  9.4820,  ..., 11.6015,  3.0754,  7.0323],\n",
            "        [22.1744, 55.4375,  9.4820,  ..., 11.6015,  3.0754,  7.0323],\n",
            "        [22.1744, 55.4375,  9.4820,  ..., 11.6015,  3.0754,  7.0323]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 927, Loss: 58600.558594\n",
            "tensor([[22.2118, 55.5501,  9.5019,  ..., 11.6327,  3.0850,  7.0447],\n",
            "        [22.2118, 55.5501,  9.5019,  ..., 11.6327,  3.0850,  7.0447],\n",
            "        [22.2118, 55.5501,  9.5019,  ..., 11.6327,  3.0850,  7.0447],\n",
            "        ...,\n",
            "        [22.2118, 55.5501,  9.5019,  ..., 11.6327,  3.0850,  7.0447],\n",
            "        [22.2118, 55.5501,  9.5019,  ..., 11.6327,  3.0850,  7.0447],\n",
            "        [22.2118, 55.5501,  9.5019,  ..., 11.6327,  3.0850,  7.0447]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 928, Loss: 58583.937500\n",
            "tensor([[22.2491, 55.6626,  9.5217,  ..., 11.6640,  3.0946,  7.0571],\n",
            "        [22.2491, 55.6626,  9.5217,  ..., 11.6640,  3.0946,  7.0571],\n",
            "        [22.2491, 55.6626,  9.5217,  ..., 11.6640,  3.0946,  7.0571],\n",
            "        ...,\n",
            "        [22.2491, 55.6626,  9.5217,  ..., 11.6640,  3.0946,  7.0571],\n",
            "        [22.2491, 55.6626,  9.5217,  ..., 11.6640,  3.0946,  7.0571],\n",
            "        [22.2491, 55.6626,  9.5217,  ..., 11.6640,  3.0946,  7.0571]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 929, Loss: 58567.332031\n",
            "tensor([[22.2865, 55.7751,  9.5415,  ..., 11.6952,  3.1042,  7.0695],\n",
            "        [22.2865, 55.7751,  9.5415,  ..., 11.6952,  3.1042,  7.0695],\n",
            "        [22.2865, 55.7751,  9.5415,  ..., 11.6952,  3.1042,  7.0695],\n",
            "        ...,\n",
            "        [22.2865, 55.7751,  9.5415,  ..., 11.6952,  3.1042,  7.0695],\n",
            "        [22.2865, 55.7751,  9.5415,  ..., 11.6952,  3.1042,  7.0695],\n",
            "        [22.2865, 55.7751,  9.5415,  ..., 11.6952,  3.1042,  7.0695]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 930, Loss: 58550.726562\n",
            "tensor([[22.3238, 55.8876,  9.5614,  ..., 11.7264,  3.1138,  7.0819],\n",
            "        [22.3238, 55.8876,  9.5614,  ..., 11.7264,  3.1138,  7.0819],\n",
            "        [22.3238, 55.8876,  9.5614,  ..., 11.7264,  3.1138,  7.0819],\n",
            "        ...,\n",
            "        [22.3238, 55.8876,  9.5614,  ..., 11.7264,  3.1138,  7.0819],\n",
            "        [22.3238, 55.8876,  9.5614,  ..., 11.7264,  3.1138,  7.0819],\n",
            "        [22.3238, 55.8876,  9.5614,  ..., 11.7264,  3.1138,  7.0819]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 931, Loss: 58534.125000\n",
            "tensor([[22.3612, 56.0000,  9.5812,  ..., 11.7576,  3.1234,  7.0943],\n",
            "        [22.3612, 56.0000,  9.5812,  ..., 11.7576,  3.1234,  7.0943],\n",
            "        [22.3612, 56.0000,  9.5812,  ..., 11.7576,  3.1234,  7.0943],\n",
            "        ...,\n",
            "        [22.3612, 56.0000,  9.5812,  ..., 11.7576,  3.1234,  7.0943],\n",
            "        [22.3612, 56.0000,  9.5812,  ..., 11.7576,  3.1234,  7.0943],\n",
            "        [22.3612, 56.0000,  9.5812,  ..., 11.7576,  3.1234,  7.0943]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 932, Loss: 58517.535156\n",
            "tensor([[22.3985, 56.1124,  9.6010,  ..., 11.7888,  3.1330,  7.1067],\n",
            "        [22.3985, 56.1124,  9.6010,  ..., 11.7888,  3.1330,  7.1067],\n",
            "        [22.3985, 56.1124,  9.6010,  ..., 11.7888,  3.1330,  7.1067],\n",
            "        ...,\n",
            "        [22.3985, 56.1124,  9.6010,  ..., 11.7888,  3.1330,  7.1067],\n",
            "        [22.3985, 56.1124,  9.6010,  ..., 11.7888,  3.1330,  7.1067],\n",
            "        [22.3985, 56.1124,  9.6010,  ..., 11.7888,  3.1330,  7.1067]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 933, Loss: 58500.949219\n",
            "tensor([[22.4358, 56.2249,  9.6208,  ..., 11.8200,  3.1426,  7.1190],\n",
            "        [22.4358, 56.2249,  9.6208,  ..., 11.8200,  3.1426,  7.1190],\n",
            "        [22.4358, 56.2249,  9.6208,  ..., 11.8200,  3.1426,  7.1190],\n",
            "        ...,\n",
            "        [22.4358, 56.2249,  9.6208,  ..., 11.8200,  3.1426,  7.1190],\n",
            "        [22.4358, 56.2249,  9.6208,  ..., 11.8200,  3.1426,  7.1190],\n",
            "        [22.4358, 56.2249,  9.6208,  ..., 11.8200,  3.1426,  7.1190]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 934, Loss: 58484.375000\n",
            "tensor([[22.4731, 56.3372,  9.6406,  ..., 11.8512,  3.1522,  7.1314],\n",
            "        [22.4731, 56.3372,  9.6406,  ..., 11.8512,  3.1522,  7.1314],\n",
            "        [22.4731, 56.3372,  9.6406,  ..., 11.8512,  3.1522,  7.1314],\n",
            "        ...,\n",
            "        [22.4731, 56.3372,  9.6406,  ..., 11.8512,  3.1522,  7.1314],\n",
            "        [22.4731, 56.3372,  9.6406,  ..., 11.8512,  3.1522,  7.1314],\n",
            "        [22.4731, 56.3372,  9.6406,  ..., 11.8512,  3.1522,  7.1314]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 935, Loss: 58467.796875\n",
            "tensor([[22.5104, 56.4496,  9.6604,  ..., 11.8824,  3.1618,  7.1438],\n",
            "        [22.5104, 56.4496,  9.6604,  ..., 11.8824,  3.1618,  7.1438],\n",
            "        [22.5104, 56.4496,  9.6604,  ..., 11.8824,  3.1618,  7.1438],\n",
            "        ...,\n",
            "        [22.5104, 56.4496,  9.6604,  ..., 11.8824,  3.1618,  7.1438],\n",
            "        [22.5104, 56.4496,  9.6604,  ..., 11.8824,  3.1618,  7.1438],\n",
            "        [22.5104, 56.4496,  9.6604,  ..., 11.8824,  3.1618,  7.1438]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 936, Loss: 58451.234375\n",
            "tensor([[22.5477, 56.5619,  9.6803,  ..., 11.9136,  3.1714,  7.1562],\n",
            "        [22.5477, 56.5619,  9.6803,  ..., 11.9136,  3.1714,  7.1562],\n",
            "        [22.5477, 56.5619,  9.6803,  ..., 11.9136,  3.1714,  7.1562],\n",
            "        ...,\n",
            "        [22.5477, 56.5619,  9.6803,  ..., 11.9136,  3.1714,  7.1562],\n",
            "        [22.5477, 56.5619,  9.6803,  ..., 11.9136,  3.1714,  7.1562],\n",
            "        [22.5477, 56.5619,  9.6803,  ..., 11.9136,  3.1714,  7.1562]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 937, Loss: 58434.671875\n",
            "tensor([[22.5850, 56.6743,  9.7001,  ..., 11.9447,  3.1810,  7.1686],\n",
            "        [22.5850, 56.6743,  9.7001,  ..., 11.9447,  3.1810,  7.1686],\n",
            "        [22.5850, 56.6743,  9.7001,  ..., 11.9447,  3.1810,  7.1686],\n",
            "        ...,\n",
            "        [22.5850, 56.6743,  9.7001,  ..., 11.9447,  3.1810,  7.1686],\n",
            "        [22.5850, 56.6743,  9.7001,  ..., 11.9447,  3.1810,  7.1686],\n",
            "        [22.5850, 56.6743,  9.7001,  ..., 11.9447,  3.1810,  7.1686]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 938, Loss: 58418.121094\n",
            "tensor([[22.6223, 56.7865,  9.7198,  ..., 11.9759,  3.1906,  7.1809],\n",
            "        [22.6223, 56.7865,  9.7198,  ..., 11.9759,  3.1906,  7.1809],\n",
            "        [22.6223, 56.7865,  9.7198,  ..., 11.9759,  3.1906,  7.1809],\n",
            "        ...,\n",
            "        [22.6223, 56.7865,  9.7198,  ..., 11.9759,  3.1906,  7.1809],\n",
            "        [22.6223, 56.7865,  9.7198,  ..., 11.9759,  3.1906,  7.1809],\n",
            "        [22.6223, 56.7865,  9.7198,  ..., 11.9759,  3.1906,  7.1809]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 939, Loss: 58401.578125\n",
            "tensor([[22.6596, 56.8988,  9.7396,  ..., 12.0071,  3.2002,  7.1933],\n",
            "        [22.6596, 56.8988,  9.7396,  ..., 12.0071,  3.2002,  7.1933],\n",
            "        [22.6596, 56.8988,  9.7396,  ..., 12.0071,  3.2002,  7.1933],\n",
            "        ...,\n",
            "        [22.6596, 56.8988,  9.7396,  ..., 12.0071,  3.2002,  7.1933],\n",
            "        [22.6596, 56.8988,  9.7396,  ..., 12.0071,  3.2002,  7.1933],\n",
            "        [22.6596, 56.8988,  9.7396,  ..., 12.0071,  3.2002,  7.1933]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 940, Loss: 58385.031250\n",
            "tensor([[22.6968, 57.0111,  9.7594,  ..., 12.0382,  3.2098,  7.2057],\n",
            "        [22.6968, 57.0111,  9.7594,  ..., 12.0382,  3.2098,  7.2057],\n",
            "        [22.6968, 57.0111,  9.7594,  ..., 12.0382,  3.2098,  7.2057],\n",
            "        ...,\n",
            "        [22.6968, 57.0111,  9.7594,  ..., 12.0382,  3.2098,  7.2057],\n",
            "        [22.6968, 57.0111,  9.7594,  ..., 12.0382,  3.2098,  7.2057],\n",
            "        [22.6968, 57.0111,  9.7594,  ..., 12.0382,  3.2098,  7.2057]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 941, Loss: 58368.503906\n",
            "tensor([[22.7341, 57.1233,  9.7792,  ..., 12.0694,  3.2194,  7.2180],\n",
            "        [22.7341, 57.1233,  9.7792,  ..., 12.0694,  3.2194,  7.2180],\n",
            "        [22.7341, 57.1233,  9.7792,  ..., 12.0694,  3.2194,  7.2180],\n",
            "        ...,\n",
            "        [22.7341, 57.1233,  9.7792,  ..., 12.0694,  3.2194,  7.2180],\n",
            "        [22.7341, 57.1233,  9.7792,  ..., 12.0694,  3.2194,  7.2180],\n",
            "        [22.7341, 57.1233,  9.7792,  ..., 12.0694,  3.2194,  7.2180]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 942, Loss: 58351.976562\n",
            "tensor([[22.7713, 57.2355,  9.7990,  ..., 12.1005,  3.2290,  7.2304],\n",
            "        [22.7713, 57.2355,  9.7990,  ..., 12.1005,  3.2290,  7.2304],\n",
            "        [22.7713, 57.2355,  9.7990,  ..., 12.1005,  3.2290,  7.2304],\n",
            "        ...,\n",
            "        [22.7713, 57.2355,  9.7990,  ..., 12.1005,  3.2290,  7.2304],\n",
            "        [22.7713, 57.2355,  9.7990,  ..., 12.1005,  3.2290,  7.2304],\n",
            "        [22.7713, 57.2355,  9.7990,  ..., 12.1005,  3.2290,  7.2304]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 943, Loss: 58335.464844\n",
            "tensor([[22.8086, 57.3477,  9.8188,  ..., 12.1316,  3.2386,  7.2428],\n",
            "        [22.8086, 57.3477,  9.8188,  ..., 12.1316,  3.2386,  7.2428],\n",
            "        [22.8086, 57.3477,  9.8188,  ..., 12.1316,  3.2386,  7.2428],\n",
            "        ...,\n",
            "        [22.8086, 57.3477,  9.8188,  ..., 12.1316,  3.2386,  7.2428],\n",
            "        [22.8086, 57.3477,  9.8188,  ..., 12.1316,  3.2386,  7.2428],\n",
            "        [22.8086, 57.3477,  9.8188,  ..., 12.1316,  3.2386,  7.2428]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 944, Loss: 58318.945312\n",
            "tensor([[22.8458, 57.4598,  9.8385,  ..., 12.1628,  3.2482,  7.2551],\n",
            "        [22.8458, 57.4598,  9.8385,  ..., 12.1628,  3.2482,  7.2551],\n",
            "        [22.8458, 57.4598,  9.8385,  ..., 12.1628,  3.2482,  7.2551],\n",
            "        ...,\n",
            "        [22.8458, 57.4598,  9.8385,  ..., 12.1628,  3.2482,  7.2551],\n",
            "        [22.8458, 57.4598,  9.8385,  ..., 12.1628,  3.2482,  7.2551],\n",
            "        [22.8458, 57.4598,  9.8385,  ..., 12.1628,  3.2482,  7.2551]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 945, Loss: 58302.441406\n",
            "tensor([[22.8831, 57.5720,  9.8583,  ..., 12.1939,  3.2578,  7.2675],\n",
            "        [22.8831, 57.5720,  9.8583,  ..., 12.1939,  3.2578,  7.2675],\n",
            "        [22.8831, 57.5720,  9.8583,  ..., 12.1939,  3.2578,  7.2675],\n",
            "        ...,\n",
            "        [22.8831, 57.5720,  9.8583,  ..., 12.1939,  3.2578,  7.2675],\n",
            "        [22.8831, 57.5720,  9.8583,  ..., 12.1939,  3.2578,  7.2675],\n",
            "        [22.8831, 57.5720,  9.8583,  ..., 12.1939,  3.2578,  7.2675]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 946, Loss: 58285.937500\n",
            "tensor([[22.9203, 57.6841,  9.8781,  ..., 12.2250,  3.2673,  7.2798],\n",
            "        [22.9203, 57.6841,  9.8781,  ..., 12.2250,  3.2673,  7.2798],\n",
            "        [22.9203, 57.6841,  9.8781,  ..., 12.2250,  3.2673,  7.2798],\n",
            "        ...,\n",
            "        [22.9203, 57.6841,  9.8781,  ..., 12.2250,  3.2673,  7.2798],\n",
            "        [22.9203, 57.6841,  9.8781,  ..., 12.2250,  3.2673,  7.2798],\n",
            "        [22.9203, 57.6841,  9.8781,  ..., 12.2250,  3.2673,  7.2798]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 947, Loss: 58269.445312\n",
            "tensor([[22.9575, 57.7962,  9.8978,  ..., 12.2561,  3.2769,  7.2922],\n",
            "        [22.9575, 57.7962,  9.8978,  ..., 12.2561,  3.2769,  7.2922],\n",
            "        [22.9575, 57.7962,  9.8978,  ..., 12.2561,  3.2769,  7.2922],\n",
            "        ...,\n",
            "        [22.9575, 57.7962,  9.8978,  ..., 12.2561,  3.2769,  7.2922],\n",
            "        [22.9575, 57.7962,  9.8978,  ..., 12.2561,  3.2769,  7.2922],\n",
            "        [22.9575, 57.7962,  9.8978,  ..., 12.2561,  3.2769,  7.2922]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 948, Loss: 58252.953125\n",
            "tensor([[22.9947, 57.9082,  9.9176,  ..., 12.2872,  3.2865,  7.3045],\n",
            "        [22.9947, 57.9082,  9.9176,  ..., 12.2872,  3.2865,  7.3045],\n",
            "        [22.9947, 57.9082,  9.9176,  ..., 12.2872,  3.2865,  7.3045],\n",
            "        ...,\n",
            "        [22.9947, 57.9082,  9.9176,  ..., 12.2872,  3.2865,  7.3045],\n",
            "        [22.9947, 57.9082,  9.9176,  ..., 12.2872,  3.2865,  7.3045],\n",
            "        [22.9947, 57.9082,  9.9176,  ..., 12.2872,  3.2865,  7.3045]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 949, Loss: 58236.484375\n",
            "tensor([[23.0319, 58.0203,  9.9374,  ..., 12.3183,  3.2961,  7.3169],\n",
            "        [23.0319, 58.0203,  9.9374,  ..., 12.3183,  3.2961,  7.3169],\n",
            "        [23.0319, 58.0203,  9.9374,  ..., 12.3183,  3.2961,  7.3169],\n",
            "        ...,\n",
            "        [23.0319, 58.0203,  9.9374,  ..., 12.3183,  3.2961,  7.3169],\n",
            "        [23.0319, 58.0203,  9.9374,  ..., 12.3183,  3.2961,  7.3169],\n",
            "        [23.0319, 58.0203,  9.9374,  ..., 12.3183,  3.2961,  7.3169]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 950, Loss: 58220.003906\n",
            "tensor([[23.0691, 58.1323,  9.9571,  ..., 12.3494,  3.3056,  7.3292],\n",
            "        [23.0691, 58.1323,  9.9571,  ..., 12.3494,  3.3056,  7.3292],\n",
            "        [23.0691, 58.1323,  9.9571,  ..., 12.3494,  3.3056,  7.3292],\n",
            "        ...,\n",
            "        [23.0691, 58.1323,  9.9571,  ..., 12.3494,  3.3056,  7.3292],\n",
            "        [23.0691, 58.1323,  9.9571,  ..., 12.3494,  3.3056,  7.3292],\n",
            "        [23.0691, 58.1323,  9.9571,  ..., 12.3494,  3.3056,  7.3292]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 951, Loss: 58203.542969\n",
            "tensor([[23.1063, 58.2443,  9.9768,  ..., 12.3805,  3.3152,  7.3416],\n",
            "        [23.1063, 58.2443,  9.9768,  ..., 12.3805,  3.3152,  7.3416],\n",
            "        [23.1063, 58.2443,  9.9768,  ..., 12.3805,  3.3152,  7.3416],\n",
            "        ...,\n",
            "        [23.1063, 58.2443,  9.9768,  ..., 12.3805,  3.3152,  7.3416],\n",
            "        [23.1063, 58.2443,  9.9768,  ..., 12.3805,  3.3152,  7.3416],\n",
            "        [23.1063, 58.2443,  9.9768,  ..., 12.3805,  3.3152,  7.3416]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 952, Loss: 58187.082031\n",
            "tensor([[23.1435, 58.3563,  9.9966,  ..., 12.4116,  3.3248,  7.3539],\n",
            "        [23.1435, 58.3563,  9.9966,  ..., 12.4116,  3.3248,  7.3539],\n",
            "        [23.1435, 58.3563,  9.9966,  ..., 12.4116,  3.3248,  7.3539],\n",
            "        ...,\n",
            "        [23.1435, 58.3563,  9.9966,  ..., 12.4116,  3.3248,  7.3539],\n",
            "        [23.1435, 58.3563,  9.9966,  ..., 12.4116,  3.3248,  7.3539],\n",
            "        [23.1435, 58.3563,  9.9966,  ..., 12.4116,  3.3248,  7.3539]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 953, Loss: 58170.628906\n",
            "tensor([[23.1806, 58.4683, 10.0163,  ..., 12.4426,  3.3344,  7.3662],\n",
            "        [23.1806, 58.4683, 10.0163,  ..., 12.4426,  3.3344,  7.3662],\n",
            "        [23.1806, 58.4683, 10.0163,  ..., 12.4426,  3.3344,  7.3662],\n",
            "        ...,\n",
            "        [23.1806, 58.4683, 10.0163,  ..., 12.4426,  3.3344,  7.3662],\n",
            "        [23.1806, 58.4683, 10.0163,  ..., 12.4426,  3.3344,  7.3662],\n",
            "        [23.1806, 58.4683, 10.0163,  ..., 12.4426,  3.3344,  7.3662]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 954, Loss: 58154.187500\n",
            "tensor([[23.2178, 58.5802, 10.0361,  ..., 12.4737,  3.3439,  7.3786],\n",
            "        [23.2178, 58.5802, 10.0361,  ..., 12.4737,  3.3439,  7.3786],\n",
            "        [23.2178, 58.5802, 10.0361,  ..., 12.4737,  3.3439,  7.3786],\n",
            "        ...,\n",
            "        [23.2178, 58.5802, 10.0361,  ..., 12.4737,  3.3439,  7.3786],\n",
            "        [23.2178, 58.5802, 10.0361,  ..., 12.4737,  3.3439,  7.3786],\n",
            "        [23.2178, 58.5802, 10.0361,  ..., 12.4737,  3.3439,  7.3786]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 955, Loss: 58137.738281\n",
            "tensor([[23.2549, 58.6921, 10.0558,  ..., 12.5048,  3.3535,  7.3909],\n",
            "        [23.2549, 58.6921, 10.0558,  ..., 12.5048,  3.3535,  7.3909],\n",
            "        [23.2549, 58.6921, 10.0558,  ..., 12.5048,  3.3535,  7.3909],\n",
            "        ...,\n",
            "        [23.2549, 58.6921, 10.0558,  ..., 12.5048,  3.3535,  7.3909],\n",
            "        [23.2549, 58.6921, 10.0558,  ..., 12.5048,  3.3535,  7.3909],\n",
            "        [23.2549, 58.6921, 10.0558,  ..., 12.5048,  3.3535,  7.3909]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 956, Loss: 58121.304688\n",
            "tensor([[23.2921, 58.8040, 10.0755,  ..., 12.5358,  3.3630,  7.4032],\n",
            "        [23.2921, 58.8040, 10.0755,  ..., 12.5358,  3.3630,  7.4032],\n",
            "        [23.2921, 58.8040, 10.0755,  ..., 12.5358,  3.3630,  7.4032],\n",
            "        ...,\n",
            "        [23.2921, 58.8040, 10.0755,  ..., 12.5358,  3.3630,  7.4032],\n",
            "        [23.2921, 58.8040, 10.0755,  ..., 12.5358,  3.3630,  7.4032],\n",
            "        [23.2921, 58.8040, 10.0755,  ..., 12.5358,  3.3630,  7.4032]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 957, Loss: 58104.882812\n",
            "tensor([[23.3292, 58.9159, 10.0952,  ..., 12.5669,  3.3726,  7.4155],\n",
            "        [23.3292, 58.9159, 10.0952,  ..., 12.5669,  3.3726,  7.4155],\n",
            "        [23.3292, 58.9159, 10.0952,  ..., 12.5669,  3.3726,  7.4155],\n",
            "        ...,\n",
            "        [23.3292, 58.9159, 10.0952,  ..., 12.5669,  3.3726,  7.4155],\n",
            "        [23.3292, 58.9159, 10.0952,  ..., 12.5669,  3.3726,  7.4155],\n",
            "        [23.3292, 58.9159, 10.0952,  ..., 12.5669,  3.3726,  7.4155]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 958, Loss: 58088.464844\n",
            "tensor([[23.3664, 59.0277, 10.1150,  ..., 12.5979,  3.3822,  7.4279],\n",
            "        [23.3664, 59.0277, 10.1150,  ..., 12.5979,  3.3822,  7.4279],\n",
            "        [23.3664, 59.0277, 10.1150,  ..., 12.5979,  3.3822,  7.4279],\n",
            "        ...,\n",
            "        [23.3664, 59.0277, 10.1150,  ..., 12.5979,  3.3822,  7.4279],\n",
            "        [23.3664, 59.0277, 10.1150,  ..., 12.5979,  3.3822,  7.4279],\n",
            "        [23.3664, 59.0277, 10.1150,  ..., 12.5979,  3.3822,  7.4279]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 959, Loss: 58072.039062\n",
            "tensor([[23.4035, 59.1395, 10.1347,  ..., 12.6289,  3.3917,  7.4402],\n",
            "        [23.4035, 59.1395, 10.1347,  ..., 12.6289,  3.3917,  7.4402],\n",
            "        [23.4035, 59.1395, 10.1347,  ..., 12.6289,  3.3917,  7.4402],\n",
            "        ...,\n",
            "        [23.4035, 59.1395, 10.1347,  ..., 12.6289,  3.3917,  7.4402],\n",
            "        [23.4035, 59.1395, 10.1347,  ..., 12.6289,  3.3917,  7.4402],\n",
            "        [23.4035, 59.1395, 10.1347,  ..., 12.6289,  3.3917,  7.4402]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 960, Loss: 58055.636719\n",
            "tensor([[23.4406, 59.2513, 10.1544,  ..., 12.6600,  3.4013,  7.4525],\n",
            "        [23.4406, 59.2513, 10.1544,  ..., 12.6600,  3.4013,  7.4525],\n",
            "        [23.4406, 59.2513, 10.1544,  ..., 12.6600,  3.4013,  7.4525],\n",
            "        ...,\n",
            "        [23.4406, 59.2513, 10.1544,  ..., 12.6600,  3.4013,  7.4525],\n",
            "        [23.4406, 59.2513, 10.1544,  ..., 12.6600,  3.4013,  7.4525],\n",
            "        [23.4406, 59.2513, 10.1544,  ..., 12.6600,  3.4013,  7.4525]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 961, Loss: 58039.234375\n",
            "tensor([[23.4777, 59.3631, 10.1741,  ..., 12.6910,  3.4108,  7.4648],\n",
            "        [23.4777, 59.3631, 10.1741,  ..., 12.6910,  3.4108,  7.4648],\n",
            "        [23.4777, 59.3631, 10.1741,  ..., 12.6910,  3.4108,  7.4648],\n",
            "        ...,\n",
            "        [23.4777, 59.3631, 10.1741,  ..., 12.6910,  3.4108,  7.4648],\n",
            "        [23.4777, 59.3631, 10.1741,  ..., 12.6910,  3.4108,  7.4648],\n",
            "        [23.4777, 59.3631, 10.1741,  ..., 12.6910,  3.4108,  7.4648]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 962, Loss: 58022.835938\n",
            "tensor([[23.5148, 59.4749, 10.1938,  ..., 12.7220,  3.4204,  7.4771],\n",
            "        [23.5148, 59.4749, 10.1938,  ..., 12.7220,  3.4204,  7.4771],\n",
            "        [23.5148, 59.4749, 10.1938,  ..., 12.7220,  3.4204,  7.4771],\n",
            "        ...,\n",
            "        [23.5148, 59.4749, 10.1938,  ..., 12.7220,  3.4204,  7.4771],\n",
            "        [23.5148, 59.4749, 10.1938,  ..., 12.7220,  3.4204,  7.4771],\n",
            "        [23.5148, 59.4749, 10.1938,  ..., 12.7220,  3.4204,  7.4771]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 963, Loss: 58006.453125\n",
            "tensor([[23.5519, 59.5866, 10.2135,  ..., 12.7530,  3.4299,  7.4894],\n",
            "        [23.5519, 59.5866, 10.2135,  ..., 12.7530,  3.4299,  7.4894],\n",
            "        [23.5519, 59.5866, 10.2135,  ..., 12.7530,  3.4299,  7.4894],\n",
            "        ...,\n",
            "        [23.5519, 59.5866, 10.2135,  ..., 12.7530,  3.4299,  7.4894],\n",
            "        [23.5519, 59.5866, 10.2135,  ..., 12.7530,  3.4299,  7.4894],\n",
            "        [23.5519, 59.5866, 10.2135,  ..., 12.7530,  3.4299,  7.4894]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 964, Loss: 57990.070312\n",
            "tensor([[23.5890, 59.6983, 10.2332,  ..., 12.7840,  3.4395,  7.5018],\n",
            "        [23.5890, 59.6983, 10.2332,  ..., 12.7840,  3.4395,  7.5018],\n",
            "        [23.5890, 59.6983, 10.2332,  ..., 12.7840,  3.4395,  7.5018],\n",
            "        ...,\n",
            "        [23.5890, 59.6983, 10.2332,  ..., 12.7840,  3.4395,  7.5018],\n",
            "        [23.5890, 59.6983, 10.2332,  ..., 12.7840,  3.4395,  7.5018],\n",
            "        [23.5890, 59.6983, 10.2332,  ..., 12.7840,  3.4395,  7.5018]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 965, Loss: 57973.695312\n",
            "tensor([[23.6261, 59.8100, 10.2529,  ..., 12.8150,  3.4490,  7.5141],\n",
            "        [23.6261, 59.8100, 10.2529,  ..., 12.8150,  3.4490,  7.5141],\n",
            "        [23.6261, 59.8100, 10.2529,  ..., 12.8150,  3.4490,  7.5141],\n",
            "        ...,\n",
            "        [23.6261, 59.8100, 10.2529,  ..., 12.8150,  3.4490,  7.5141],\n",
            "        [23.6261, 59.8100, 10.2529,  ..., 12.8150,  3.4490,  7.5141],\n",
            "        [23.6261, 59.8100, 10.2529,  ..., 12.8150,  3.4490,  7.5141]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 966, Loss: 57957.332031\n",
            "tensor([[23.6632, 59.9217, 10.2725,  ..., 12.8460,  3.4586,  7.5264],\n",
            "        [23.6632, 59.9217, 10.2725,  ..., 12.8460,  3.4586,  7.5264],\n",
            "        [23.6632, 59.9217, 10.2725,  ..., 12.8460,  3.4586,  7.5264],\n",
            "        ...,\n",
            "        [23.6632, 59.9217, 10.2725,  ..., 12.8460,  3.4586,  7.5264],\n",
            "        [23.6632, 59.9217, 10.2725,  ..., 12.8460,  3.4586,  7.5264],\n",
            "        [23.6632, 59.9217, 10.2725,  ..., 12.8460,  3.4586,  7.5264]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 967, Loss: 57940.972656\n",
            "tensor([[23.7002, 60.0333, 10.2922,  ..., 12.8770,  3.4681,  7.5387],\n",
            "        [23.7002, 60.0333, 10.2922,  ..., 12.8770,  3.4681,  7.5387],\n",
            "        [23.7002, 60.0333, 10.2922,  ..., 12.8770,  3.4681,  7.5387],\n",
            "        ...,\n",
            "        [23.7002, 60.0333, 10.2922,  ..., 12.8770,  3.4681,  7.5387],\n",
            "        [23.7002, 60.0333, 10.2922,  ..., 12.8770,  3.4681,  7.5387],\n",
            "        [23.7002, 60.0333, 10.2922,  ..., 12.8770,  3.4681,  7.5387]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 968, Loss: 57924.609375\n",
            "tensor([[23.7373, 60.1449, 10.3119,  ..., 12.9080,  3.4776,  7.5510],\n",
            "        [23.7373, 60.1449, 10.3119,  ..., 12.9080,  3.4776,  7.5510],\n",
            "        [23.7373, 60.1449, 10.3119,  ..., 12.9080,  3.4776,  7.5510],\n",
            "        ...,\n",
            "        [23.7373, 60.1449, 10.3119,  ..., 12.9080,  3.4776,  7.5510],\n",
            "        [23.7373, 60.1449, 10.3119,  ..., 12.9080,  3.4776,  7.5510],\n",
            "        [23.7373, 60.1449, 10.3119,  ..., 12.9080,  3.4776,  7.5510]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 969, Loss: 57908.261719\n",
            "tensor([[23.7744, 60.2565, 10.3316,  ..., 12.9389,  3.4872,  7.5633],\n",
            "        [23.7744, 60.2565, 10.3316,  ..., 12.9389,  3.4872,  7.5633],\n",
            "        [23.7744, 60.2565, 10.3316,  ..., 12.9389,  3.4872,  7.5633],\n",
            "        ...,\n",
            "        [23.7744, 60.2565, 10.3316,  ..., 12.9389,  3.4872,  7.5633],\n",
            "        [23.7744, 60.2565, 10.3316,  ..., 12.9389,  3.4872,  7.5633],\n",
            "        [23.7744, 60.2565, 10.3316,  ..., 12.9389,  3.4872,  7.5633]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 970, Loss: 57891.925781\n",
            "tensor([[23.8114, 60.3681, 10.3513,  ..., 12.9699,  3.4967,  7.5756],\n",
            "        [23.8114, 60.3681, 10.3513,  ..., 12.9699,  3.4967,  7.5756],\n",
            "        [23.8114, 60.3681, 10.3513,  ..., 12.9699,  3.4967,  7.5756],\n",
            "        ...,\n",
            "        [23.8114, 60.3681, 10.3513,  ..., 12.9699,  3.4967,  7.5756],\n",
            "        [23.8114, 60.3681, 10.3513,  ..., 12.9699,  3.4967,  7.5756],\n",
            "        [23.8114, 60.3681, 10.3513,  ..., 12.9699,  3.4967,  7.5756]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 971, Loss: 57875.589844\n",
            "tensor([[23.8484, 60.4797, 10.3709,  ..., 13.0009,  3.5062,  7.5879],\n",
            "        [23.8484, 60.4797, 10.3709,  ..., 13.0009,  3.5062,  7.5879],\n",
            "        [23.8484, 60.4797, 10.3709,  ..., 13.0009,  3.5062,  7.5879],\n",
            "        ...,\n",
            "        [23.8484, 60.4797, 10.3709,  ..., 13.0009,  3.5062,  7.5879],\n",
            "        [23.8484, 60.4797, 10.3709,  ..., 13.0009,  3.5062,  7.5879],\n",
            "        [23.8484, 60.4797, 10.3709,  ..., 13.0009,  3.5062,  7.5879]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 972, Loss: 57859.253906\n",
            "tensor([[23.8855, 60.5912, 10.3906,  ..., 13.0318,  3.5158,  7.6001],\n",
            "        [23.8855, 60.5912, 10.3906,  ..., 13.0318,  3.5158,  7.6001],\n",
            "        [23.8855, 60.5912, 10.3906,  ..., 13.0318,  3.5158,  7.6001],\n",
            "        ...,\n",
            "        [23.8855, 60.5912, 10.3906,  ..., 13.0318,  3.5158,  7.6001],\n",
            "        [23.8855, 60.5912, 10.3906,  ..., 13.0318,  3.5158,  7.6001],\n",
            "        [23.8855, 60.5912, 10.3906,  ..., 13.0318,  3.5158,  7.6001]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 973, Loss: 57842.941406\n",
            "tensor([[23.9225, 60.7027, 10.4102,  ..., 13.0628,  3.5253,  7.6124],\n",
            "        [23.9225, 60.7027, 10.4102,  ..., 13.0628,  3.5253,  7.6124],\n",
            "        [23.9225, 60.7027, 10.4102,  ..., 13.0628,  3.5253,  7.6124],\n",
            "        ...,\n",
            "        [23.9225, 60.7027, 10.4102,  ..., 13.0628,  3.5253,  7.6124],\n",
            "        [23.9225, 60.7027, 10.4102,  ..., 13.0628,  3.5253,  7.6124],\n",
            "        [23.9225, 60.7027, 10.4102,  ..., 13.0628,  3.5253,  7.6124]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 974, Loss: 57826.621094\n",
            "tensor([[23.9595, 60.8142, 10.4299,  ..., 13.0937,  3.5348,  7.6247],\n",
            "        [23.9595, 60.8142, 10.4299,  ..., 13.0937,  3.5348,  7.6247],\n",
            "        [23.9595, 60.8142, 10.4299,  ..., 13.0937,  3.5348,  7.6247],\n",
            "        ...,\n",
            "        [23.9595, 60.8142, 10.4299,  ..., 13.0937,  3.5348,  7.6247],\n",
            "        [23.9595, 60.8142, 10.4299,  ..., 13.0937,  3.5348,  7.6247],\n",
            "        [23.9595, 60.8142, 10.4299,  ..., 13.0937,  3.5348,  7.6247]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 975, Loss: 57810.308594\n",
            "tensor([[23.9965, 60.9257, 10.4495,  ..., 13.1247,  3.5444,  7.6370],\n",
            "        [23.9965, 60.9257, 10.4495,  ..., 13.1247,  3.5444,  7.6370],\n",
            "        [23.9965, 60.9257, 10.4495,  ..., 13.1247,  3.5444,  7.6370],\n",
            "        ...,\n",
            "        [23.9965, 60.9257, 10.4495,  ..., 13.1247,  3.5444,  7.6370],\n",
            "        [23.9965, 60.9257, 10.4495,  ..., 13.1247,  3.5444,  7.6370],\n",
            "        [23.9965, 60.9257, 10.4495,  ..., 13.1247,  3.5444,  7.6370]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 976, Loss: 57794.007812\n",
            "tensor([[24.0335, 61.0371, 10.4692,  ..., 13.1556,  3.5539,  7.6493],\n",
            "        [24.0335, 61.0371, 10.4692,  ..., 13.1556,  3.5539,  7.6493],\n",
            "        [24.0335, 61.0371, 10.4692,  ..., 13.1556,  3.5539,  7.6493],\n",
            "        ...,\n",
            "        [24.0335, 61.0371, 10.4692,  ..., 13.1556,  3.5539,  7.6493],\n",
            "        [24.0335, 61.0371, 10.4692,  ..., 13.1556,  3.5539,  7.6493],\n",
            "        [24.0335, 61.0371, 10.4692,  ..., 13.1556,  3.5539,  7.6493]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 977, Loss: 57777.714844\n",
            "tensor([[24.0705, 61.1485, 10.4888,  ..., 13.1865,  3.5634,  7.6615],\n",
            "        [24.0705, 61.1485, 10.4888,  ..., 13.1865,  3.5634,  7.6615],\n",
            "        [24.0705, 61.1485, 10.4888,  ..., 13.1865,  3.5634,  7.6615],\n",
            "        ...,\n",
            "        [24.0705, 61.1485, 10.4888,  ..., 13.1865,  3.5634,  7.6615],\n",
            "        [24.0705, 61.1485, 10.4888,  ..., 13.1865,  3.5634,  7.6615],\n",
            "        [24.0705, 61.1485, 10.4888,  ..., 13.1865,  3.5634,  7.6615]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 978, Loss: 57761.421875\n",
            "tensor([[24.1075, 61.2599, 10.5085,  ..., 13.2174,  3.5729,  7.6738],\n",
            "        [24.1075, 61.2599, 10.5085,  ..., 13.2174,  3.5729,  7.6738],\n",
            "        [24.1075, 61.2599, 10.5085,  ..., 13.2174,  3.5729,  7.6738],\n",
            "        ...,\n",
            "        [24.1075, 61.2599, 10.5085,  ..., 13.2174,  3.5729,  7.6738],\n",
            "        [24.1075, 61.2599, 10.5085,  ..., 13.2174,  3.5729,  7.6738],\n",
            "        [24.1075, 61.2599, 10.5085,  ..., 13.2174,  3.5729,  7.6738]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 979, Loss: 57745.132812\n",
            "tensor([[24.1445, 61.3713, 10.5281,  ..., 13.2483,  3.5824,  7.6861],\n",
            "        [24.1445, 61.3713, 10.5281,  ..., 13.2483,  3.5824,  7.6861],\n",
            "        [24.1445, 61.3713, 10.5281,  ..., 13.2483,  3.5824,  7.6861],\n",
            "        ...,\n",
            "        [24.1445, 61.3713, 10.5281,  ..., 13.2483,  3.5824,  7.6861],\n",
            "        [24.1445, 61.3713, 10.5281,  ..., 13.2483,  3.5824,  7.6861],\n",
            "        [24.1445, 61.3713, 10.5281,  ..., 13.2483,  3.5824,  7.6861]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 980, Loss: 57728.859375\n",
            "tensor([[24.1814, 61.4826, 10.5477,  ..., 13.2792,  3.5920,  7.6984],\n",
            "        [24.1814, 61.4826, 10.5477,  ..., 13.2792,  3.5920,  7.6984],\n",
            "        [24.1814, 61.4826, 10.5477,  ..., 13.2792,  3.5920,  7.6984],\n",
            "        ...,\n",
            "        [24.1814, 61.4826, 10.5477,  ..., 13.2792,  3.5920,  7.6984],\n",
            "        [24.1814, 61.4826, 10.5477,  ..., 13.2792,  3.5920,  7.6984],\n",
            "        [24.1814, 61.4826, 10.5477,  ..., 13.2792,  3.5920,  7.6984]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 981, Loss: 57712.593750\n",
            "tensor([[24.2184, 61.5940, 10.5674,  ..., 13.3101,  3.6015,  7.7106],\n",
            "        [24.2184, 61.5940, 10.5674,  ..., 13.3101,  3.6015,  7.7106],\n",
            "        [24.2184, 61.5940, 10.5674,  ..., 13.3101,  3.6015,  7.7106],\n",
            "        ...,\n",
            "        [24.2184, 61.5940, 10.5674,  ..., 13.3101,  3.6015,  7.7106],\n",
            "        [24.2184, 61.5940, 10.5674,  ..., 13.3101,  3.6015,  7.7106],\n",
            "        [24.2184, 61.5940, 10.5674,  ..., 13.3101,  3.6015,  7.7106]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 982, Loss: 57696.324219\n",
            "tensor([[24.2554, 61.7053, 10.5870,  ..., 13.3410,  3.6110,  7.7229],\n",
            "        [24.2554, 61.7053, 10.5870,  ..., 13.3410,  3.6110,  7.7229],\n",
            "        [24.2554, 61.7053, 10.5870,  ..., 13.3410,  3.6110,  7.7229],\n",
            "        ...,\n",
            "        [24.2554, 61.7053, 10.5870,  ..., 13.3410,  3.6110,  7.7229],\n",
            "        [24.2554, 61.7053, 10.5870,  ..., 13.3410,  3.6110,  7.7229],\n",
            "        [24.2554, 61.7053, 10.5870,  ..., 13.3410,  3.6110,  7.7229]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 983, Loss: 57680.074219\n",
            "tensor([[24.2923, 61.8166, 10.6066,  ..., 13.3719,  3.6205,  7.7352],\n",
            "        [24.2923, 61.8166, 10.6066,  ..., 13.3719,  3.6205,  7.7352],\n",
            "        [24.2923, 61.8166, 10.6066,  ..., 13.3719,  3.6205,  7.7352],\n",
            "        ...,\n",
            "        [24.2923, 61.8166, 10.6066,  ..., 13.3719,  3.6205,  7.7352],\n",
            "        [24.2923, 61.8166, 10.6066,  ..., 13.3719,  3.6205,  7.7352],\n",
            "        [24.2923, 61.8166, 10.6066,  ..., 13.3719,  3.6205,  7.7352]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 984, Loss: 57663.820312\n",
            "tensor([[24.3292, 61.9278, 10.6262,  ..., 13.4028,  3.6300,  7.7474],\n",
            "        [24.3292, 61.9278, 10.6262,  ..., 13.4028,  3.6300,  7.7474],\n",
            "        [24.3292, 61.9278, 10.6262,  ..., 13.4028,  3.6300,  7.7474],\n",
            "        ...,\n",
            "        [24.3292, 61.9278, 10.6262,  ..., 13.4028,  3.6300,  7.7474],\n",
            "        [24.3292, 61.9278, 10.6262,  ..., 13.4028,  3.6300,  7.7474],\n",
            "        [24.3292, 61.9278, 10.6262,  ..., 13.4028,  3.6300,  7.7474]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 985, Loss: 57647.570312\n",
            "tensor([[24.3662, 62.0391, 10.6458,  ..., 13.4337,  3.6395,  7.7597],\n",
            "        [24.3662, 62.0391, 10.6458,  ..., 13.4337,  3.6395,  7.7597],\n",
            "        [24.3662, 62.0391, 10.6458,  ..., 13.4337,  3.6395,  7.7597],\n",
            "        ...,\n",
            "        [24.3662, 62.0391, 10.6458,  ..., 13.4337,  3.6395,  7.7597],\n",
            "        [24.3662, 62.0391, 10.6458,  ..., 13.4337,  3.6395,  7.7597],\n",
            "        [24.3662, 62.0391, 10.6458,  ..., 13.4337,  3.6395,  7.7597]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 986, Loss: 57631.343750\n",
            "tensor([[24.4031, 62.1503, 10.6654,  ..., 13.4645,  3.6490,  7.7719],\n",
            "        [24.4031, 62.1503, 10.6654,  ..., 13.4645,  3.6490,  7.7719],\n",
            "        [24.4031, 62.1503, 10.6654,  ..., 13.4645,  3.6490,  7.7719],\n",
            "        ...,\n",
            "        [24.4031, 62.1503, 10.6654,  ..., 13.4645,  3.6490,  7.7719],\n",
            "        [24.4031, 62.1503, 10.6654,  ..., 13.4645,  3.6490,  7.7719],\n",
            "        [24.4031, 62.1503, 10.6654,  ..., 13.4645,  3.6490,  7.7719]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 987, Loss: 57615.113281\n",
            "tensor([[24.4400, 62.2615, 10.6850,  ..., 13.4954,  3.6585,  7.7842],\n",
            "        [24.4400, 62.2615, 10.6850,  ..., 13.4954,  3.6585,  7.7842],\n",
            "        [24.4400, 62.2615, 10.6850,  ..., 13.4954,  3.6585,  7.7842],\n",
            "        ...,\n",
            "        [24.4400, 62.2615, 10.6850,  ..., 13.4954,  3.6585,  7.7842],\n",
            "        [24.4400, 62.2615, 10.6850,  ..., 13.4954,  3.6585,  7.7842],\n",
            "        [24.4400, 62.2615, 10.6850,  ..., 13.4954,  3.6585,  7.7842]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 988, Loss: 57598.882812\n",
            "tensor([[24.4769, 62.3727, 10.7046,  ..., 13.5263,  3.6680,  7.7964],\n",
            "        [24.4769, 62.3727, 10.7046,  ..., 13.5263,  3.6680,  7.7964],\n",
            "        [24.4769, 62.3727, 10.7046,  ..., 13.5263,  3.6680,  7.7964],\n",
            "        ...,\n",
            "        [24.4769, 62.3727, 10.7046,  ..., 13.5263,  3.6680,  7.7964],\n",
            "        [24.4769, 62.3727, 10.7046,  ..., 13.5263,  3.6680,  7.7964],\n",
            "        [24.4769, 62.3727, 10.7046,  ..., 13.5263,  3.6680,  7.7964]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 989, Loss: 57582.664062\n",
            "tensor([[24.5138, 62.4838, 10.7242,  ..., 13.5571,  3.6775,  7.8087],\n",
            "        [24.5138, 62.4838, 10.7242,  ..., 13.5571,  3.6775,  7.8087],\n",
            "        [24.5138, 62.4838, 10.7242,  ..., 13.5571,  3.6775,  7.8087],\n",
            "        ...,\n",
            "        [24.5138, 62.4838, 10.7242,  ..., 13.5571,  3.6775,  7.8087],\n",
            "        [24.5138, 62.4838, 10.7242,  ..., 13.5571,  3.6775,  7.8087],\n",
            "        [24.5138, 62.4838, 10.7242,  ..., 13.5571,  3.6775,  7.8087]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 990, Loss: 57566.453125\n",
            "tensor([[24.5507, 62.5950, 10.7438,  ..., 13.5880,  3.6870,  7.8209],\n",
            "        [24.5507, 62.5950, 10.7438,  ..., 13.5880,  3.6870,  7.8209],\n",
            "        [24.5507, 62.5950, 10.7438,  ..., 13.5880,  3.6870,  7.8209],\n",
            "        ...,\n",
            "        [24.5507, 62.5950, 10.7438,  ..., 13.5880,  3.6870,  7.8209],\n",
            "        [24.5507, 62.5950, 10.7438,  ..., 13.5880,  3.6870,  7.8209],\n",
            "        [24.5507, 62.5950, 10.7438,  ..., 13.5880,  3.6870,  7.8209]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 991, Loss: 57550.250000\n",
            "tensor([[24.5876, 62.7061, 10.7634,  ..., 13.6188,  3.6965,  7.8332],\n",
            "        [24.5876, 62.7061, 10.7634,  ..., 13.6188,  3.6965,  7.8332],\n",
            "        [24.5876, 62.7061, 10.7634,  ..., 13.6188,  3.6965,  7.8332],\n",
            "        ...,\n",
            "        [24.5876, 62.7061, 10.7634,  ..., 13.6188,  3.6965,  7.8332],\n",
            "        [24.5876, 62.7061, 10.7634,  ..., 13.6188,  3.6965,  7.8332],\n",
            "        [24.5876, 62.7061, 10.7634,  ..., 13.6188,  3.6965,  7.8332]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 992, Loss: 57534.054688\n",
            "tensor([[24.6245, 62.8172, 10.7830,  ..., 13.6496,  3.7060,  7.8454],\n",
            "        [24.6245, 62.8172, 10.7830,  ..., 13.6496,  3.7060,  7.8454],\n",
            "        [24.6245, 62.8172, 10.7830,  ..., 13.6496,  3.7060,  7.8454],\n",
            "        ...,\n",
            "        [24.6245, 62.8172, 10.7830,  ..., 13.6496,  3.7060,  7.8454],\n",
            "        [24.6245, 62.8172, 10.7830,  ..., 13.6496,  3.7060,  7.8454],\n",
            "        [24.6245, 62.8172, 10.7830,  ..., 13.6496,  3.7060,  7.8454]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 993, Loss: 57517.859375\n",
            "tensor([[24.6614, 62.9282, 10.8026,  ..., 13.6804,  3.7155,  7.8576],\n",
            "        [24.6614, 62.9282, 10.8026,  ..., 13.6804,  3.7155,  7.8576],\n",
            "        [24.6614, 62.9282, 10.8026,  ..., 13.6804,  3.7155,  7.8576],\n",
            "        ...,\n",
            "        [24.6614, 62.9282, 10.8026,  ..., 13.6804,  3.7155,  7.8576],\n",
            "        [24.6614, 62.9282, 10.8026,  ..., 13.6804,  3.7155,  7.8576],\n",
            "        [24.6614, 62.9282, 10.8026,  ..., 13.6804,  3.7155,  7.8576]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 994, Loss: 57501.675781\n",
            "tensor([[24.6983, 63.0393, 10.8222,  ..., 13.7113,  3.7250,  7.8699],\n",
            "        [24.6983, 63.0393, 10.8222,  ..., 13.7113,  3.7250,  7.8699],\n",
            "        [24.6983, 63.0393, 10.8222,  ..., 13.7113,  3.7250,  7.8699],\n",
            "        ...,\n",
            "        [24.6983, 63.0393, 10.8222,  ..., 13.7113,  3.7250,  7.8699],\n",
            "        [24.6983, 63.0393, 10.8222,  ..., 13.7113,  3.7250,  7.8699],\n",
            "        [24.6983, 63.0393, 10.8222,  ..., 13.7113,  3.7250,  7.8699]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 995, Loss: 57485.496094\n",
            "tensor([[24.7351, 63.1503, 10.8417,  ..., 13.7421,  3.7345,  7.8821],\n",
            "        [24.7351, 63.1503, 10.8417,  ..., 13.7421,  3.7345,  7.8821],\n",
            "        [24.7351, 63.1503, 10.8417,  ..., 13.7421,  3.7345,  7.8821],\n",
            "        ...,\n",
            "        [24.7351, 63.1503, 10.8417,  ..., 13.7421,  3.7345,  7.8821],\n",
            "        [24.7351, 63.1503, 10.8417,  ..., 13.7421,  3.7345,  7.8821],\n",
            "        [24.7351, 63.1503, 10.8417,  ..., 13.7421,  3.7345,  7.8821]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 996, Loss: 57469.316406\n",
            "tensor([[24.7720, 63.2613, 10.8613,  ..., 13.7729,  3.7439,  7.8943],\n",
            "        [24.7720, 63.2613, 10.8613,  ..., 13.7729,  3.7439,  7.8943],\n",
            "        [24.7720, 63.2613, 10.8613,  ..., 13.7729,  3.7439,  7.8943],\n",
            "        ...,\n",
            "        [24.7720, 63.2613, 10.8613,  ..., 13.7729,  3.7439,  7.8943],\n",
            "        [24.7720, 63.2613, 10.8613,  ..., 13.7729,  3.7439,  7.8943],\n",
            "        [24.7720, 63.2613, 10.8613,  ..., 13.7729,  3.7439,  7.8943]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 997, Loss: 57453.160156\n",
            "tensor([[24.8088, 63.3723, 10.8809,  ..., 13.8037,  3.7534,  7.9066],\n",
            "        [24.8088, 63.3723, 10.8809,  ..., 13.8037,  3.7534,  7.9066],\n",
            "        [24.8088, 63.3723, 10.8809,  ..., 13.8037,  3.7534,  7.9066],\n",
            "        ...,\n",
            "        [24.8088, 63.3723, 10.8809,  ..., 13.8037,  3.7534,  7.9066],\n",
            "        [24.8088, 63.3723, 10.8809,  ..., 13.8037,  3.7534,  7.9066],\n",
            "        [24.8088, 63.3723, 10.8809,  ..., 13.8037,  3.7534,  7.9066]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 998, Loss: 57436.988281\n",
            "tensor([[24.8456, 63.4832, 10.9004,  ..., 13.8345,  3.7629,  7.9188],\n",
            "        [24.8456, 63.4832, 10.9004,  ..., 13.8345,  3.7629,  7.9188],\n",
            "        [24.8456, 63.4832, 10.9004,  ..., 13.8345,  3.7629,  7.9188],\n",
            "        ...,\n",
            "        [24.8456, 63.4832, 10.9004,  ..., 13.8345,  3.7629,  7.9188],\n",
            "        [24.8456, 63.4832, 10.9004,  ..., 13.8345,  3.7629,  7.9188],\n",
            "        [24.8456, 63.4832, 10.9004,  ..., 13.8345,  3.7629,  7.9188]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 999, Loss: 57420.847656\n",
            "tensor([[24.8825, 63.5941, 10.9200,  ..., 13.8653,  3.7724,  7.9310],\n",
            "        [24.8825, 63.5941, 10.9200,  ..., 13.8653,  3.7724,  7.9310],\n",
            "        [24.8825, 63.5941, 10.9200,  ..., 13.8653,  3.7724,  7.9310],\n",
            "        ...,\n",
            "        [24.8825, 63.5941, 10.9200,  ..., 13.8653,  3.7724,  7.9310],\n",
            "        [24.8825, 63.5941, 10.9200,  ..., 13.8653,  3.7724,  7.9310],\n",
            "        [24.8825, 63.5941, 10.9200,  ..., 13.8653,  3.7724,  7.9310]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch: 1000, Loss: 57404.691406\n",
            "Optimized Weights: [0.1459365  0.47382853 0.08800036 0.06747959 0.04085271 0.01818576\n",
            " 0.05218249 0.04953178 0.02796344 0.03603884]\n",
            "Sharpe Ratio: 0.09700934621974942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using DeepDow\n",
        "\n",
        "In progress"
      ],
      "metadata": {
        "id": "K2E9CbLpHBh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookback, gap, horizon = 40, 2, 20\n",
        "n_samples = len(assets) - lookback - horizon - gap + 1"
      ],
      "metadata": {
        "id": "SQQtDTTDBfn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_ix = int(n_samples * 0.8)\n",
        "indices_train = list(range(split_ix))\n",
        "indices_test = list(range(split_ix + lookback + horizon, n_samples))\n",
        "\n",
        "print('Train range: {}:{}\\nTest range: {}:{}'.format(indices_train[0], indices_train[-1],\n",
        "                                                     indices_test[0], indices_test[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k965HlYEG_yZ",
        "outputId": "f90f2041-3d50-44f6-d3ac-7add79e854b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train range: 0:1966\n",
            "Test range: 2027:2458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "igEEZjmMHJ-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}